{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from my_efficientnet_pytorch_3d import EfficientNet3D\n",
    "\n",
    "import scipy.ndimage as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "# from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import glob\n",
    "# import tqdm\n",
    "from typing import Dict\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"../input/osic-pulmonary-fibrosis-progression/\" if 'linux' in platform.platform().lower() else 'data/'\n",
    "\n",
    "train_df = pd.read_csv(f'{IMAGE_PATH}/train.csv')\n",
    "test_df = pd.read_csv(f'{IMAGE_PATH}/test.csv')\n",
    "\n",
    "# print(Fore.YELLOW + 'Training data shape: ',Style.RESET_ALL,train_df.shape)\n",
    "# train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating unique patient lists and their properties. \n",
    "train_dir = f'{IMAGE_PATH}/train/'\n",
    "test_dir = f'{IMAGE_PATH}/test/'\n",
    "\n",
    "patient_ids = os.listdir(train_dir)\n",
    "patient_ids = sorted(patient_ids)\n",
    "\n",
    "#Creating new rows\n",
    "no_of_instances = []\n",
    "age = []\n",
    "sex = []\n",
    "smoking_status = []\n",
    "\n",
    "for patient_id in patient_ids:\n",
    "    patient_info = train_df[train_df['Patient'] == patient_id].reset_index()\n",
    "    no_of_instances.append(len(os.listdir(train_dir + patient_id)))\n",
    "    age.append(patient_info['Age'][0])\n",
    "    sex.append(patient_info['Sex'][0])\n",
    "    smoking_status.append(patient_info['SmokingStatus'][0])\n",
    "\n",
    "#Creating the dataframe for the patient info    \n",
    "patient_df = pd.DataFrame(list(zip(patient_ids, no_of_instances, age, sex, smoking_status)), \n",
    "                                 columns =['Patient', 'no_of_instances', 'Age', 'Sex', 'SmokingStatus'])\n",
    "# print(patient_df.info())\n",
    "# patient_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = []\n",
    "for i, patient in test_df.iterrows():\n",
    "    for week in range(-12, 133 + 1):\n",
    "        tmp_id = patient.Patient + '_' + str(week)\n",
    "        FVC = patient.FVC + (-110 if week > 0 else 130)\n",
    "        Confidence = 70\n",
    "        answer.append([tmp_id, FVC, Confidence])\n",
    "#         print(tmp_id, FVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(answer, columns=['Patient_Week', 'FVC', 'Confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"submission.csv\", index=False)  # .to_csv('sample_submission.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "\n",
    "import scipy\n",
    "\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.segmentation\n",
    "\n",
    "import imageio\n",
    "\n",
    "import tabulate\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from pydicom import dcmread\n",
    "from pydicom import multival\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = dcmread(f'{IMAGE_PATH}/train/ID00183637202241995351650/52.dcm')\n",
    "# image\n",
    "# plt.imshow(image.pixel_array, cmap=\"gray\")\n",
    "\n",
    "\n",
    "# def subplots_3d(nrows=1, ncols=1, figsize=None):\n",
    "#     fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "#     axes = np.array(axes).reshape([nrows, ncols])\n",
    "    \n",
    "#     for idx in range(len(axes)):\n",
    "#         for jdx in range(len(axes[idx])):\n",
    "#             axes[idx][jdx].remove()\n",
    "#             axes[idx][jdx] = fig.add_subplot(nrows, ncols, 1 + idx * ncols + jdx,projection='3d')\n",
    "            \n",
    "#     if nrows == 1:\n",
    "#         return fig, axes[0].tolist()\n",
    "#     return fig, axes.tolist()\n",
    "\n",
    "# def plot_3d(ax, image, stride, threshold=700, color=\"navy\"):\n",
    "#     if isinstance(stride, (int, float)):\n",
    "#         stride = (stride, stride, stride)\n",
    "    \n",
    "#     image = image[::stride[0], ::stride[1], ::stride[2]]\n",
    "        \n",
    "#     # Position the scan upright, \n",
    "#     # so the head of the patient would be at the top facing the camera\n",
    "#     p = image.transpose(2,1,0)\n",
    "    \n",
    "#     verts, faces,_,_ = skimage.measure.marching_cubes(p, threshold)\n",
    "    \n",
    "#     # Fancy indexing: `verts[faces]` to generate a collection of triangles\n",
    "#     mesh = Poly3DCollection(verts[faces], alpha=0.2)\n",
    "#     mesh.set_facecolor(color)\n",
    "#     ax.add_collection3d(mesh)\n",
    "\n",
    "#     ax.set_xlim(0, p.shape[0])\n",
    "#     ax.set_ylim(0, p.shape[1])\n",
    "#     ax.set_zlim(0, p.shape[2])\n",
    "    \n",
    "# def sample_slices(images, n_slices, masks=None, alpha=0.2, cmap_name=None):\n",
    "#     nrows, ncols = n_slices // 4 + ((n_slices % 4) > 0), 4\n",
    "#     fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 5, nrows * 4))\n",
    "#     axes = np.array(axes).reshape(-1)\n",
    "\n",
    "#     idxs = np.sort(np.random.choice(np.arange(len(images)), nrows * ncols, replace=False))\n",
    "    \n",
    "#     for ax, idx in zip(axes, idxs):\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "#         ax.get_yaxis().set_visible(False)\n",
    "#         ax.imshow(images[idx], cmap=plt.get_cmap(cmap_name))\n",
    "#         if masks is not None:\n",
    "#             ax.imshow(masks[idx], alpha=alpha)\n",
    "# #             ax.imshow(masks[idx], alpha=alpha, cmap=plt.get_cmap(cmap_name))\n",
    "#         ax.grid(False)\n",
    "#         ax.set_title(f'Slice {idx}')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_patients = sorted(os.listdir('./data/test/'))\n",
    "# train_patients = sorted(os.listdir('./data/train/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ct = {\n",
    "#     patient: [\n",
    "#         dcmread(os.path.join('./data/test', patient, ct_file)) \n",
    "#         for ct_file in sorted(os.listdir(os.path.join('./data/test/', patient)))\n",
    "#     ] for patient in test_patients\n",
    "# }\n",
    "# train_ct = {\n",
    "#     patient: [\n",
    "#         dcmread(os.path.join('./data/train', patient, ct_file)) \n",
    "#         for ct_file in os.listdir(os.path.join('./data/train/', patient))\n",
    "#     ] for patient in train_patients\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    ID00026637202179561894768 №11 -- strange images\\n    ID00076637202199015035026 №30 -- first 9 images need to be fixed\\n    ID00078637202199415319443 №32 -- two breathes\\n    ID00123637202217151272140 №51 -- very bag segmentation\\n    ID00126637202218610655908 №54 -- first 1 images need to be fixed\\n    ID00128637202219474716089 №56 -- strange images\\n    ID00129637202219868188000 №57 -- very bag segmentation\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getkey(dcm, key):\n",
    "    try:\n",
    "        base_value = dcm[key]\n",
    "    except:\n",
    "        print(dcm.PatientID, dcm.InstanceNumber, key)\n",
    "        return'KeyError'\n",
    "    try:\n",
    "        return base_value.value\n",
    "    except:\n",
    "        return base_value\n",
    "\n",
    "def transform_to_hu(ct):\n",
    "    slope = ct.RescaleSlope\n",
    "    intercept = ct.RescaleIntercept\n",
    "    image = ct.pixel_array.astype(np.int16)\n",
    "    \n",
    "    # some images has ousige pixel-values corresponging water\n",
    "    # fix those images\n",
    "    zero_cols = np.argwhere(np.sum(ct.pixel_array, axis=0) == 0).reshape(-1)\n",
    "    zero_rows = np.argwhere(np.sum(ct.pixel_array, axis=1) == 0).reshape(-1)\n",
    "    image[zero_rows, :] = -1000 - np.int16(intercept)\n",
    "    image[:, zero_cols] = -1000 - np.int16(intercept)\n",
    "    \n",
    "    # convert to HU\n",
    "    if slope != 1:\n",
    "        image = (slope * image.astype(np.float64)).astype(np.int16)\n",
    "    image += np.int16(intercept)\n",
    "    \n",
    "    # convert ouside pixel-values to air:\n",
    "    # I'm using <= -1000 to be sure that other defaults are captured as well\n",
    "    image[image <= -1000] = -1000\n",
    "    \n",
    "    return ct, image\n",
    "\n",
    "def crop(image, center, size):\n",
    "    return image.copy()[\n",
    "        center[0] - size[0] // 2:center[0] + size[0] // 2\n",
    "    ][:, center[1] - size[1] // 2:center[1] + size[1] // 2]\n",
    "\n",
    "transformations_in_train = defaultdict(lambda: lambda x: x, {\n",
    "    'ID00014637202177757139317': lambda x: crop(x, (x.shape[0] // 2, x.shape[1] // 2), (512, 512)),\n",
    "    'ID00067637202189903532242': lambda x: crop(x, (x.shape[0] // 2, x.shape[1] // 2), (512, 512)),\n",
    "    'ID00086637202203494931510': lambda x: crop(x, (x.shape[0] // 2, x.shape[1] // 2), (512, 512)),\n",
    "    'ID00094637202205333947361': lambda x: crop(x, (x.shape[0] // 2, x.shape[1] // 2), (512, 512)),\n",
    "    'ID00122637202216437668965': lambda x: crop(x, (x.shape[0] // 2, x.shape[1] // 2), (512, 512)),\n",
    "    'ID00240637202264138860065': lambda x: crop(x, (x.shape[0] // 2, x.shape[1] // 2), (512, 512)),\n",
    "    'ID00419637202311204720264': lambda x: crop(x, (x.shape[0] // 2, x.shape[1] // 2), (512, 512))\n",
    "})\n",
    "\n",
    "# # images that needs transformation in train set:\n",
    "# '''\n",
    "#     ID00115637202211874187958 1302 1302\n",
    "#     ID00288637202279148973731 632 632\n",
    "#     ID00358637202295388077032 632 632 \n",
    "#     ID00009637202177434476278 768 768\n",
    "#     ID00015637202177877247924 768 768\n",
    "#     ID00025637202179541264076 768 768\n",
    "#     ID00026637202179561894768 768 768\n",
    "#     ID00027637202179689871102 768 768\n",
    "#     ID00038637202182690843176 768 768\n",
    "#     ID00042637202184406822975 768 768\n",
    "#     ID00078637202199415319443 768 768\n",
    "#     ID00082637202201836229724 768 768\n",
    "#     ID00089637202204675567570 768 768\n",
    "#     ID00105637202208831864134 768 768\n",
    "#     ID00108637202209619669361 768 768\n",
    "#     ID00110637202210673668310 768 768\n",
    "#     ID00128637202219474716089 768 768\n",
    "#     ID00129637202219868188000 768 768\n",
    "#     ID00132637202222178761324 768 768\n",
    "#     ID00169637202238024117706 768 768\n",
    "#     ID00173637202238329754031 768 768\n",
    "#     ID00183637202241995351650 768 768\n",
    "#     ID00214637202257820847190 768 768\n",
    "#     ID00216637202257988213445 768 768\n",
    "#     ID00242637202264759739921 768 768\n",
    "#     ID00248637202266698862378 768 768\n",
    "#     ID00285637202278913507108 768 768\n",
    "#     ID00290637202279304677843 768 768\n",
    "#     ID00291637202279398396106 768 768\n",
    "#     ID00309637202282195513787 768 768\n",
    "#     ID00343637202287577133798 768 768\n",
    "#     ID00344637202287684217717 768 768\n",
    "#     ID00351637202289476567312 768 768\n",
    "#     ID00367637202296290303449 768 768\n",
    "#     ID00388637202301028491611 768 768\n",
    "#     ID00414637202310318891556 768 768\n",
    "#     ID00421637202311550012437 768 768\n",
    "# '''\n",
    "\n",
    "transformations_in_test = defaultdict(lambda: lambda x: x, {\n",
    "    'ID00419637202311204720264': lambda x: crop(x, (x.shape[0] // 2, x.shape[1] // 2), (512, 512))\n",
    "})\n",
    "    \n",
    "# # images that needs transformation in test set:\n",
    "# '''\n",
    "#     ID00421637202311550012437 768 768\n",
    "# '''\n",
    "\n",
    "transformations = {\n",
    "    'test': transformations_in_test,\n",
    "    'train': transformations_in_train\n",
    "}\n",
    "\n",
    "def int16touint8(image):\n",
    "    result = image.copy().astype(np.int16)\n",
    "    result = result - result.min() + 10\n",
    "    result = result / (result.max() + 10)\n",
    "    return (result * 255.0).astype(np.uint8)\n",
    "\n",
    "def segmentate_patient(mode, patient_n):\n",
    "    base_path = os.path.join('./data', mode)\n",
    "    patient = sorted(os.listdir(base_path))[patient_n]\n",
    "    patient_path = os.path.join(base_path, patient)\n",
    "    \n",
    "    all_images, all_lungs, all_residuals, all_masks = [], [], [], []\n",
    "    meta_data = {\n",
    "        'InstanceNumber': [], 'SliceLocation': [], 'SliceThickness': [], 'PixelSpacing': [], 'PatientPosition': []\n",
    "    }\n",
    "    for idx, ct_name in enumerate(sorted(os.listdir(patient_path), key=lambda x: int(x.split('.')[0]))):\n",
    "        ct_path = os.path.join(patient_path, ct_name)\n",
    "        ct, ct_image = transform_to_hu(dcmread(ct_path))\n",
    "        ct_image = transformations[mode][patient](ct_image)\n",
    "        all_images.append(ct_image)\n",
    "        \n",
    "        lungs, residual, mask = segment_lungs(ct_image, patient_n, display=False)\n",
    "        \n",
    "        all_lungs.append(lungs)\n",
    "        all_residuals.append(residual)        \n",
    "        all_masks.append(mask)\n",
    "        \n",
    "        for key in meta_data.keys():\n",
    "            meta_data[key].append(getkey(ct, key))\n",
    "            \n",
    "    return all_images, all_lungs, all_residuals, all_masks, meta_data\n",
    "\n",
    "def merge(all_lungs, all_residuals, meta_data):\n",
    "    def _issorted(_array):\n",
    "        return np.all(_array[:-1] <= _array[1:]) or np.all(_array[:-1] >= _array[1:])\n",
    "    \n",
    "    SliceLocations = np.array(meta_data['SliceLocation'])\n",
    "    InstanceNumbers = np.array(meta_data['InstanceNumber'])\n",
    "    \n",
    "#     assert _issorted(SliceLocations)\n",
    "#     assert _issorted(InstanceNumbers)\n",
    "    \n",
    "    return np.stack(all_lungs), np.stack(all_residuals)\n",
    "\n",
    "def _get_max_quantile(_array, _thresh=0.9):\n",
    "    sorted_array = np.sort(_array)[::-1]\n",
    "    thresh_idx =  np.argwhere((np.cumsum(sorted_array) / np.sum(_array) > _thresh)).reshape(-1)[0]\n",
    "    return sorted_array[thresh_idx]\n",
    "\n",
    "def segment_lungs(image, patient_n, display=False):\n",
    "    def _contour_border_distance(_contour, shape):\n",
    "        _distance = 2 * shape[0]\n",
    "        _vdistance = 2 * shape[0]\n",
    "        _hdistance = 2 * shape[0]\n",
    "        for (point, ) in _contour:\n",
    "            # image[point[1], point[0]]\n",
    "            _distance = min(_distance, point[0], point[1], shape[1] - point[0], shape[0] - point[1])\n",
    "            _vdistance = min(_vdistance, point[1], shape[0] - point[1])\n",
    "            _hdistance = min(_hdistance, point[0], shape[1] - point[0])\n",
    "        return _distance, _vdistance, _hdistance\n",
    "    \n",
    "    def _filter_contours(_mask):\n",
    "        # Find all segments on the mask\n",
    "        contours, hierarchy = cv2.findContours(_mask.astype(np.uint8), 1, 2)\n",
    "        if len(contours) == 0:\n",
    "            return _mask\n",
    "        \n",
    "        # Evaluate some statistics for each segment like area, perimeter, shape of bounding box, distance to borders\n",
    "        countours_metrics = []\n",
    "        for contour in contours:\n",
    "            ((_, _), (horizontal_range, vertical_range), _) = cv2.minAreaRect(contour)\n",
    "\n",
    "            countours_metrics.append(\n",
    "                [\n",
    "                    horizontal_range, vertical_range, \n",
    "                    cv2.arcLength(contour, True), cv2.contourArea(contour), \n",
    "                    _contour_border_distance(contour, image.shape)\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        # If a perimeter to small -- drop segment\n",
    "        perimeter_thresh_1 = 2 * (2 * (_mask.shape[0] / 512.0) + 2 * (_mask.shape[1] / 512.0))\n",
    "        # If a perimeter less than 10-th quantile -- drop segment\n",
    "        perimeter_thresh_2 = np.quantile([_[2] for _ in countours_metrics], 0.1) if len(countours_metrics) > 7 else 0.0\n",
    "        perimeter_thresh = max(perimeter_thresh_1, perimeter_thresh_2)\n",
    "\n",
    "        # If an area to small -- drop segment\n",
    "        area_thresh_1 = 6 * 6 * (_mask.shape[0] / 512.0)  * (_mask.shape[1] / 512.0)\n",
    "        # If anarea less than 10-th quantile -- drop segment\n",
    "        area_thresh_2 = np.quantile([_[3] for _ in countours_metrics], 0.1) if len(countours_metrics) > 7 else 0.0\n",
    "        # Save the lagrest segments -- segments that overlap more than 95% of area of all segments\n",
    "        area_thresh_3 = _get_max_quantile([_[3] for _ in countours_metrics], 0.95)\n",
    "        area_thresh = max(area_thresh_1, area_thresh_2, area_thresh_3)\n",
    "        \n",
    "        # If a segment too close to the top or bottom border -- drop segment\n",
    "        vdistance_to_border_thresh = 30.0 * (_mask.shape[0] / 512.0)\n",
    "        # If a segment too close to the left or right border -- drop segment\n",
    "        hdistance_to_border_thresh = 3.0 * (_mask.shape[1] / 512.0)\n",
    "        \n",
    "        for contour, (horizontal_range, vertical_range, perimeter, area, distances) in zip(contours, countours_metrics):\n",
    "            distance, vdistance, hdistance = distances\n",
    "            if_small_area = area < area_thresh\n",
    "            if_small_high = vertical_range < 2.0\n",
    "            if_small_width = horizontal_range < 2.0\n",
    "            if_small_perimeter = perimeter < perimeter_thresh\n",
    "            if_too_close_to_vborder = vdistance < vdistance_to_border_thresh\n",
    "            if_too_close_to_hborder = hdistance < hdistance_to_border_thresh\n",
    "            # If a segment too wide in compare to its height -- drop segment \n",
    "            if_too_long_1 = max(horizontal_range / vertical_range, vertical_range / horizontal_range) > 7.5\n",
    "            # If a segment too wide and too flat -- drop segment \n",
    "            if_too_long_2 = horizontal_range > 0.5 * _mask.shape[0] and vertical_range < 0.15 * _mask.shape[1]\n",
    "            # If a segment really too wide -- drope segment\n",
    "            if_too_long_3 = horizontal_range > 0.87 * _mask.shape[0] or vertical_range > 0.87 * _mask.shape[1]\n",
    "            \n",
    "            if (\n",
    "                if_small_area or \n",
    "                if_small_high or \n",
    "                if_small_width or \n",
    "                if_small_perimeter or\n",
    "                if_too_close_to_vborder or\n",
    "                if_too_close_to_hborder or\n",
    "                if_too_long_1 or\n",
    "                if_too_long_2 or \n",
    "                if_too_long_3\n",
    "            ):        \n",
    "                _mask = cv2.drawContours(\n",
    "                    _mask.astype(np.uint8), [contour],\n",
    "                    contourIdx=-1, color=(0), thickness=-1).astype(np.bool)\n",
    "                if display:\n",
    "                    print('Remove: ', (horizontal_range, vertical_range, perimeter, area, distances))\n",
    "                    table = tabulate.tabulate([[\n",
    "                        if_small_area,\n",
    "                        if_small_high,\n",
    "                        if_small_width,\n",
    "                        if_small_perimeter,\n",
    "                        if_too_close_to_vborder,\n",
    "                        if_too_close_to_hborder,\n",
    "                        if_too_long_1,\n",
    "                        if_too_long_2,\n",
    "                        if_too_long_3\n",
    "                    ]], headers=[\n",
    "                        'smll_area',\n",
    "                        'smll_high',\n",
    "                        'smll_width',\n",
    "                        'smll_perimeter',\n",
    "                        'close_to_vbrd',\n",
    "                        'close_to_hbrd',\n",
    "                        'long_1',\n",
    "                        'long_2',\n",
    "                        'long_3'\n",
    "                    ])\n",
    "                    print(table)\n",
    "            else:\n",
    "                if display:\n",
    "                    print('Do not remove: ', (horizontal_range, vertical_range, perimeter, area, distances))\n",
    "        \n",
    "        return _mask\n",
    "\n",
    "    thresh = -700\n",
    "    thresh_mask = image <= thresh\n",
    "    \n",
    "    if patient_n >= 26:\n",
    "        # Remove small holes and disconnections (Fixes patient №26. Need to check first 26 patients)\n",
    "        # Bad for some patients with № < 26\n",
    "        kernel = skimage.morphology.disk(3)\n",
    "        thresh_mask = skimage.morphology.binary_closing(thresh_mask, selem=kernel)\n",
    "    \n",
    "    thresh_mask = skimage.segmentation.clear_border(thresh_mask)\n",
    "\n",
    "    # Smooth image with\n",
    "    lungs_mask = skimage.filters.median(thresh_mask)\n",
    "    \n",
    "    # Remove small holes and disconnections\n",
    "    kernel = skimage.morphology.disk(7)\n",
    "    lungs_mask = skimage.morphology.binary_closing(lungs_mask, selem=kernel)\n",
    "    \n",
    "    # Expand verticaly\n",
    "    kernel = np.ones([3, 1], dtype=np.bool)\n",
    "    lungs_mask = skimage.morphology.dilation(lungs_mask, selem=kernel)\n",
    "    # Expand horizontaly\n",
    "    kernel = np.ones([1, 7], dtype=np.bool)\n",
    "    lungs_mask = skimage.morphology.dilation(lungs_mask, selem=kernel)\n",
    "    lungs_mask = skimage.morphology.dilation(lungs_mask, selem=kernel)\n",
    "    lungs_mask = skimage.morphology.dilation(lungs_mask, selem=kernel)\n",
    "    \n",
    "    # Remove some garbage\n",
    "    lungs_mask = _filter_contours(lungs_mask)\n",
    "    \n",
    "    # Squeeze image horizontaly back\n",
    "    kernel = np.ones([1, 7], dtype=np.bool)\n",
    "    lungs_mask = skimage.morphology.erosion(lungs_mask, selem=kernel)\n",
    "    lungs_mask = skimage.morphology.erosion(lungs_mask, selem=kernel)\n",
    "    lungs_mask = skimage.morphology.erosion(lungs_mask, selem=kernel)\n",
    "    # Squeeze image verticaly back\n",
    "    kernel = np.ones([3, 1], dtype=np.bool)\n",
    "    lungs_mask = skimage.morphology.erosion(lungs_mask, selem=kernel)\n",
    "    \n",
    "    # Fixes patient №55 (works well for all patients)\n",
    "    kernel = np.ones([3, 1], dtype=np.bool)\n",
    "    lungs_mask = skimage.morphology.erosion(lungs_mask, selem=kernel)\n",
    "    # Remove small holes\n",
    "    lungs_mask = scipy.ndimage.binary_fill_holes(lungs_mask)\n",
    "    # Fixes patient №55 (works well for all patients)\n",
    "    kernel = np.ones([3, 1], dtype=np.bool)\n",
    "    lungs_mask = skimage.morphology.dilation(lungs_mask, selem=kernel)\n",
    "    \n",
    "    lungs = lungs_mask * image\n",
    "    residual = (1.0 - lungs_mask) * image\n",
    "    \n",
    "    lungs[lungs == 0] = np.min(image)\n",
    "    residual[residual == 0] = np.min(image)\n",
    "    \n",
    "    if display:\n",
    "        fig, ax = plt.subplots(1, 5, figsize=(20, 15))\n",
    "\n",
    "        ax[0].set_title('HU Image')\n",
    "        ax[0].imshow(image, cmap='gray')\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].set_title('Thresholded Image')\n",
    "        ax[1].imshow(thresh_mask, cmap='gray')\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        ax[2].set_title('Lungs Mask')\n",
    "        ax[2].imshow(lungs_mask)\n",
    "        ax[2].axis('off')\n",
    "\n",
    "        ax[3].set_title('Lungs Image')\n",
    "        ax[3].imshow(lungs)\n",
    "        ax[3].axis('off')\n",
    "        \n",
    "        ax[4].set_title('Residual Image')\n",
    "        ax[4].imshow(residual)\n",
    "        ax[4].axis('off')\n",
    "    \n",
    "    return lungs, residual, lungs_mask\n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "    'base_threshold': -700,\n",
    "    'min_vperimeter': 2, 'min_hperimeter': 2,\n",
    "    'min_varea': 6, 'min_harea': 6,\n",
    "    'min_quantile_contours': 7,\n",
    "    'perimeter_quantile': 0.1,\n",
    "    'area_quantile': 0.1, 'area_max_quantile': 0.95,\n",
    "    'min_vdistance': 30.0, 'min_hdistance': 3.0,\n",
    "    'min_hv_ratio': 7.5\n",
    "}\n",
    "\n",
    "'''\n",
    "    ID00026637202179561894768 №11 -- strange images\n",
    "    ID00076637202199015035026 №30 -- first 9 images need to be fixed\n",
    "    ID00078637202199415319443 №32 -- two breathes\n",
    "    ID00123637202217151272140 №51 -- very bag segmentation\n",
    "    ID00126637202218610655908 №54 -- first 1 images need to be fixed\n",
    "    ID00128637202219474716089 №56 -- strange images\n",
    "    ID00129637202219868188000 №57 -- very bag segmentation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mode, patient_n = 'train', 32\n",
    "# all_images, all_lungs, all_residuals, all_masks, meta_data = segmentate_patient(mode, patient_n)\n",
    "# lungs_3d, residuals_3d = merge(all_lungs, all_residuals, meta_data)\n",
    "\n",
    "# print(f'{mode} patient {patient}. number of slices: {len(all_images)}')\n",
    "\n",
    "# _, __, ___ = segment_lungs(all_images[0], patient_n, display=True)\n",
    "# _, __, ___ = segment_lungs(all_images[len(all_images) // 2], patient_n, display=True)\n",
    "# _, __, ___ = segment_lungs(all_images[-1], patient_n, display=True)\n",
    "# # _, __, ___ = segment_lungs(all_images[24], patient_n, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n_samples = len(all_images) // 2 if len(all_images) > 200 else len(all_images) - 3\n",
    "# sample_slices(all_images, n_samples, masks=all_masks, alpha=.2, cmap_name='gray')\n",
    "# # sample_slices(all_lungs, 28, masks=None, alpha=0.2, cmap_name=None)\n",
    "# # sample_slices(all_images[:28], 28, masks=None, alpha=0.2, cmap_name=None)\n",
    "# # sample_slices(all_masks[:28], 28, masks=None, alpha=0.2, cmap_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = subplots_3d(1, 2, figsize=(15, 7))\n",
    "\n",
    "# plot_3d(axes[0], lungs_3d, stride=1, threshold=-900)\n",
    "# plot_3d(axes[1], residuals_3d, stride=1, threshold=700)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(image, SliceThickness, PixelSpacing, new_spacing=(1.0, 1.0, 1.0)):\n",
    "    # Determine current pixel spacing\n",
    "    spacing = np.array([SliceThickness] + list(PixelSpacing), dtype=np.float32)\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
    "    \n",
    "    return image, new_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lungs_3d_resampled, new_spacing = resample(lungs_3d, meta_data['SliceThickness'][-1], meta_data['PixelSpacing'][-1])\n",
    "\n",
    "# lungs_3d.shape, lungs_3d_resampled.shape\n",
    "\n",
    "# sample_slices(lungs_3d_resampled, 10)\n",
    "\n",
    "# gif_writer = imageio.get_writer('./test.gif', mode='I', duration=0.1) \n",
    "# for _ in tqdm.tqdm(range(1, 60)):\n",
    "#     ct, ct_image = transform_to_hu(dcmread(os.path.join('./data/train', 'ID00421637202311550012437', f'{_}.dcm')))\n",
    "#     lungs, lungs_mask = segment_lungs(ct_image)\n",
    "#     gif_writer.append_data(np.hstack([int16touint8(ct_image), int16touint8(lungs), int16touint8(lungs_mask)]))\n",
    "\n",
    "# plt.imshow(lung_segment(ct_image)[0]); plt.show()\n",
    "# plt.imshow(lung_segment(ct_image)[1]); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mode = 'train'\n",
    "# base_path = os.path.join('./data', mode)\n",
    "\n",
    "# counter = defaultdict(int)\n",
    "# for patient in tqdm.tqdm(os.listdir(base_path)):\n",
    "#     patient_counter = defaultdict(int)\n",
    "#     patient_path = os.path.join(base_path, patient)\n",
    "#     for idx, ct_name in enumerate(sorted(os.listdir(patient_path), key=lambda x: int(x.split('.')[0]))):\n",
    "#         if idx > -1:\n",
    "#             ct_path = os.path.join(patient_path, ct_name)\n",
    "#             ct, ct_image = transform_to_hu(dcmread(ct_path))\n",
    "#             ct_image = transformations[mode][patient](ct_image)\n",
    "#             patient_counter[(getkey(ct, 'PixelSpacing')[0])] += 1\n",
    "            \n",
    "#             del ct\n",
    "    \n",
    "#     for key in patient_counter.keys():\n",
    "#         counter[key] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(list(counter.keys()), bins=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# test_data = pd.read_csv('./data/test.csv')\n",
    "# train_data = pd.read_csv('./data/train.csv')\n",
    "\n",
    "# train_data\n",
    "\n",
    "# train_patients_data = defaultdict(list)\n",
    "\n",
    "# for row in train_data.iterrows():\n",
    "#     train_patients_data[row[1]['Patient']].append((\n",
    "#         int(row[1]['Weeks']), \n",
    "#         float(row[1]['FVC']),\n",
    "#         float(row[1]['Percent']),\n",
    "#         int(row[1]['Age']),\n",
    "#         row[1]['Sex'],\n",
    "#         row[1]['SmokingStatus']\n",
    "#     ))\n",
    "\n",
    "# for patient, values in train_patients_data.items():\n",
    "#     weeks, fvcs, percents, ages, sex, smoking = zip(*values)\n",
    "#     plt.plot(weeks, sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_CT_patient(mode, patient_n):\n",
    "#     base_path = os.path.join(IMAGE_PATH, mode)\n",
    "#     patient = sorted(os.listdir(base_path))[patient_n]\n",
    "#     patient_path = os.path.join(base_path, patient)\n",
    "    \n",
    "#     all_images = []  # , all_lungs, all_residuals, all_masks = [], [], [], []\n",
    "#     meta_data = {\n",
    "#         'InstanceNumber': [], 'SliceLocation': [], 'SliceThickness': [], 'PixelSpacing': [], 'PatientPosition': []\n",
    "#     }\n",
    "#     for idx, ct_name in enumerate(sorted(os.listdir(patient_path), key=lambda x: int(x.split('.')[0]))):\n",
    "#         ct_path = os.path.join(patient_path, ct_name)\n",
    "#         ct, ct_image = transform_to_hu(dcmread(ct_path))\n",
    "#         ct_image = transformations[mode][patient](ct_image)\n",
    "#         all_images.append(ct_image)\n",
    "        \n",
    "# #         lungs, residual, mask = segment_lungs(ct_image, patient_n, display=False)\n",
    "        \n",
    "# #         all_lungs.append(lungs)\n",
    "# #         all_residuals.append(residual)        \n",
    "# #         all_masks.append(mask)\n",
    "        \n",
    "#         for key in meta_data.keys():\n",
    "#             meta_data[key].append(getkey(ct, key))\n",
    "            \n",
    "#     return all_images, meta_data  # all_lungs, all_residuals, all_masks, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_images, meta_data = get_CT_patient('train', 0)\n",
    "\n",
    "# torch.stack(tuple(map(torch.tensor, all_images))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sorted(os.listdir(base_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient = sorted(os.listdir(base_path))[patient_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SHAPE = (64, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataset(Dataset):\n",
    "    \"\"\"CT dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode, wanted_shape=DEFAULT_SHAPE):  # , transform=None):  # csv_file\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "#         self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.base_path = os.path.join(IMAGE_PATH, mode)\n",
    "        self.df = pd.read_csv(self.base_path + '.csv')\n",
    "        self.patients = sorted(os.listdir(self.base_path))\n",
    "        self.wanted_shape = wanted_shape\n",
    "        self.mode = mode\n",
    "#         self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patients)\n",
    "\n",
    "    def __getitem__(self, patient_n):\n",
    "        if torch.is_tensor(patient_n):\n",
    "            patient_n = patient_n.tolist()\n",
    "\n",
    "        patient = self.patients[patient_n]\n",
    "        patient_path = os.path.join(self.base_path, patient)\n",
    "        \n",
    "#         print(patient)\n",
    "        patient_df = self.df[self.df.Patient == patient]\n",
    "        min_week = patient_df.Weeks.min()\n",
    "        base_FVC = patient_df.FVC[patient_df.Weeks == min_week].values\n",
    "        base_df = patient_df[patient_df.Weeks == min_week]\n",
    "        if len(base_FVC) != 1:\n",
    "            print('More than 1 FVC measurment on min week')\n",
    "        base_FVC = base_FVC[0]\n",
    "        rest_df = patient_df[patient_df.Weeks != min_week]\n",
    "#         print(patient, min_week, base_FVC)\n",
    "\n",
    "        all_images = []  # , all_lungs, all_residuals, all_masks = [], [], [], []\n",
    "        meta_data = {\n",
    "            'InstanceNumber': [], 'SliceLocation': [], 'SliceThickness': [], 'PixelSpacing': [], 'PatientPosition': []\n",
    "        }\n",
    "        for idx, ct_name in enumerate(sorted(os.listdir(patient_path), key=lambda x: int(x.split('.')[0]))):\n",
    "            ct_path = os.path.join(patient_path, ct_name)\n",
    "            ct, ct_image = transform_to_hu(dcmread(ct_path))\n",
    "            ct_image = transformations[self.mode][patient](ct_image)\n",
    "            all_images.append(ct_image)\n",
    "\n",
    "#             lungs, residual, mask = segment_lungs(ct_image, patient_n, display=False)\n",
    "\n",
    "#             all_lungs.append(lungs)\n",
    "#             all_residuals.append(residual)        \n",
    "#             all_masks.append(mask)\n",
    "\n",
    "            for key in meta_data.keys():\n",
    "                meta_data[key].append(getkey(ct, key))\n",
    "\n",
    "#         all_images, meta_data  # all_lungs, all_residuals, all_masks, \n",
    "\n",
    "        images = np.array(all_images)\n",
    "        factor = [w / float(f) for w, f in zip(self.wanted_shape, images.shape)]\n",
    "        resized = nd.interpolation.zoom(images, zoom=factor)\n",
    "        image3D = torch.from_numpy(resized).unsqueeze(0).float()\n",
    "\n",
    "#         if self.transform:\n",
    "#             image3D = self.transform(image3D)\n",
    "        \n",
    "        return {\n",
    "            'image': image3D,\n",
    "#             'base_df': base_df,\n",
    "#             'rest_df': rest_df,\n",
    "#             'meta_data': meta_data\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "#         img_name = os.path.join(self.root_dir,\n",
    "#                                 self.landmarks_frame.iloc[idx, 0])\n",
    "#         image = io.imread(img_name)\n",
    "#         landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "#         landmarks = np.array([landmarks])\n",
    "#         landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "#         sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "#         return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CTDataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 256, 256])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[train_df.Patient == 'ID00009637202177434476278']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 256, 256])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# model = EfficientNet.from_pretrained('efficientnet-b0', in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1, 300):\n",
    "#     tmp = torch.randn(2, 1, i, 32)\n",
    "#     res = model.extract_features(tmp).shape\n",
    "#     print(i, res[2])\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 2}, in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "├─Conv3dStaticSamePadding: 1-1                     --\n",
      "|    └─ZeroPad2d: 2-1                              --\n",
      "├─BatchNorm3d: 1-2                                 64\n",
      "├─ModuleList: 1-3                                  --\n",
      "|    └─MBConvBlock3D: 2-2                          --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-1           864\n",
      "|    |    └─BatchNorm3d: 3-2                       64\n",
      "|    |    └─Conv3dStaticSamePadding: 3-3           264\n",
      "|    |    └─Conv3dStaticSamePadding: 3-4           288\n",
      "|    |    └─Conv3dStaticSamePadding: 3-5           512\n",
      "|    |    └─BatchNorm3d: 3-6                       32\n",
      "|    |    └─MemoryEfficientSwish: 3-7              --\n",
      "|    └─MBConvBlock3D: 2-3                          --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-8           1,536\n",
      "|    |    └─BatchNorm3d: 3-9                       192\n",
      "|    |    └─Conv3dStaticSamePadding: 3-10          2,592\n",
      "|    |    └─BatchNorm3d: 3-11                      192\n",
      "|    |    └─Conv3dStaticSamePadding: 3-12          388\n",
      "|    |    └─Conv3dStaticSamePadding: 3-13          480\n",
      "|    |    └─Conv3dStaticSamePadding: 3-14          2,304\n",
      "|    |    └─BatchNorm3d: 3-15                      48\n",
      "|    |    └─MemoryEfficientSwish: 3-16             --\n",
      "|    └─MBConvBlock3D: 2-4                          --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-17          3,456\n",
      "|    |    └─BatchNorm3d: 3-18                      288\n",
      "|    |    └─Conv3dStaticSamePadding: 3-19          3,888\n",
      "|    |    └─BatchNorm3d: 3-20                      288\n",
      "|    |    └─Conv3dStaticSamePadding: 3-21          870\n",
      "|    |    └─Conv3dStaticSamePadding: 3-22          1,008\n",
      "|    |    └─Conv3dStaticSamePadding: 3-23          3,456\n",
      "|    |    └─BatchNorm3d: 3-24                      48\n",
      "|    |    └─MemoryEfficientSwish: 3-25             --\n",
      "|    └─MBConvBlock3D: 2-5                          --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-26          3,456\n",
      "|    |    └─BatchNorm3d: 3-27                      288\n",
      "|    |    └─Conv3dStaticSamePadding: 3-28          18,000\n",
      "|    |    └─BatchNorm3d: 3-29                      288\n",
      "|    |    └─Conv3dStaticSamePadding: 3-30          870\n",
      "|    |    └─Conv3dStaticSamePadding: 3-31          1,008\n",
      "|    |    └─Conv3dStaticSamePadding: 3-32          5,760\n",
      "|    |    └─BatchNorm3d: 3-33                      80\n",
      "|    |    └─MemoryEfficientSwish: 3-34             --\n",
      "|    └─MBConvBlock3D: 2-6                          --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-35          9,600\n",
      "|    |    └─BatchNorm3d: 3-36                      480\n",
      "|    |    └─Conv3dStaticSamePadding: 3-37          30,000\n",
      "|    |    └─BatchNorm3d: 3-38                      480\n",
      "|    |    └─Conv3dStaticSamePadding: 3-39          2,410\n",
      "|    |    └─Conv3dStaticSamePadding: 3-40          2,640\n",
      "|    |    └─Conv3dStaticSamePadding: 3-41          9,600\n",
      "|    |    └─BatchNorm3d: 3-42                      80\n",
      "|    |    └─MemoryEfficientSwish: 3-43             --\n",
      "|    └─MBConvBlock3D: 2-7                          --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-44          9,600\n",
      "|    |    └─BatchNorm3d: 3-45                      480\n",
      "|    |    └─Conv3dStaticSamePadding: 3-46          6,480\n",
      "|    |    └─BatchNorm3d: 3-47                      480\n",
      "|    |    └─Conv3dStaticSamePadding: 3-48          2,410\n",
      "|    |    └─Conv3dStaticSamePadding: 3-49          2,640\n",
      "|    |    └─Conv3dStaticSamePadding: 3-50          19,200\n",
      "|    |    └─BatchNorm3d: 3-51                      160\n",
      "|    |    └─MemoryEfficientSwish: 3-52             --\n",
      "|    └─MBConvBlock3D: 2-8                          --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-53          38,400\n",
      "|    |    └─BatchNorm3d: 3-54                      960\n",
      "|    |    └─Conv3dStaticSamePadding: 3-55          12,960\n",
      "|    |    └─BatchNorm3d: 3-56                      960\n",
      "|    |    └─Conv3dStaticSamePadding: 3-57          9,620\n",
      "|    |    └─Conv3dStaticSamePadding: 3-58          10,080\n",
      "|    |    └─Conv3dStaticSamePadding: 3-59          38,400\n",
      "|    |    └─BatchNorm3d: 3-60                      160\n",
      "|    |    └─MemoryEfficientSwish: 3-61             --\n",
      "|    └─MBConvBlock3D: 2-9                          --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-62          38,400\n",
      "|    |    └─BatchNorm3d: 3-63                      960\n",
      "|    |    └─Conv3dStaticSamePadding: 3-64          12,960\n",
      "|    |    └─BatchNorm3d: 3-65                      960\n",
      "|    |    └─Conv3dStaticSamePadding: 3-66          9,620\n",
      "|    |    └─Conv3dStaticSamePadding: 3-67          10,080\n",
      "|    |    └─Conv3dStaticSamePadding: 3-68          38,400\n",
      "|    |    └─BatchNorm3d: 3-69                      160\n",
      "|    |    └─MemoryEfficientSwish: 3-70             --\n",
      "|    └─MBConvBlock3D: 2-10                         --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-71          38,400\n",
      "|    |    └─BatchNorm3d: 3-72                      960\n",
      "|    |    └─Conv3dStaticSamePadding: 3-73          60,000\n",
      "|    |    └─BatchNorm3d: 3-74                      960\n",
      "|    |    └─Conv3dStaticSamePadding: 3-75          9,620\n",
      "|    |    └─Conv3dStaticSamePadding: 3-76          10,080\n",
      "|    |    └─Conv3dStaticSamePadding: 3-77          53,760\n",
      "|    |    └─BatchNorm3d: 3-78                      224\n",
      "|    |    └─MemoryEfficientSwish: 3-79             --\n",
      "|    └─MBConvBlock3D: 2-11                         --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-80          75,264\n",
      "|    |    └─BatchNorm3d: 3-81                      1,344\n",
      "|    |    └─Conv3dStaticSamePadding: 3-82          84,000\n",
      "|    |    └─BatchNorm3d: 3-83                      1,344\n",
      "|    |    └─Conv3dStaticSamePadding: 3-84          18,844\n",
      "|    |    └─Conv3dStaticSamePadding: 3-85          19,488\n",
      "|    |    └─Conv3dStaticSamePadding: 3-86          75,264\n",
      "|    |    └─BatchNorm3d: 3-87                      224\n",
      "|    |    └─MemoryEfficientSwish: 3-88             --\n",
      "|    └─MBConvBlock3D: 2-12                         --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-89          75,264\n",
      "|    |    └─BatchNorm3d: 3-90                      1,344\n",
      "|    |    └─Conv3dStaticSamePadding: 3-91          84,000\n",
      "|    |    └─BatchNorm3d: 3-92                      1,344\n",
      "|    |    └─Conv3dStaticSamePadding: 3-93          18,844\n",
      "|    |    └─Conv3dStaticSamePadding: 3-94          19,488\n",
      "|    |    └─Conv3dStaticSamePadding: 3-95          75,264\n",
      "|    |    └─BatchNorm3d: 3-96                      224\n",
      "|    |    └─MemoryEfficientSwish: 3-97             --\n",
      "|    └─MBConvBlock3D: 2-13                         --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-98          75,264\n",
      "|    |    └─BatchNorm3d: 3-99                      1,344\n",
      "|    |    └─Conv3dStaticSamePadding: 3-100         84,000\n",
      "|    |    └─BatchNorm3d: 3-101                     1,344\n",
      "|    |    └─Conv3dStaticSamePadding: 3-102         18,844\n",
      "|    |    └─Conv3dStaticSamePadding: 3-103         19,488\n",
      "|    |    └─Conv3dStaticSamePadding: 3-104         129,024\n",
      "|    |    └─BatchNorm3d: 3-105                     384\n",
      "|    |    └─MemoryEfficientSwish: 3-106            --\n",
      "|    └─MBConvBlock3D: 2-14                         --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-107         221,184\n",
      "|    |    └─BatchNorm3d: 3-108                     2,304\n",
      "|    |    └─Conv3dStaticSamePadding: 3-109         144,000\n",
      "|    |    └─BatchNorm3d: 3-110                     2,304\n",
      "|    |    └─Conv3dStaticSamePadding: 3-111         55,344\n",
      "|    |    └─Conv3dStaticSamePadding: 3-112         56,448\n",
      "|    |    └─Conv3dStaticSamePadding: 3-113         221,184\n",
      "|    |    └─BatchNorm3d: 3-114                     384\n",
      "|    |    └─MemoryEfficientSwish: 3-115            --\n",
      "|    └─MBConvBlock3D: 2-15                         --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-116         221,184\n",
      "|    |    └─BatchNorm3d: 3-117                     2,304\n",
      "|    |    └─Conv3dStaticSamePadding: 3-118         144,000\n",
      "|    |    └─BatchNorm3d: 3-119                     2,304\n",
      "|    |    └─Conv3dStaticSamePadding: 3-120         55,344\n",
      "|    |    └─Conv3dStaticSamePadding: 3-121         56,448\n",
      "|    |    └─Conv3dStaticSamePadding: 3-122         221,184\n",
      "|    |    └─BatchNorm3d: 3-123                     384\n",
      "|    |    └─MemoryEfficientSwish: 3-124            --\n",
      "|    └─MBConvBlock3D: 2-16                         --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-125         221,184\n",
      "|    |    └─BatchNorm3d: 3-126                     2,304\n",
      "|    |    └─Conv3dStaticSamePadding: 3-127         144,000\n",
      "|    |    └─BatchNorm3d: 3-128                     2,304\n",
      "|    |    └─Conv3dStaticSamePadding: 3-129         55,344\n",
      "|    |    └─Conv3dStaticSamePadding: 3-130         56,448\n",
      "|    |    └─Conv3dStaticSamePadding: 3-131         221,184\n",
      "|    |    └─BatchNorm3d: 3-132                     384\n",
      "|    |    └─MemoryEfficientSwish: 3-133            --\n",
      "|    └─MBConvBlock3D: 2-17                         --\n",
      "|    |    └─Conv3dStaticSamePadding: 3-134         221,184\n",
      "|    |    └─BatchNorm3d: 3-135                     2,304\n",
      "|    |    └─Conv3dStaticSamePadding: 3-136         31,104\n",
      "|    |    └─BatchNorm3d: 3-137                     2,304\n",
      "|    |    └─Conv3dStaticSamePadding: 3-138         55,344\n",
      "|    |    └─Conv3dStaticSamePadding: 3-139         56,448\n",
      "|    |    └─Conv3dStaticSamePadding: 3-140         368,640\n",
      "|    |    └─BatchNorm3d: 3-141                     640\n",
      "|    |    └─MemoryEfficientSwish: 3-142            --\n",
      "├─Conv3dStaticSamePadding: 1-4                     --\n",
      "|    └─Identity: 2-18                              --\n",
      "├─BatchNorm3d: 1-5                                 2,560\n",
      "├─AdaptiveAvgPool3d: 1-6                           --\n",
      "├─Dropout: 1-7                                     --\n",
      "├─Linear: 1-8                                      2,562\n",
      "├─MemoryEfficientSwish: 1-9                        --\n",
      "===========================================================================\n",
      "Total params: 4,280,478\n",
      "Trainable params: 4,280,478\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(1,) + DEFAULT_SHAPE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.cuda()\n",
    "\n",
    "\n",
    "# inputs = torch.randn((1, 3, 200, 200, 200)).cuda()\n",
    "# labels = torch.tensor([0]).cuda()\n",
    "# test forward\n",
    "# num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet3D(\n",
       "  (_conv_stem): Conv3dStaticSamePadding(\n",
       "    1, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm3d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock3D(\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3, 3), stride=[1, 1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3, 3), stride=[2, 2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5, 5), stride=[2, 2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3, 3), stride=[2, 2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3, 3), stride=(1, 1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5, 5), stride=[1, 1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5, 5), stride=[2, 2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5, 5), stride=(1, 1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock3D(\n",
       "      (_expand_conv): Conv3dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv3dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3, 3), stride=[1, 1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm3d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv3dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv3dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1, 1), stride=(1, 1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv3dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm3d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv3dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm3d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.Size([1, 1, 64, 256, 256]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['image'].dtype, batch['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.extract_features(batch['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280, 2, 8, 8])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    x_tmp = torch.randn(1, 1, 300, 256, 256)\n",
    "    res = model.extract_features(x_tmp.to(device))\n",
    "    loss = res.sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(image, target_shape, SliceThickness, PixelSpacing):\n",
    "    factors = np.array(target_shape, dtype=np.float32) / np.array(image.shape, dtype=np.float32)\n",
    "    image = scipy.ndimage.interpolation.zoom(image, factors, mode='nearest')\n",
    "\n",
    "    # Determine current pixel spacing\n",
    "    spacing = np.array([SliceThickness] + list(PixelSpacing), dtype=np.float32)\n",
    "    new_spacing = spacing / factors\n",
    "\n",
    "    return image, new_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, efficient_net_number=0):\n",
    "        super().__init__()\n",
    "        self.model = EfficientNet3D.from_name(f\"efficientnet-b{efficient_net_number}\", in_channels=1)\n",
    "        # override_params={'num_classes': 2}\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0406, 0.0494]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SLICES = 64\n",
    "cur_slices = 900\n",
    "if cur_slices > 64:\n",
    "    tmp = np.linspace(0, cur_silces, NUM_SLICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 200, 200, 200])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.973\n",
      "[2] loss: 0.848\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(2):\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    print('[%d] loss: %.3f' % (epoch + 1, loss.item()))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-246-d875468caf7f>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-246-d875468caf7f>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    return torch.from_numpy(resized)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "mode = 'train'\n",
    "wanted_shape = DEFAULT_SHAPE  # (20, 256, 256)\n",
    "\n",
    "base_path = os.path.join(IMAGE_PATH, mode)\n",
    "for patient_n in range(len(os.listdir(base_path))):\n",
    "    all_images, meta_data = get_CT_patient(mode, patient_n)\n",
    "#     X = torch.stack(tuple(map(torch.tensor, all_images))).shape\n",
    "    images = np.array(all_images)\n",
    "    factor = [w / float(f) for w, f in zip(wanted_shape, images.shape)]\n",
    "    resized = nd.interpolation.zoom(images, zoom=factor)\n",
    "    return torch.from_numpy(resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms.Resize((20, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsfactor = [w / float(f) for w, f in zip(whole.shape, flash.shape)]\n",
    "downed = nd.interpolation.zoom(flash, zoom=dsfactor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function scipy.ndimage.interpolation.zoom(input, zoom, output=None, order=3, mode='constant', cval=0.0, prefilter=True)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.interpolation.zoom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
