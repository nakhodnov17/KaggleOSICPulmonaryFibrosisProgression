{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install sparse==0.7.0\n!pip install efficientnet_pytorch\n!pip install scipy==1.4.1\n!pip install torchio","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting sparse==0.7.0\n  Downloading sparse-0.7.0-py2.py3-none-any.whl (48 kB)\n\u001b[K     |████████████████████████████████| 48 kB 335 kB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: numpy>=1.13 in /opt/conda/lib/python3.7/site-packages (from sparse==0.7.0) (1.18.5)\nRequirement already satisfied: numba>=0.39 in /opt/conda/lib/python3.7/site-packages (from sparse==0.7.0) (0.48.0)\nRequirement already satisfied: scipy>=0.19 in /opt/conda/lib/python3.7/site-packages (from sparse==0.7.0) (1.4.1)\nRequirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /opt/conda/lib/python3.7/site-packages (from numba>=0.39->sparse==0.7.0) (0.31.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.39->sparse==0.7.0) (46.1.3.post20200325)\nInstalling collected packages: sparse\nSuccessfully installed sparse-0.7.0\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nCollecting efficientnet_pytorch\n  Downloading efficientnet_pytorch-0.7.0.tar.gz (20 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet_pytorch) (1.5.1)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (0.18.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (1.18.5)\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-py3-none-any.whl size=16035 sha256=521566f1f40d3c0b20760b21de51e9dbfd027a5f545ec30c0b7f3f24c44e8783\n  Stored in directory: /root/.cache/pip/wheels/b7/cc/0d/41d384b0071c6f46e542aded5f8571700ace4f1eb3f1591c29\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch\nSuccessfully installed efficientnet-pytorch-0.7.0\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: scipy==1.4.1 in /opt/conda/lib/python3.7/site-packages (1.4.1)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scipy==1.4.1) (1.18.5)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nCollecting torchio\n  Downloading torchio-0.17.46-py2.py3-none-any.whl (108 kB)\n\u001b[K     |████████████████████████████████| 108 kB 581 kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchio) (4.45.0)\nRequirement already satisfied: humanize in /opt/conda/lib/python3.7/site-packages (from torchio) (2.4.0)\nRequirement already satisfied: Click in /opt/conda/lib/python3.7/site-packages (from torchio) (7.1.1)\nRequirement already satisfied: SimpleITK<2 in /opt/conda/lib/python3.7/site-packages (from torchio) (1.2.4)\nRequirement already satisfied: torch>=1.1 in /opt/conda/lib/python3.7/site-packages (from torchio) (1.5.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchio) (1.18.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from torchio) (1.4.1)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from torchio) (0.6.0a0+35d732a)\nCollecting Python-Deprecated\n  Downloading Python-Deprecated-1.1.0.tar.gz (2.9 kB)\nRequirement already satisfied: nibabel in /opt/conda/lib/python3.7/site-packages (from torchio) (3.1.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.1->torchio) (0.18.2)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->torchio) (5.4.1)\nRequirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from nibabel->torchio) (20.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->nibabel->torchio) (1.14.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->nibabel->torchio) (2.4.7)\nBuilding wheels for collected packages: Python-Deprecated\n  Building wheel for Python-Deprecated (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for Python-Deprecated: filename=Python_Deprecated-1.1.0-py2.py3-none-any.whl size=3069 sha256=80284587e44dadfa89b4f9ec81db290625f7ff716045816cdae0e007767480b4\n  Stored in directory: /root/.cache/pip/wheels/e2/6a/3e/ebd9c3f8035615ea08f284613943124ea530d735d5c9f84528\nSuccessfully built Python-Deprecated\nInstalling collected packages: Python-Deprecated, torchio\nSuccessfully installed Python-Deprecated-1.1.0 torchio-0.17.46\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"import platform\nimport os\nfrom collections import namedtuple, defaultdict\n\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchio\n\n\nimport numpy as np\nimport pandas as pd\nimport sparse\n\nfrom efficientnet_pytorch import EfficientNet\n\nfrom sklearn.model_selection import train_test_split\n\n\nRUNNING_IN_KAGGLE = 'linux' in platform.platform().lower()\nIMAGE_PATH = \"../input/osic-pulmonary-fibrosis-progression/\" if RUNNING_IN_KAGGLE else '/Users/Macbook/datasets/KaggleOSICPulmonaryFibrosisProgression'\nPROCESSED_PATH = '../input/osic-processed/' if RUNNING_IN_KAGGLE else '/Users/Macbook/datasets/processed-data/'  # TODO: fix this line\n\ndtype = torch.float32\nUSE_GPU = True\nif USE_GPU and torch.cuda.is_available():\n    device = 'cuda:0'\nelse:\n    device = 'cpu'\ndevice = torch.device(device)","execution_count":2,"outputs":[{"output_type":"stream","text":"If you use TorchIO for your research, please cite the following paper:\nPérez-García et al., TorchIO: a Python library for efficient loading,\npreprocessing, augmentation and patch-based sampling of medical images\nin deep learning. Credits instructions: https://torchio.readthedocs.io/#credits\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"root = f'{PROCESSED_PATH}/train'\npatients = list(sorted(os.listdir(root)))\nstats = defaultdict(list)\nfor patient in patients:\n    base_path = os.path.join(root, patient)\n    meta = np.load(os.path.join(base_path, 'meta.npy'), allow_pickle=True).tolist() \n    meta_processed = dict()\n    for key, values in meta.items():\n        if key in {'SliceLocation', 'InstanceNumber'}:\n            continue\n        else:\n            unique_values, values_cnt = np.unique(values, return_counts=True, axis=0)\n            most_frequent = sorted(zip(unique_values, values_cnt), key=lambda x: x[1])[-1][0]\n            most_frequent = np.array(most_frequent).reshape(-1)\n            if key in {\n                'SliceThickness', 'TableHeight', 'WindowCenter', 'WindowWidth'\n            }:\n                meta_processed[key] = most_frequent[0]\n            elif key == 'PixelSpacing':\n                if len(most_frequent) == 1:\n                    meta_processed['PixelSpacingX'], meta_processed['PixelSpacingY'] = (\n                        most_frequent[0], most_frequent[0]\n                    )\n                else:\n                    meta_processed['PixelSpacingX'], meta_processed['PixelSpacingY'] = (\n                        most_frequent[0], most_frequent[1]\n                    )\n            elif key == 'PatientPosition':\n                pass\n            elif key == 'PositionReferenceIndicator':\n                pass\n    for key in meta_processed:\n        stats[key] += [meta_processed[key]]","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ct_stats = {}\nfor key, values in stats.items():\n    values = np.array(values)\n    stat = namedtuple('mean', 'std')\n    stat.mean = values.mean()\n    stat.std = values.std()\n    ct_stats[key] = stat","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for key in ct_stats:\n    print(key, 'mean: ', ct_stats[key].mean, 'std: ', ct_stats[key].std)","execution_count":59,"outputs":[{"output_type":"stream","text":"PixelSpacingX mean:  2.7656187595460904 std:  2.3477744475149662\nPixelSpacingY mean:  1.4237380549311638 std:  0.14756358563813035\nSliceThickness mean:  1.256083 std:  0.99084175\nTableHeight mean:  133.76607959659088 std:  58.598966674166675\nWindowCenter mean:  -523.8579545454545 std:  192.05943458731193\nWindowWidth mean:  -1241.5454545454545 std:  848.268562869134\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for key in meta_stats:\n    print(key, 'mean: ', meta_stats[key].mean, 'std: ', meta_stats[key].std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_stats = dict.fromkeys(['Weeks', 'FVC', 'Age'])\nmeta_df = pd.read_csv(f'{IMAGE_PATH}/train.csv')\nfor key in meta_stats:\n    values = meta_df[key]\n    stat = namedtuple('mean', 'std')\n    stat.mean = values.mean()\n    stat.std = values.std()\n    meta_stats[key] = stat\nstat = namedtuple('mean', 'std')\nstat.mean = 971.4692260919278\nstat.std = 117.84143467421829\nmeta_stats['Lungs'] = stat","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CTDataset(Dataset):\n    _ReturnValue = namedtuple('ReturnValue', ['weeks', 'fvcs', 'features', 'masks', 'images'])\n\n    def __init__(\n            self, root, csv_path, train=True, test_size=0.25, random_state=42,\n            padding_mode=None, padding_constant=None, transform=None\n    ):\n        assert test_size is not None\n        assert padding_mode in {None, 'edge', 'mean', 'max_min', 'constant'}\n        assert (padding_mode == 'constant' and padding_constant is not None) or (padding_mode != 'constant')\n\n        self.root = root\n        self.train = train\n        self.transform = transform\n        self.csv_path = csv_path\n        self.test_size = test_size\n        self.random_state = random_state\n        self.padding_mode = padding_mode\n        self.padding_constant = padding_constant\n\n        if not os.path.exists(self.root):\n            raise ValueError('Data is missing')\n\n        self._patients = list(sorted(os.listdir(self.root)))\n\n        if self.test_size == 0:\n            self._train_patients, self._test_patients = self._patients, []\n        else:\n            self._train_patients, self._test_patients = train_test_split(\n                self._patients, test_size=self.test_size, random_state=random_state\n            )\n\n        self._table_features = dict()\n        table_data = pd.read_csv(self.csv_path)\n        for patient in self._patients:\n            patient_data = table_data[table_data.Patient == patient]\n\n            all_weeks = patient_data.Weeks.tolist()\n            all_fvcs = patient_data.FVC.tolist()\n\n            all_weeks, all_fvcs = zip(*sorted(zip(all_weeks, all_fvcs), key=lambda x: x[0]))\n\n            age = sorted(zip(*np.unique(patient_data.Age, return_counts=True)), key=lambda x: x[1])[-1][0]\n            sex = sorted(zip(*np.unique(patient_data.Sex, return_counts=True)), key=lambda x: x[1])[-1][0]\n            smoking_status = \\\n                sorted(zip(*np.unique(patient_data.SmokingStatus, return_counts=True)), key=lambda x: x[1])[-1][0]\n\n            sex = [0] if sex == 'Female' else [1]\n            smoking_status = (\n                [1, 0] if smoking_status == 'Ex-smoker' else\n                [0, 1] if smoking_status == 'Never smoked' else\n                [0, 0]\n            )\n            \n            age = (age - meta_stats['Age'].mean) / meta_stats['Age'].std # add normalization\n            self._table_features[patient] = (\n                all_weeks, all_fvcs, [age] + sex + smoking_status\n            )\n\n    def __getitem__(self, index):\n        \"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        \"\"\"\n        patient = self._train_patients[index] if self.train else self._test_patients[index]\n        base_path = os.path.join(self.root, patient)\n\n        # noinspection PyTypeChecker\n        meta = np.load(os.path.join(base_path, 'meta.npy'), allow_pickle=True).tolist()  # type: Dict[List]\n        masks = sparse.load_npz(os.path.join(base_path, 'masks.npz'))\n        images = np.load(os.path.join(base_path, 'images.npy'))\n\n        meta_processed = dict()\n        for key, values in meta.items():\n            if key in {'SliceLocation', 'InstanceNumber'}:\n                continue\n            else:\n                unique_values, values_cnt = np.unique(values, return_counts=True, axis=0)\n                most_frequent = sorted(zip(unique_values, values_cnt), key=lambda x: x[1])[-1][0]\n                most_frequent = np.array(most_frequent).reshape(-1)\n                if key in {\n                    'SliceThickness', 'TableHeight', 'WindowCenter', 'WindowWidth'\n                }:\n                    meta_processed[key] = most_frequent[0]\n                elif key == 'PixelSpacing':\n                    if len(most_frequent) == 1:\n                        meta_processed['PixelSpacingX'], meta_processed['PixelSpacingY'] = (\n                            most_frequent[0], most_frequent[0]\n                        )\n                    else:\n                        meta_processed['PixelSpacingX'], meta_processed['PixelSpacingY'] = (\n                            most_frequent[0], most_frequent[1]\n                        )\n                elif key == 'PatientPosition':\n                    pass\n                elif key == 'PositionReferenceIndicator':\n                    pass\n        \n        # add normalization\n        for key in meta_processed:\n            meta_processed[key] = (meta_processed[key] - ct_stats[key].mean) / ct_stats[key].std\n        \n        all_weeks, all_fvcs, features = self._table_features[patient]\n        features = [value for key, value in meta_processed.items()] + features\n\n        if self.padding_mode is None:\n            pass\n        if self.padding_mode == 'edge':\n            all_weeks, all_fvcs = [-13] + all_weeks + [133], [all_fvcs[0]] + all_fvcs + [all_fvcs[1]]\n        if self.padding_mode == 'mean':\n            all_weeks, all_fvcs = [-13] + all_weeks + [133], [np.mean(all_fvcs)] + all_fvcs + [np.mean(all_fvcs)]\n        if self.padding_mode == 'max_min':\n            all_weeks, all_fvcs = [-13] + all_weeks + [133], [np.max(all_fvcs)] + all_fvcs + [np.min(all_fvcs)]\n        if self.padding_mode == 'constant':\n            all_weeks, all_fvcs = [-13] + all_weeks + [133], [self.padding_constant] + all_fvcs + [\n                self.padding_constant]\n        \n        images = torch.tensor(images[None, :, :, :], dtype=dtype)\n        masks = torch.tensor(masks[None, :, :, :].todense(), dtype=dtype)\n        \n        if self.transform is not None:\n            # noinspection PyTypeChecker\n            subject = torchio.Subject(\n                masks=torchio.ScalarImage(tensor=masks),\n                images=torchio.ScalarImage(tensor=images)\n            )\n            transformed_subject = self.transform(subject)\n            masks = transformed_subject.masks\n            images = transformed_subject.images\n\n        return CTDataset._ReturnValue(weeks=all_weeks, fvcs=all_fvcs, features=features, masks=masks, images=images)\n\n    def __len__(self):\n        return len(self._train_patients if self.train else self._test_patients)\n\n    def __repr__(self):\n        fmt_str = 'OSIC Pulmonary Fibrosis Progression Dataset ' + self.__class__.__name__ + '\\n'\n        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n        tmp = 'train' if self.train is True else 'test'\n        fmt_str += '    Split: {}\\n'.format(tmp)\n        fmt_str += '    Root Location: {}\\n'.format(self.root)\n        return fmt_str","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transforms = torchio.transforms.Compose([\n    torchio.transforms.RandomAffine(degrees=(10, 10),\n                                    translation=(-10, -10), \n                                    isotropic=False, \n                                    default_pad_value='minimum', \n                                    image_interpolation='linear')])","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = CTDataset(\n    f'{PROCESSED_PATH}/train',\n    f'{IMAGE_PATH}/train.csv',\n    train=True, test_size=0.25, random_state=42, transform=None\n)\n\nval_dataset = CTDataset(\n    f'{PROCESSED_PATH}/train',\n    f'{IMAGE_PATH}/train.csv',\n    train=False, test_size=0.25, random_state=42, transform=None\n)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_dataset), len(val_dataset)","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"(132, 44)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_dataloader = DataLoader(train_dataset, batch_size=1, num_workers=3)\n# val_dataloader = DataLoader(val_dataset, batch_size=1, num_workers=3)\n# next(iter(train_dataloader))","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def laplace_loss(y_true, y_pred, log_sigma):\n    log_sigma = torch.clamp(log_sigma, -5, 5)\n    losses = np.sqrt(2) * (y_true - y_pred).abs() / log_sigma.exp() + log_sigma + np.log(2) / 2\n    return losses.mean()","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mse_loss(y_true, y_pred, log_sigma):\n    losses = (y_true - y_pred)**2 + (log_sigma - np.log(70))**2\n    return losses.mean()","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net2D(nn.Module):\n    \n    def __init__(self):\n        super(Net2D, self).__init__()\n        \n        self.efficient_net_1 = EfficientNet.from_pretrained('efficientnet-b0', in_channels=1)\n        self.batch_norm = nn.BatchNorm2d(num_features=1280)\n        self.efficient_net_2 = EfficientNet.from_pretrained('efficientnet-b0', in_channels=1280)\n\n        self.fc_1 = nn.Linear(1280 + 12, 500)\n        self.fc_2 = nn.Linear(500, 250)\n        self.fc_3 = nn.Linear(250, 5)\n        \n        self._initialize_weights()\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, torch.nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, np.sqrt(2. / n))\n            elif isinstance(m, torch.nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)\n    \n    def forward(self, X, meta_X):\n        \"\"\"\n        X: tensor (s, h, w): s - slices\n        meta_X: tensor (n, 12)\n        \"\"\"\n        \n        X = X[::3, :, :]\n        X = X.unsqueeze(1)\n        X = self.efficient_net_1.extract_features(X)\n        \n        X = X.view(X.shape[0], 1280, 64) # shape (s, 1280, 64)\n        \n        X = X.unsqueeze(0) # shape (1, s, 1280, 64)\n        X = X.transpose(1, 2) # shape (1,  1280, s, 64)\n        \n        X = self.batch_norm(X)\n        \n        X = self.efficient_net_2.extract_features(X) # shape (1, 1280, 2, 2)\n        X = torch.mean(X, dim=(2,3)) # shape (1, 1280)\n#       X = X.view(1, 5120)\n        \n        X = torch.cat([X.repeat(meta_X.shape[0], 1), meta_X], dim=1) \n        \n        X = F.relu(self.fc_1(X))\n        X = F.relu(self.fc_2(X))\n        y = self.fc_3(X)\n        \n        return y","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = torch.rand(1,1280, 64, 64)\nX = nn.Conv2d(1280, 640, 3, 3)(X)\nX = F.relu(X)\nX = nn.Conv2d(640, 320, 3, 3)(X)\nX = F.relu(X)\nX = nn.Conv2d(320, 320, 3, 3)(X)\nX = F.relu(X)\nX.shape\nX.view(1,-1).shape","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"torch.Size([1, 1280])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net2D_2(nn.Module):\n    \n    def __init__(self):\n        super(Net2D, self).__init__()\n        \n        self.efficient_net_1 = EfficientNet.from_pretrained('efficientnet-b0', in_channels=1)\n        self.batch_norm_1 = nn.BatchNorm2d(num_features=1280)\n        self.conv_1 = nn.Conv2d(1280, 640, 3, 3)\n        self.batch_norm_2 = nn.BatchNorm2d(num_features=1280)\n        self.conv_2 = nn.Conv2d(640, 320, 3, 3)\n        self.batch_norm_1 = nn.BatchNorm2d(num_features=1280)\n        self.conv_3 = nn.Conv2d(320, 320, 3, 3)\n        \n\n        self.fc_1 = nn.Linear(1280 + 12, 500)\n        self.fc_2 = nn.Linear(500, 250)\n        self.fc_3 = nn.Linear(250, 5)\n        \n        self._initialize_weights()\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, torch.nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, np.sqrt(2. / n))\n            elif isinstance(m, torch.nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)\n    \n    def forward(self, X, meta_X):\n        \"\"\"\n        X: tensor (s, h, w): s - slices\n        meta_X: tensor (n, 12)\n        \"\"\"\n        \n        X = X[::3, :, :]\n        X = X.unsqueeze(1)\n        X = self.efficient_net_1.extract_features(X)\n        \n        X = X.view(X.shape[0], 1280, 64) # shape (s, 1280, 64)\n        \n        X = X.unsqueeze(0) # shape (1, s, 1280, 64)\n        X = X.transpose(1, 2) # shape (1,  1280, s, 64)\n        \n        X = self.batch_norm(X)\n        \n        X = nn.Conv2d(X)\n        X = F.relu(X)\n        X = nn.Conv2d(640, 320, 3, 3)(X)\n        X = F.relu(X)\n        X = nn.Conv2d(320, 320, 3, 3)(X)\n        X = F.relu(X)\n        X.view(1,-1)\n\n        X = self.efficient_net_2.extract_features(X) # shape (1, 1280, 2, 2)\n        X = torch.mean(X, dim=(2,3)) # shape (1, 1280)\n#       X = X.view(1, 5120)\n        \n        X = torch.cat([X.repeat(meta_X.shape[0], 1), meta_X], dim=1) \n        \n        X = F.relu(self.fc_1(X))\n        X = F.relu(self.fc_2(X))\n        y = self.fc_3(X)\n        \n        return y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def polynom(coords, coefs):\n    # coords shape (n, )\n    # coefs shape (4, )\n    \n    poly_coords = torch.empty((coords.shape[0], 4), dtype=dtype, device=device)\n    poly_coords[:, 3] = 1\n    poly_coords[:, 2] = coords\n    poly_coords[:, 1] = coords**2\n    poly_coords[:, 0] = coords**3\n    return (poly_coords * coefs.unsqueeze(0)).sum(dim=1)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, optimizer, loss_func, train_dataset, val_dataset, epochs, scheduler=None):\n\n    def get_lr(optimizer):\n        for param_group in optimizer.param_groups:\n            return param_group['lr']\n\n    val_loss_min = np.inf\n    for epoch in range(epochs):\n        running_loss = 0.0\n        \n#         for iter_num, data in enumerate(train_dataset):\n        data = train_dataset[0]\n        iter_num = 0\n        model.train()\n        optimizer.zero_grad()\n\n        #prepare lungs\n        masks = data.masks \n        images = data.images\n\n        lungs = -1000 * (1.0 - masks) + masks * images\n        lungs = (lungs - meta_stats['Lungs'].mean) / meta_stats['Lungs'].std\n        \n        lungs = lungs.squeeze(0)\n        X = lungs.to(device)\n\n        # prepare features\n        weeks = torch.tensor(data.weeks, dtype=dtype, device=device)\n        fvcs = torch.tensor(data.fvcs, dtype=dtype, device=device)\n        features = torch.tensor(data.features, dtype=dtype, device=device)\n        num_weeks = len(weeks)\n        meta_weeks = (weeks - meta_stats['Weeks'].mean) / meta_stats['Weeks'].std\n        meta_fvcs = (fvcs - meta_stats['FVC'].mean) / meta_stats['FVC'].std\n        \n        meta_X = torch.cat([meta_weeks.unsqueeze(1), meta_fvcs.unsqueeze(1), \n                               features.unsqueeze(0).repeat(num_weeks, 1)], dim=1)\n        \n        preds = model(X, meta_X) # shape (num_weeks, 5)\n\n\n        coefs = preds[:, 0:4]\n        log_sigma = preds[:, 4]\n\n        loss = 0.0\n        lap_loss = 0.0\n        for week in range(num_weeks):\n            fvcs_pred = polynom(weeks, coefs[week])\n            loss += loss_func(fvcs, fvcs_pred, log_sigma[week])\n            lap_loss += laplace_loss(fvcs.detach(), fvcs_pred.detach(), log_sigma[week].detach())\n\n        loss /= num_weeks\n        lap_loss /= num_weeks\n        loss.backward() \n        optimizer.step()\n        running_loss += loss.item()\n\n        print(\"Epoch: {} \".format(epoch + 1),\n              \"Iteration: {} \".format(iter_num),\n              \"lr: {:.6f} \".format(get_lr(optimizer)),\n              \"Loss: {:.6f}.\".format(loss.item()),\n              'Laplace loss: {:.6f}.'.format(lap_loss.item()),\n               \"Sigma: {:.6f}\".format(log_sigma.mean().item()))\n\n    running_loss /= len(train_dataset)  \n        \n#         val_loss = eval_model(model, loss_func, val_dataset)\n    \n        \n#         print(\"Epoch: {}/{}...\".format(epoch + 1, n_epochs),\n#               \"lr: {:.6f}...\".format(get_lr(optimizer)),\n#               \"Loss: {:.6f}...\".format(running_loss.item()),\n#               \"Val Loss: {:.6f}\".format(val_loss))\n#         print('------------------------------')\n\n        \n#         if val_loss <= val_loss_min:\n#             torch.save(model.state_dict(), f'./state_dict{epoch}.pt')\n#             print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(val_loss_min, val_loss))\n#             val_loss_min = val_loss\n        \n#         if scheduler is not None:\n#             scheduler.step()","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Net2D().to(device)\noptimizer = optim.Adam(model.parameters(), lr=1e-2)","execution_count":45,"outputs":[{"output_type":"stream","text":"Loaded pretrained weights for efficientnet-b0\nLoaded pretrained weights for efficientnet-b0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(model, optimizer, mse_loss, train_dataset, val_dataset, epochs=100, scheduler=None)","execution_count":46,"outputs":[{"output_type":"stream","text":"torch.Size([1, 1280, 64, 64])\nEpoch: 1  Iteration: 0  lr: 0.010000  Loss: 4082568.500000. Laplace loss: 2824.787109. Sigma: 0.000597\ntorch.Size([1, 1280, 64, 64])\nEpoch: 2  Iteration: 0  lr: 0.010000  Loss: 935636238336.000000. Laplace loss: 57986.050781. Sigma: 2.645709\ntorch.Size([1, 1280, 64, 64])\nEpoch: 3  Iteration: 0  lr: 0.010000  Loss: 100736784.000000. Laplace loss: 4838.610840. Sigma: 0.495149\ntorch.Size([1, 1280, 64, 64])\nEpoch: 4  Iteration: 0  lr: 0.010000  Loss: 38320384.000000. Laplace loss: 6642.150879. Sigma: 0.054521\ntorch.Size([1, 1280, 64, 64])\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-b5e2841c9eae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-32-ce8ead381137>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, loss_func, train_dataset, val_dataset, epochs, scheduler)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mlap_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnum_weeks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param_group in optimizer.param_groups:\n    param_group['lr'] /= 5","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def eval_model(model, loss_func, val_dataset):\n#     running_loss = 0.0\n#     model.eval()    \n#     for i, data in enumerate(val_dataset):\n#         #prepare lungs\n#         masks = data.masks \n#         images = data.images\n\n#         lungs = -1000 * (1.0 - masks) + masks * images\n    \n#         X = transforms(lungs).to(device)\n\n#         # prepare features\n#         weeks = torch.tensor(data.all_weeks).to(device)\n#         fvcs = torch.tensor(data.all_fvcs).to(device)\n#         features = torch.tensor(data.features).to(device)\n\n#         num_weeks = len(weeks)\n#         meta_X = torch.concat([weeks.unsqueeze(1), fvcs.unsqueeze(1), \n#                                features.unsqueeze(0).repeat(num_weeks, 1)], dim=1)\n\n#         preds = model(X, meta_X) # shape (num_weeks, 5)\n\n#         coefs = pred[: 0:4]\n#         log_sigma = pred[:, 5]\n\n#         loss = 0\n#         for i in range(num_weeks):\n#             fwc_pred = polynom(weeks, coefs[i])\n#             loss += loss_func(fwc, fwc_pred, log_sigma[i])\n\n#         loss /= num_weeks\n#         running_loss += loss.item()\n    \n#     return running_loss / len(val_dataset)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}