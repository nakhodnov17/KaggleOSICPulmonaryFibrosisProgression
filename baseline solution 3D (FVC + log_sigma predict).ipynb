{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add crop for log_sigma and for abs diff for FVC\n",
    "# TODO: add normalization for data\n",
    "# TODO: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import os\n",
    "import platform\n",
    "from collections import namedtuple\n",
    "import time\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import tabulate\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sparse\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "# from torchvision import transforms\n",
    "# from torchsummary import summary\n",
    "# from efficientnet_pytorch_3d import EfficientNet3D\n",
    "from my_efficientnet_pytorch_3d import EfficientNet3D\n",
    "import torchio\n",
    "\n",
    "from utils import CTDataset\n",
    "\n",
    "\n",
    "########################\n",
    "\n",
    "RUNNING_IN_KAGGLE = 'linux' in platform.platform().lower()\n",
    "IMAGE_PATH = \"../input/osic-pulmonary-fibrosis-progression/\" if RUNNING_IN_KAGGLE else 'data/'\n",
    "PROCESSED_PATH = 'FIX IT!' if RUNNING_IN_KAGGLE else 'data/processed-data/'  # TODO: fix this line\n",
    "\n",
    "dtype = torch.float32\n",
    "USE_GPU = True\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.squeeze()\n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, net):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net.extract_features(x.unsqueeze(0).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(torch.nn.Module):\n",
    "    _vgg_configurations = {\n",
    "        'small': [8, 'M', 8, 'M', 16, 'M', 16, 'M'],  # , 64, 'M', 64, 'M'],  # , 512, 'M', 512, 'M'],\n",
    "        8: [64, 'M', 128, 'M', 256, 'M', 512, 'M', 512, 'M'],\n",
    "        11: [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "        13: [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "        16: [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "        19: [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "    }\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_layers(cfg, batch_norm):\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [torch.nn.MaxPool3d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [torch.nn.Conv3d(in_channels, v, kernel_size=3, padding=1)]\n",
    "                if batch_norm:\n",
    "                    layers += [torch.nn.BatchNorm3d(v)]\n",
    "                layers += [torch.nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "        return layers\n",
    "\n",
    "    def __init__(self, VGG_version, batch_norm):  # num_classes, \n",
    "        super().__init__()\n",
    "        self.VGG_version = VGG_version\n",
    "        self.batch_norm = batch_norm\n",
    "#         self.num_classes = num_classes\n",
    "\n",
    "#         self.layers = torch.nn.ModuleList([\n",
    "#             # Convolution Layers\n",
    "#             *make_layers(_vgg_configurations[VGG_version], batch_norm),\n",
    "\n",
    "#             torch.nn.modules.flatten.Flatten(),\n",
    "\n",
    "#             # Fully Connected Layers\n",
    "#             torch.nn.Dropout(),\n",
    "#             torch.nn.Linear(512, 512),\n",
    "#             torch.nn.ReLU(inplace=True),\n",
    "#             torch.nn.Dropout(),\n",
    "#             torch.nn.Linear(512, 512),\n",
    "#             torch.nn.ReLU(inplace=True),\n",
    "#             torch.nn.Linear(512, num_classes),\n",
    "#         ])\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            *VGG._make_layers(self._vgg_configurations[VGG_version], batch_norm)\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "#         for module in self.modules():\n",
    "#             if isinstance(module, torch.nn.Conv3d):\n",
    "#                 torch.nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "#                 if module.bias is not None:\n",
    "#                     torch.nn.init.constant_(module.bias, 0)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv3d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.kernel_size[2] * m.out_channels\n",
    "                m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "            elif isinstance(m, torch.nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):  # , target_layers: Optional[set] = None):\n",
    "#         intermediate_layers = []\n",
    "#         for idx, layer in enumerate(self.layers):\n",
    "#             if target_layers is not None and idx in target_layers:\n",
    "#                 x.requires_grad_(True)\n",
    "#                 intermediate_layers.append(x)\n",
    "#             x = layer(x)\n",
    "#         if target_layers is not None and len(self.layers) in target_layers:\n",
    "#             x.requires_grad_(True)\n",
    "#             intermediate_layers.append(x)\n",
    "\n",
    "#         if target_layers is not None:\n",
    "#             return x, intermediate_layers\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplaceLoss(nn.Module):  # _Loss):\n",
    "    def forward(self, y_true, preds, log_sigma, metric=False):\n",
    "        abs_diff = (y_true - preds).abs()\n",
    "\n",
    "        log_sigma.clamp_(-5, 5)\n",
    "\n",
    "        if metric:\n",
    "            abs_diff.clamp_max_(1000)\n",
    "            log_sigma.clamp_(-np.log(70), np.log(70))  # TODO: min bound is strange??\n",
    "\n",
    "#         log_sigma.clamp_min_(-5)\n",
    "\n",
    "        losses = np.sqrt(2) * abs_diff / log_sigma.exp() + log_sigma + np.log(2) / 2\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSICNet(nn.Module):\n",
    "    def __init__(self, dtype, device, efficient_net_model_number, hidden_size, dropout_rate):  # , output_size\n",
    "        super().__init__()\n",
    "\n",
    "        self.dtype = dtype\n",
    "        self.device = device\n",
    "\n",
    "        self.CT_features_extractor = nn.Sequential(\n",
    "#             FeatureExtractor(\n",
    "#                 EfficientNet3D.from_name(\n",
    "#                     f'efficientnet-b{efficient_net_model_number}', override_params={'num_classes': 1}, in_channels=1\n",
    "#                 )\n",
    "#             ),\n",
    "            VGG('small', True),\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            SqueezeLayer()\n",
    "        )\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(16, hidden_size),  # 16 +   # 1294\n",
    "            nn.ReLU(),  # nn.Tanh(),  # \n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),  # nn.Tanh(),  # \n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, 2)  # FVC & log_sigma  # output_size\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "        self.CT_features_extractor.to(self.device)\n",
    "        self.predictor.to(self.device)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv3d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.kernel_size[2] * m.out_channels\n",
    "                m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "            elif isinstance(m, torch.nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        \n",
    "#     def forward(self, data):\n",
    "#         mean_dataset, std_dataset = -971.4692260919278, 117.84143467421829\n",
    "#         lungs = -1000 * (1.0 - data.masks) + data.masks * data.images\n",
    "#         lungs = (lungs - mean_dataset) / std_dataset\n",
    "#         lungs = torch.tensor(lungs, dtype=self.dtype, device=self.device)\n",
    "#         lungs_features = self.CT_features_extractor(lungs)\n",
    "\n",
    "#         data_weeks = torch.tensor(data.weeks, dtype=self.dtype)\n",
    "#         weeks = torch.empty(len(data.weeks), 4, dtype=self.dtype)\n",
    "#         weeks[:, 3] = 1\n",
    "#         weeks[:, 2] = data_weeks\n",
    "#         weeks[:, 1] = data_weeks ** 2\n",
    "#         weeks[:, 0] = data_weeks ** 3\n",
    "\n",
    "#         agg_loss = 0\n",
    "#         for week, FVC in zip(data.weeks, data.fvcs):\n",
    "#             table_features = torch.tensor(np.r_[week, FVC, data.features], dtype=self.dtype, device=self.device)\n",
    "#             X = lungs_features  # torch.cat([lungs_features, table_features])\n",
    "\n",
    "#             pred_numbers = self.predictor(X).cpu()\n",
    "#             coefs = pred_numbers[:4]\n",
    "#             log_sigma = pred_numbers[4]\n",
    "\n",
    "#             FVC_preds = (weeks * coefs).sum(dim=1)\n",
    "#             FVC_true = torch.tensor(data.fvcs, dtype=self.dtype)\n",
    "\n",
    "#             agg_loss += LaplaceLoss()(FVC_true, FVC_preds, log_sigma)\n",
    "\n",
    "#         return agg_loss / len(data.weeks)\n",
    "\n",
    "    def _normalize_data(self, data):\n",
    "        percents, weeks, FVCs, features, masks, images = data\n",
    "\n",
    "        lungs_mean, lungs_std = -971.4692260919278, 117.84143467421829\n",
    "        lungs = -1000 * (1.0 - masks) + masks * images\n",
    "        lungs = (lungs - lungs_mean) / lungs_std\n",
    "        lungs = lungs.type(self.dtype)\n",
    "#         lungs = torch.tensor(lungs, dtype=self.dtype, device=self.device)\n",
    "#         lungs_features = self.CT_features_extractor(lungs)\n",
    "\n",
    "        percents_mean, percents_std = 77.6726, 19.8233\n",
    "        weeks_mean, weeks_std = 31.861846352485475, 23.240045178171002\n",
    "        FVCs_mean, FVCs_std = 2690.479018721756, 832.5021066817238\n",
    "#         other_ftrs_mean = np.array([\n",
    "#             2.76561876e+00,  1.42373805e+00,  1.25608294e+00,  1.33766080e+02,\n",
    "#             -5.23857955e+02, -1.24154545e+03,  6.72613636e+01,  7.89772727e-01,\n",
    "#             2.10227273e-01,  6.70454545e-01,  2.78409091e-01,  5.11363636e-02\n",
    "#         ])\n",
    "#         other_ftrs_std = np.array([\n",
    "#             2.34777445e+00, 1.47563586e-01, 9.90841780e-01, 5.85989667e+01,\n",
    "#             1.92059435e+02, 8.48268563e+02, 7.06784382e+00, 4.07469958e-01,\n",
    "#             4.07469958e-01, 4.70048134e-01, 4.48215873e-01, 2.20275818e-01\n",
    "#         ])\n",
    "\n",
    "        percents = (percents - percents_mean) / percents_std\n",
    "        weeks = (weeks - weeks_mean) / weeks_std\n",
    "        FVCs = (FVCs - FVCs_mean) / FVCs_std\n",
    "#         features = (features - other_ftrs_mean) / other_ftrs_std\n",
    "        features = features.type(self.dtype)\n",
    "#         masks = lungs\n",
    "#         images = None\n",
    "\n",
    "        return percents, weeks, FVCs, features, lungs, images\n",
    "\n",
    "    def forward(self, data):\n",
    "        percents, weeks, FVCs, features, lungs, images = self._normalize_data(data)\n",
    "#         lungs_mean, lungs_std = -971.4692260919278, 117.84143467421829\n",
    "#         lungs = -1000 * (1.0 - data.masks) + data.masks * data.images\n",
    "#         lungs = (lungs - lungs_mean) / lungs_std\n",
    "#         lungs = torch.tensor(lungs, dtype=self.dtype, device=self.device)\n",
    "#         OSICNet._normalize_data(data)\n",
    "\n",
    "#         lungs = data.masks\n",
    "\n",
    "        ###############################\n",
    "#         lungs = lungs.unsqueeze(0).to(self.device)  # TODO: uncomment\n",
    "#         lungs_features = self.CT_features_extractor(lungs)\n",
    "        ###############################\n",
    "        \n",
    "#         weeks_mean, weeks_std = 31.861846352485475, 23.240045178171002\n",
    "#         FVCs_mean, FVCs_std = 2690.479018721756, 832.5021066817238\n",
    "#         other_ftrs_mean = np.array([\n",
    "#             2.76561876e+00,  1.42373805e+00,  1.25608294e+00,  1.33766080e+02,\n",
    "#             -5.23857955e+02, -1.24154545e+03,  6.72613636e+01,  7.89772727e-01,\n",
    "#             2.10227273e-01,  6.70454545e-01,  2.78409091e-01,  5.11363636e-02\n",
    "#         ])\n",
    "#         other_ftrs_std = np.array([\n",
    "#             2.34777445e+00, 1.47563586e-01, 9.90841780e-01, 5.85989667e+01,\n",
    "#             1.92059435e+02, 8.48268563e+02, 7.06784382e+00, 4.07469958e-01,\n",
    "#             4.07469958e-01, 4.70048134e-01, 4.48215873e-01, 2.20275818e-01\n",
    "#         ])\n",
    "\n",
    "#         data._replace(weeks = (np.array(data.weeks) - weeks_mean) / weeks_std)\n",
    "#         data._replace(fvcs = (np.array(data.fvcs) - FVCs_mean) / FVCs_std)\n",
    "#         data._replace(features = (np.array(data.features) - other_ftrs_mean) / other_ftrs_std)\n",
    "\n",
    "#         data_weeks = torch.tensor(data.weeks, dtype=self.dtype)\n",
    "#         weeks = torch.empty(len(data.weeks), 4, dtype=self.dtype)\n",
    "#         weeks[:, 3] = 1\n",
    "#         weeks[:, 2] = data_weeks\n",
    "#         weeks[:, 1] = data_weeks ** 2\n",
    "#         weeks[:, 0] = data_weeks ** 3\n",
    "\n",
    "#         agg_loss = 0\n",
    "        all_preds = []\n",
    "        for base_percent, base_week, base_FVC in zip(percents, weeks, FVCs):\n",
    "            table_features = torch.cat([\n",
    "                torch.tensor([base_percent]),\n",
    "                torch.tensor([base_week]),\n",
    "                torch.tensor([base_FVC]),\n",
    "                features\n",
    "            ]).to(self.device)  # torch.tensor([week]),\n",
    "\n",
    "            all_features = torch.cat([table_features])  # lungs_features,  # TODO: uncomment\n",
    "\n",
    "            X = torch.cat([all_features.repeat(weeks.shape[0], 1), weeks.unsqueeze(1).to(self.device)], dim=1)\n",
    "\n",
    "            preds = self.predictor(X).cpu()\n",
    "            \n",
    "#             for week in weeks:\n",
    "#                 table_features = torch.cat([torch.tensor([base_week]), torch.tensor([base_FVC]),\n",
    "#                                             torch.tensor([week]), features]).to(self.device)\n",
    "# #                                            dtype=self.dtype, device=self.device)\n",
    "#                 X = torch.cat([lungs_features, table_features])  # .to(self.device)  # lungs_features\n",
    "\n",
    "#                 pred_numbers = self.predictor(X).cpu()\n",
    "#                 preds = self.predictor(X).cpu()\n",
    "            all_preds.append(preds)\n",
    "#             coefs = pred_numbers[:4]\n",
    "#             log_sigma = pred_numbers[4]\n",
    "\n",
    "#             FVC_preds = (weeks * coefs).sum(dim=1)\n",
    "#             FVC_true = torch.tensor(data.fvcs, dtype=self.dtype)\n",
    "            \n",
    "#             agg_loss += LaplaceLoss()(FVC_true, FVC_preds, log_sigma)\n",
    "\n",
    "#         return agg_loss / len(data.weeks)\n",
    "        return all_preds\n",
    "\n",
    "#     def forward(self, data):\n",
    "#         lungs_mean, lungs_std = -971.4692260919278, 117.84143467421829\n",
    "#         lungs = -1000 * (1.0 - data.masks) + data.masks * data.images\n",
    "#         lungs = (lungs - lungs_mean) / lungs_std\n",
    "#         lungs = torch.tensor(lungs, dtype=self.dtype, device=self.device)\n",
    "#         lungs_features = self.CT_features_extractor(lungs)\n",
    "\n",
    "#         weeks_mean, weeks_std = 31.861846352485475, 23.240045178171002\n",
    "#         FVCs_mean, FVCs_std = 2690.479018721756, 832.5021066817238\n",
    "#         other_ftrs_mean = np.array([\n",
    "#             2.76561876e+00,  1.42373805e+00,  1.25608294e+00,  1.33766080e+02,\n",
    "#             -5.23857955e+02, -1.24154545e+03,  6.72613636e+01,  7.89772727e-01,\n",
    "#             2.10227273e-01,  6.70454545e-01,  2.78409091e-01,  5.11363636e-02\n",
    "#         ])\n",
    "#         other_ftrs_std = np.array([\n",
    "#             2.34777445e+00, 1.47563586e-01, 9.90841780e-01, 5.85989667e+01,\n",
    "#             1.92059435e+02, 8.48268563e+02, 7.06784382e+00, 4.07469958e-01,\n",
    "#             4.07469958e-01, 4.70048134e-01, 4.48215873e-01, 2.20275818e-01\n",
    "#         ])\n",
    "\n",
    "#         data._replace(weeks = (np.array(data.weeks) - weeks_mean) / weeks_std)\n",
    "#         data._replace(fvcs = (np.array(data.fvcs) - FVCs_mean) / FVCs_std)\n",
    "#         data._replace(features = (np.array(data.features) - other_ftrs_mean) / other_ftrs_std)\n",
    "\n",
    "# #         data_weeks = torch.tensor(data.weeks, dtype=self.dtype)\n",
    "# #         weeks = torch.empty(len(data.weeks), 4, dtype=self.dtype)\n",
    "# #         weeks[:, 3] = 1\n",
    "# #         weeks[:, 2] = data_weeks\n",
    "# #         weeks[:, 1] = data_weeks ** 2\n",
    "# #         weeks[:, 0] = data_weeks ** 3\n",
    "\n",
    "# #         agg_loss = 0\n",
    "#         all_preds = []\n",
    "#         for week, FVC in zip(data.weeks, data.fvcs):\n",
    "#             table_features = torch.tensor(np.r_[week, FVC, data.features], dtype=self.dtype, device=self.device)\n",
    "#             X = torch.cat([lungs_features, table_features])  # lungs_features\n",
    "\n",
    "#             pred_numbers = self.predictor(X).cpu()\n",
    "#             all_preds.append(pred_numbers)\n",
    "# #             coefs = pred_numbers[:4]\n",
    "# #             log_sigma = pred_numbers[4]\n",
    "\n",
    "# #             FVC_preds = (weeks * coefs).sum(dim=1)\n",
    "# #             FVC_true = torch.tensor(data.fvcs, dtype=self.dtype)\n",
    "            \n",
    "# #             agg_loss += LaplaceLoss()(FVC_true, FVC_preds, log_sigma)\n",
    "\n",
    "# #         return agg_loss / len(data.weeks)\n",
    "#         return all_preds\n",
    "\n",
    "\n",
    "class LinearDecayLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, start_epoch, stop_epoch, start_lr, stop_lr, last_epoch=-1):\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.start_epoch = start_epoch\n",
    "        self.stop_epoch = stop_epoch\n",
    "\n",
    "        self.start_lr = start_lr\n",
    "        self.stop_lr = stop_lr\n",
    "\n",
    "        self.last_epoch = last_epoch\n",
    "\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self) -> list:\n",
    "        if self.last_epoch < self.start_epoch:\n",
    "            new_lr = self.start_lr\n",
    "        elif self.last_epoch > self.stop_epoch:\n",
    "            new_lr = self.stop_lr\n",
    "        else:\n",
    "            new_lr = self.start_lr + (\n",
    "                (self.stop_lr - self.start_lr) *\n",
    "                (self.last_epoch - self.start_epoch) /\n",
    "                (self.stop_epoch - self.start_epoch)\n",
    "            )\n",
    "        return [new_lr for _ in self.optimizer.param_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchio.transforms.Compose([\n",
    "    torchio.transforms.RandomAffine(\n",
    "        degrees=(10, 10),\n",
    "        translation=(-10, -10),\n",
    "        isotropic=False,\n",
    "        default_pad_value='minimum',\n",
    "        image_interpolation='linear',\n",
    "    ),\n",
    "#     torchio.transforms.RandomElasticDeformation(\n",
    "#         max_displacement=3.0\n",
    "#     )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CTDataset(\n",
    "    f'{PROCESSED_PATH}/train',\n",
    "    f'{IMAGE_PATH}/train.csv',\n",
    "    train=True,\n",
    "    transform=transforms,\n",
    "    test_size=0.25,\n",
    "    padding_mode='edge',\n",
    "    random_state=42,\n",
    "    pad_global=False,\n",
    ")\n",
    "\n",
    "test_dataset = CTDataset(\n",
    "    f'{PROCESSED_PATH}/train',\n",
    "    f'{IMAGE_PATH}/train.csv',\n",
    "    train=False,\n",
    "    transform=transforms,\n",
    "    test_size=0.25,\n",
    "    padding_mode=None,  # 'edge',\n",
    "    random_state=42,\n",
    "    pad_global=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dl = DataLoader(train_dataset, batch_size=1, num_workers=4)\n",
    "# # next(iter(dl))\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# # %%time\n",
    "\n",
    "# # for _ in tqdm(dl):\n",
    "# #     pass\n",
    "\n",
    "# # %%time\n",
    "\n",
    "# # for _ in train_dataset:\n",
    "# #     pass\n",
    "\n",
    "# # # _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OSICNet(dtype=dtype, device=device, efficient_net_model_number=0, hidden_size=100, dropout_rate=0)  # 512, 0.5)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-8, momentum=0.9)  # , weight_decay=5e-4)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)  # 3e-4\n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-3)  # 3e-4\n",
    "\n",
    "\n",
    "### TMP ###\n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-9, momentum=0, weight_decay=0)  # 0.9, 5e-4)\n",
    "# lr_scheduler = LinearDecayLR(optimizer, )\n",
    "\n",
    "\n",
    "\n",
    "# for g in optimizer.param_groups:\n",
    "#     g['lr'] /= 10\n",
    "\n",
    "\n",
    "\n",
    "# from torchsummary import summary\n",
    "# summary(model.CT_features_extractor[0].net)\n",
    "\n",
    "# mmm = FeatureExtractor(\n",
    "#     EfficientNet3D.from_name(\n",
    "#         f'efficientnet-b{0}', override_params={'num_classes': 1}, in_channels=1\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# summary(mmm)\n",
    "\n",
    "# preds = model(train_dataset[0])\n",
    "# preds\n",
    "\n",
    "\n",
    "# torch.cat([torch.tensor([1]), torch.tensor([2]), torch.tensor([3]), torch.tensor([1, 2, 3])])\n",
    "\n",
    "# lungs_features.shape\n",
    "\n",
    "# preds\n",
    "# preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "log_writer = SummaryWriter(log_dir='logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(mode, writer, epoch, cur_iter, loss, metric, metric_last_3, start_time,\n",
    "                  cur_start_time, cur_end_time, log_sigmas):\n",
    "    writer.add_scalar(f'loss/{mode}', loss.item(), epoch)\n",
    "    writer.add_scalar(f'metric/{mode}', metric, epoch)\n",
    "    writer.add_scalar(f'metric (last 3)/{mode}', metric_last_3, epoch)\n",
    "    writer.add_scalar(f'log sigma/{mode}', log_sigmas.detach().mean().item(), epoch)\n",
    "\n",
    "    columns = [\n",
    "        'Epoch', \n",
    "        'Iter', \n",
    "        'Loss', \n",
    "        'Metric', \n",
    "        'Metric (last 3)', \n",
    "        'Cur iter time', \n",
    "        'Elapsed time', \n",
    "        'Log sigma'\n",
    "    ]\n",
    "\n",
    "    values = [\n",
    "        f'{epoch + 1}',\n",
    "        f'{cur_iter + 1}',\n",
    "        f'{loss.item():0.6f}',\n",
    "        f'{metric:0.6f}',\n",
    "        f'{metric_last_3:0.6f}',\n",
    "        f'{cur_end_time - cur_start_time:0.1f} sec',\n",
    "        f'{cur_end_time - start_time:0.1f} sec',\n",
    "        f'{log_sigmas.detach().mean().item():0.3f}'\n",
    "    ]\n",
    "    table = tabulate.tabulate([values], columns, tablefmt='simple', floatfmt='8.4f')\n",
    "    if cur_iter % 40 == 0:\n",
    "        table = table.split('\\n')\n",
    "        table = '\\n'.join([table[1]] + table)\n",
    "    else:\n",
    "        table = table.split('\\n')[2]\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      1       1    7.5008   10.3879            11.3841  0.1 sec          1.2 sec              5.0000\n",
      "      1       2    6.8031    8.9087            11.8248  0.1 sec          2.3 sec              5.0000\n",
      "      1       3    9.3029   14.2089            15.0897  0.1 sec          3.4 sec              5.0000\n",
      "      1       4    6.6835    8.6551             8.2377  0.1 sec          4.5 sec              5.0000\n",
      "      1       5    5.4640    6.0695             5.4016  0.1 sec          5.7 sec              5.0000\n",
      "      1       6    6.2835    7.8072             6.7732  0.1 sec          6.8 sec              5.0000\n",
      "      1       7    6.0816    7.3791             7.8802  0.1 sec          7.9 sec              5.0000\n",
      "      1       8    5.0077    5.3746             4.6866  0.1 sec          9.1 sec              5.0000\n",
      "      1       9    5.9834    7.1707             8.8478  0.1 sec          10.2 sec             5.0000\n",
      "      1      10    7.3312   10.0285             7.9027  0.1 sec          11.3 sec             5.0000\n",
      "      1      11   11.8292   18.5408            17.1047  0.1 sec          12.4 sec             5.0000\n",
      "      1      12    6.8387    8.8954            13.2171  0.1 sec          13.6 sec             5.0000\n",
      "      1      13    7.9788   11.4016            13.1782  0.1 sec          14.7 sec             5.0000\n",
      "      1      14    6.8303    9.0890            11.4332  0.1 sec          15.8 sec             5.0000\n",
      "      1      15   13.3389   19.2401            18.3455  0.1 sec          17.0 sec             5.0000\n",
      "      1      16    7.8961   10.9547            14.4228  0.1 sec          18.1 sec             5.0000\n",
      "      1      17    7.3790   10.1297            12.1838  0.1 sec          19.3 sec             5.0000\n",
      "      1      18    8.0742   11.7262            12.4326  0.1 sec          20.5 sec             5.0000\n",
      "      1      19    8.0570   11.5672            14.2075  0.1 sec          21.7 sec             5.0000\n",
      "      1      20    9.0640   13.7023            12.4166  0.1 sec          22.8 sec             5.0000\n",
      "      1      21   11.6891   17.8200            20.2858  0.1 sec          24.0 sec             5.0000\n",
      "      1      22    6.6830    8.7768             9.0624  0.1 sec          25.2 sec             5.0000\n",
      "      1      23    5.1740    5.4547             4.9981  0.1 sec          26.3 sec             5.0000\n",
      "      1      24    8.1122   11.5821             8.7818  0.1 sec          27.4 sec             5.0000\n",
      "      1      25    7.5554   10.4459             9.9888  0.1 sec          28.6 sec             5.0000\n",
      "      1      26   15.3884   20.1903            20.2894  0.1 sec          29.7 sec             5.0000\n",
      "      1      27    5.2259    5.5647             5.6611  0.1 sec          30.9 sec             5.0000\n",
      "      1      28    9.9546   15.5054            13.2580  0.1 sec          32.1 sec             5.0000\n",
      "      1      29    6.0209    7.2502             8.3455  0.1 sec          33.2 sec             5.0000\n",
      "      1      30    6.3216    7.8879             9.3306  0.1 sec          34.4 sec             5.0000\n",
      "      1      31    7.3977    9.9718            11.9925  0.1 sec          35.7 sec             5.0000\n",
      "      1      32    7.7931   11.1304             8.6411  0.1 sec          36.8 sec             5.0000\n",
      "      1      33    5.3699    5.8701             6.5798  0.1 sec          38.0 sec             5.0000\n",
      "      1      34    6.3357    8.0404             6.1125  0.1 sec          39.1 sec             5.0000\n",
      "      1      35    5.6994    6.5687             5.6444  0.1 sec          40.2 sec             5.0000\n",
      "      1      36    8.7398   13.0148            11.0416  0.1 sec          41.3 sec             5.0000\n",
      "      1      37    5.4454    6.0303             6.4360  0.1 sec          42.4 sec             5.0000\n",
      "      1      38    7.0388    9.4085            10.6414  0.1 sec          43.6 sec             5.0000\n",
      "      1      39    8.1681   11.7346            12.7507  0.1 sec          44.7 sec             5.0000\n",
      "      1      40    6.5595    8.3699             6.9210  0.1 sec          45.8 sec             5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      1      41    6.2055    7.6417             9.5155  0.1 sec          47.0 sec             5.0000\n",
      "      1      42    8.4786   12.5815            15.7644  0.1 sec          48.1 sec             5.0000\n",
      "      1      43   10.6533   16.4186            15.8628  0.1 sec          49.2 sec             5.0000\n",
      "      1      44    6.1048    7.5509             8.5529  0.1 sec          50.5 sec             5.0000\n",
      "      1      45    5.7231    6.6189             7.0895  0.1 sec          51.7 sec             5.0000\n",
      "      1      46    5.9014    6.9970             8.4380  0.1 sec          53.0 sec             5.0000\n",
      "      1      47    8.9851   13.2122            11.9142  0.1 sec          54.1 sec             5.0000\n",
      "      1      48   11.4412   18.4722            18.9533  0.1 sec          55.4 sec             5.0000\n",
      "      1      49    6.7366    8.7677            10.9302  0.1 sec          56.5 sec             5.0000\n",
      "      1      50    8.7273   12.5695             8.8556  0.1 sec          57.7 sec             5.0000\n",
      "      1      51    5.6405    6.5664             6.1697  0.1 sec          58.8 sec             5.0000\n",
      "      1      52    6.6087    8.4965             6.6190  0.1 sec          60.0 sec             5.0000\n",
      "      1      53    6.0452    7.3020             7.1140  0.1 sec          61.1 sec             5.0000\n",
      "      1      54    7.3767   10.2474            10.8237  0.1 sec          62.3 sec             5.0000\n",
      "      1      55    7.3262   10.0177             9.3442  0.1 sec          63.5 sec             5.0000\n",
      "      1      56    9.8942   15.0146            19.2116  0.1 sec          64.6 sec             5.0000\n",
      "      1      57    5.4226    5.9819             5.8327  0.1 sec          65.8 sec             5.0000\n",
      "      1      58    7.9388   11.3167            10.2369  0.1 sec          67.3 sec             5.0000\n",
      "      1      59    5.0854    5.2668             5.8667  0.1 sec          68.5 sec             5.0000\n",
      "      1      60    9.3876   14.3265            17.3051  0.1 sec          69.7 sec             5.0000\n",
      "      1      61    5.8125    6.8084             9.0768  0.1 sec          70.9 sec             5.0000\n",
      "      1      62    5.9879    7.1803             7.9647  0.1 sec          72.1 sec             5.0000\n",
      "      1      63    6.7537    8.8040             9.9415  0.1 sec          73.2 sec             5.0000\n",
      "      1      64    5.7648    6.7074             8.6146  0.1 sec          74.4 sec             5.0000\n",
      "      1      65    7.0519    9.4363             6.7739  0.1 sec          75.5 sec             5.0000\n",
      "      1      66    5.0783    5.7115             6.6989  0.1 sec          76.7 sec             5.0000\n",
      "      1      67    6.2136    7.9312             6.3613  0.1 sec          77.8 sec             5.0000\n",
      "      1      68    6.9106    9.1366             9.1587  0.1 sec          78.9 sec             5.0000\n",
      "      1      69    6.2265    7.8088            10.0983  0.1 sec          80.1 sec             5.0000\n",
      "      1      70    7.0243    9.3650            10.5436  0.1 sec          81.2 sec             5.0000\n",
      "      1      71   12.2286   19.1215            17.7791  0.1 sec          82.4 sec             5.0000\n",
      "      1      72    8.5613   12.6365            12.3713  0.1 sec          83.7 sec             5.0000\n",
      "      1      73    8.3808   12.1517            11.2907  0.1 sec          84.9 sec             5.0000\n",
      "      1      74    6.5373    8.2430             7.6827  0.1 sec          86.0 sec             5.0000\n",
      "      1      75    6.1032    7.4249             8.0743  0.1 sec          87.2 sec             5.0000\n",
      "      1      76    6.1512    7.7989             8.9215  0.1 sec          88.3 sec             5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1      77    5.3321    5.7900             6.0906  0.1 sec          89.5 sec             5.0000\n",
      "      1      78   11.5386   18.4509            16.7002  0.1 sec          90.7 sec             5.0000\n",
      "      1      79    6.5211    8.5833            10.5330  0.1 sec          91.9 sec             5.0000\n",
      "      1      80    7.9249   11.2873            10.2916  0.1 sec          93.1 sec             5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      1      81    5.7056    6.5819             7.1210  0.1 sec          94.3 sec             5.0000\n",
      "      1      82   10.0465   15.7854            16.5251  0.1 sec          95.4 sec             5.0000\n",
      "      1      83    6.7631    8.7924            13.3872  0.1 sec          96.5 sec             5.0000\n",
      "      1      84    6.4860    8.3591             7.4348  0.1 sec          97.6 sec             5.0000\n",
      "      1      85    6.0325    7.2749             6.8710  0.1 sec          98.7 sec             5.0000\n",
      "      1      86    5.7656    6.7091             7.1884  0.1 sec          99.8 sec             5.0000\n",
      "      1      87    6.8799    9.0716             6.9253  0.1 sec          101.0 sec            5.0000\n",
      "      1      88    7.0319    9.2917            11.9316  0.1 sec          102.1 sec            5.0000\n",
      "      1      89    5.5343    6.2186             7.4017  0.1 sec          103.2 sec            5.0000\n",
      "      1      90    6.6008    8.4799             6.9363  0.1 sec          104.3 sec            5.0000\n",
      "      1      91    6.0221    7.3754             7.9498  0.1 sec          105.5 sec            5.0000\n",
      "      1      92    8.6321   12.7691             9.6829  0.1 sec          106.7 sec            5.0000\n",
      "      1      93    6.2492    7.8570            10.0108  0.1 sec          107.8 sec            5.0000\n",
      "      1      94    8.7065   12.7906            13.2106  0.1 sec          109.0 sec            5.0000\n",
      "      1      95    7.0598    9.4529            11.8711  0.1 sec          110.2 sec            5.0000\n",
      "      1      96    6.2604    7.7580             9.4203  0.1 sec          111.3 sec            5.0000\n",
      "      1      97    5.7163    6.6045             5.3621  0.1 sec          112.5 sec            5.0000\n",
      "      1      98    5.3079    5.7387             5.0817  0.1 sec          113.6 sec            5.0000\n",
      "      1      99    5.6541    6.5953             7.0950  0.1 sec          114.8 sec            5.0000\n",
      "      1     100    6.0051    7.2168             5.8668  0.1 sec          115.9 sec            5.0000\n",
      "      1     101    6.0175    7.2431             6.3827  0.1 sec          117.2 sec            5.0000\n",
      "      1     102    6.2690    7.7763             7.4257  0.1 sec          118.4 sec            5.0000\n",
      "      1     103   10.2797   16.2799            14.7810  0.1 sec          119.5 sec            5.0000\n",
      "      1     104    7.0500    9.4323            10.1907  0.1 sec          120.6 sec            5.0000\n",
      "      1     105    6.1553    7.6579             8.7154  0.1 sec          121.8 sec            5.0000\n",
      "      1     106    5.7373    6.6491             7.8464  0.1 sec          122.9 sec            5.0000\n",
      "      1     107    5.2447    5.6046             6.6246  0.1 sec          124.1 sec            5.0000\n",
      "      1     108    5.6978    6.5654             6.0163  0.1 sec          125.3 sec            5.0000\n",
      "      1     109    6.5251    8.5864            10.0338  0.1 sec          126.3 sec            5.0000\n",
      "      1     110    4.9796    5.0425             5.8498  0.1 sec          127.5 sec            5.0000\n",
      "      1     111    5.3751    5.8811             6.9145  0.1 sec          128.7 sec            5.0000\n",
      "      1     112    7.0500    9.4323            10.4415  0.1 sec          129.8 sec            5.0000\n",
      "      1     113    9.3320   13.9957            17.8290  0.1 sec          130.9 sec            5.0000\n",
      "      1     114    6.6482    8.5804            11.7038  0.1 sec          132.0 sec            5.0000\n",
      "      1     115    6.8860    9.0844             6.7352  0.1 sec          133.2 sec            5.0000\n",
      "      1     116    6.1014    7.4209             7.9611  0.1 sec          134.4 sec            5.0000\n",
      "      1     117    7.4466   10.2731             9.6194  0.1 sec          135.6 sec            5.0000\n",
      "      1     118    6.3150    7.9965             8.1769  0.1 sec          136.7 sec            5.0000\n",
      "      1     119    9.0202   13.4213            15.1207  0.1 sec          137.9 sec            5.0000\n",
      "      1     120    5.0244    5.1376             4.6737  0.1 sec          139.0 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      1     121    8.6792   12.7843            15.0210  0.1 sec          140.2 sec            5.0000\n",
      "      1     122    7.1460    9.6251            11.7626  0.1 sec          141.4 sec            5.0000\n",
      "      1     123    6.3755    8.0021             6.1510  0.1 sec          142.5 sec            5.0000\n",
      "      1     124    6.9586    9.2385            11.8298  0.1 sec          143.7 sec            5.0000\n",
      "      1     125    8.8560   12.7684            18.6680  0.1 sec          144.9 sec            5.0000\n",
      "      1     126    5.7757    6.7305             7.7472  0.1 sec          146.0 sec            5.0000\n",
      "      1     127    5.9323    7.0626             7.7143  0.1 sec          147.2 sec            5.0000\n",
      "      1     128    6.7834    8.7428            11.5528  0.1 sec          148.4 sec            5.0000\n",
      "      1     129   10.5016   16.7504            18.0636  0.1 sec          149.5 sec            5.0000\n",
      "      1     130    7.8181   10.5183            14.0963  0.1 sec          150.6 sec            5.0000\n",
      "      1     131    6.9881    9.3011             8.6526  0.1 sec          151.8 sec            5.0000\n",
      "      1     132    5.8946    7.1051             7.6802  0.1 sec          152.9 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      2       1    7.2675    9.8933            10.8650  0.1 sec          154.1 sec            5.0000\n",
      "      2       2    7.9650   11.1534            13.6108  0.1 sec          155.3 sec            5.0000\n",
      "      2       3    5.6012    6.3606             6.4893  0.1 sec          156.4 sec            5.0000\n",
      "      2       4    5.6073    6.3734             6.6631  0.1 sec          157.5 sec            5.0000\n",
      "      2       5    7.3090    9.9813            10.7330  0.1 sec          158.7 sec            5.0000\n",
      "      2       6   11.7248   18.7575            19.7142  0.1 sec          159.8 sec            5.0000\n",
      "      2       7    9.0974   13.7625            13.6745  0.1 sec          160.9 sec            5.0000\n",
      "      2       8    7.2941   10.2222             7.8538  0.1 sec          162.1 sec            5.0000\n",
      "      2       9    5.8832    6.9584             8.1819  0.1 sec          163.3 sec            5.0000\n",
      "      2      10    5.6656    6.4970             5.7137  0.1 sec          164.4 sec            5.0000\n",
      "      2      11    7.0011    9.3286             7.1108  0.1 sec          165.5 sec            5.0000\n",
      "      2      12    6.1498    7.5236             8.3831  0.1 sec          166.7 sec            5.0000\n",
      "      2      13    5.7840    6.7480             7.1066  0.1 sec          167.8 sec            5.0000\n",
      "      2      14    6.2821    7.9266             7.4603  0.1 sec          169.0 sec            5.0000\n",
      "      2      15    8.5460   11.9775             8.8935  0.1 sec          170.2 sec            5.0000\n",
      "      2      16    5.8746    6.9402             8.1537  0.1 sec          171.3 sec            5.0000\n",
      "      2      17    5.4223    5.9811             6.0818  0.1 sec          172.5 sec            5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2      18    9.0425   13.4206            15.8849  0.1 sec          173.7 sec            5.0000\n",
      "      2      19    5.5399    6.2306             6.7181  0.1 sec          174.9 sec            5.0000\n",
      "      2      20    8.5781   12.6721            12.8208  0.1 sec          176.0 sec            5.0000\n",
      "      2      21   11.9798   18.2142            20.2894  0.1 sec          177.2 sec            5.0000\n",
      "      2      22    5.8662    7.0450             7.1626  0.1 sec          178.3 sec            5.0000\n",
      "      2      23    5.6302    6.4220             6.8859  0.1 sec          179.5 sec            5.0000\n",
      "      2      24    7.6113   10.5202             9.4203  0.1 sec          180.7 sec            5.0000\n",
      "      2      25    7.2312    9.7619            13.0194  0.1 sec          181.9 sec            5.0000\n",
      "      2      26   11.3107   17.5347            20.0041  0.1 sec          182.9 sec            5.0000\n",
      "      2      27    6.2830    7.8060             6.0755  0.1 sec          184.1 sec            5.0000\n",
      "      2      28    7.3144    9.9929             8.8741  0.1 sec          185.2 sec            5.0000\n",
      "      2      29    6.2208    7.6742             7.9723  0.1 sec          186.4 sec            5.0000\n",
      "      2      30    7.4307   10.2394             9.6158  0.1 sec          187.6 sec            5.0000\n",
      "      2      31    7.2764    9.7595            11.8397  0.1 sec          188.9 sec            5.0000\n",
      "      2      32    5.5292    6.3303             5.9339  0.1 sec          190.0 sec            5.0000\n",
      "      2      33    6.5460    8.3636             8.1554  0.1 sec          191.2 sec            5.0000\n",
      "      2      34    5.6693    6.6274             5.9050  0.1 sec          192.4 sec            5.0000\n",
      "      2      35    5.5893    6.3352             5.5009  0.1 sec          193.5 sec            5.0000\n",
      "      2      36    6.2068    7.6445             7.1402  0.1 sec          194.7 sec            5.0000\n",
      "      2      37    5.4905    6.1259             6.7441  0.1 sec          195.8 sec            5.0000\n",
      "      2      38    7.1205    9.5816             9.0383  0.1 sec          197.0 sec            5.0000\n",
      "      2      39    6.3023    7.9695             9.9867  0.1 sec          198.1 sec            5.0000\n",
      "      2      40    6.0842    7.3846             6.3052  0.1 sec          199.3 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      2      41    6.2283    7.6901             6.8457  0.1 sec          200.5 sec            5.0000\n",
      "      2      42    5.9484    7.2192            10.4442  0.1 sec          201.7 sec            5.0000\n",
      "      2      43    7.7335    9.4473            10.7862  0.1 sec          202.9 sec            5.0000\n",
      "      2      44    4.6279    4.4194             5.3778  0.1 sec          204.1 sec            5.0000\n",
      "      2      45    5.5628    6.2790             5.9629  0.1 sec          205.2 sec            5.0000\n",
      "      2      46    5.7609    6.6990             6.0665  0.1 sec          206.3 sec            5.0000\n",
      "      2      47    8.8628   13.0284            12.8744  0.1 sec          207.5 sec            5.0000\n",
      "      2      48    6.0992    7.3142             6.2943  0.1 sec          208.7 sec            5.0000\n",
      "      2      49    6.1488    7.5216             9.1774  0.1 sec          209.8 sec            5.0000\n",
      "      2      50    7.7095   10.8035             9.5964  0.1 sec          211.0 sec            5.0000\n",
      "      2      51    5.3619    5.9757             7.5281  0.1 sec          212.1 sec            5.0000\n",
      "      2      52    6.0435    7.2983             7.4002  0.1 sec          213.3 sec            5.0000\n",
      "      2      53    7.0863    9.5091            10.4005  0.1 sec          214.5 sec            5.0000\n",
      "      2      54    6.6824    8.7755            10.5906  0.1 sec          215.7 sec            5.0000\n",
      "      2      55    5.3693    5.8688             5.2306  0.1 sec          216.8 sec            5.0000\n",
      "      2      56    7.0010    9.3283            14.2861  0.1 sec          217.9 sec            5.0000\n",
      "      2      57    6.1181    7.4564             8.6080  0.1 sec          219.3 sec            5.0000\n",
      "      2      58    5.0290    5.1473             5.2503  0.1 sec          220.5 sec            5.0000\n",
      "      2      59    7.4713   10.3254             9.3638  0.1 sec          221.7 sec            5.0000\n",
      "      2      60    5.5996    6.3571             5.2274  0.1 sec          222.9 sec            5.0000\n",
      "      2      61    5.7914    6.7637             6.3509  0.1 sec          224.0 sec            5.0000\n",
      "      2      62    5.3803    5.8921             6.6271  0.1 sec          225.1 sec            5.0000\n",
      "      2      63    6.3669    7.9839             8.7765  0.1 sec          226.2 sec            5.0000\n",
      "      2      64    5.9660    7.1339             7.4694  0.1 sec          227.4 sec            5.0000\n",
      "      2      65    6.5275    8.3244             6.1783  0.1 sec          228.5 sec            5.0000\n",
      "      2      66    5.3027    6.1873             6.3017  0.1 sec          229.6 sec            5.0000\n",
      "      2      67    5.1048    5.5805             6.1912  0.1 sec          230.8 sec            5.0000\n",
      "      2      68    8.4824   12.4692            12.8966  0.1 sec          231.8 sec            5.0000\n",
      "      2      69    5.9624    7.2488             9.7924  0.1 sec          233.0 sec            5.0000\n",
      "      2      70    6.4804    8.2246            10.7934  0.1 sec          234.1 sec            5.0000\n",
      "      2      71    6.5865    8.4496             5.8268  0.1 sec          235.3 sec            5.0000\n",
      "      2      72    6.2780    7.7954             7.7023  0.1 sec          236.6 sec            5.0000\n",
      "      2      73    6.8803    8.9702             7.6364  0.1 sec          237.7 sec            5.0000\n",
      "      2      74    4.9610    4.9010             5.3542  0.1 sec          238.8 sec            5.0000\n",
      "      2      75    5.9974    7.2005             8.6034  0.1 sec          240.0 sec            5.0000\n",
      "      2      76    6.2159    7.9361             9.1856  0.1 sec          241.2 sec            5.0000\n",
      "      2      77    5.4627    6.0669             6.7278  0.1 sec          242.3 sec            5.0000\n",
      "      2      78    6.6475    8.5789             6.6882  0.1 sec          243.5 sec            5.0000\n",
      "      2      79    5.3908    6.1867             7.7226  0.1 sec          244.7 sec            5.0000\n",
      "      2      80    6.7008    8.6918             7.1169  0.1 sec          245.8 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      2      81    5.4452    6.0298             6.5137  0.1 sec          247.1 sec            5.0000\n",
      "      2      82    9.6056   14.8505            15.4198  0.2 sec          248.4 sec            5.0000\n",
      "      2      83    7.1335    9.5594            13.9982  0.1 sec          249.7 sec            5.0000\n",
      "      2      84    5.7026    6.6981             5.9872  0.1 sec          250.8 sec            5.0000\n",
      "      2      85    5.9386    7.0759             6.5149  0.1 sec          252.0 sec            5.0000\n",
      "      2      86    5.6360    6.4342             6.9743  0.1 sec          253.1 sec            5.0000\n",
      "      2      87    6.5233    8.3155            12.5277  0.1 sec          254.3 sec            5.0000\n",
      "      2      88    5.7273    6.5257             8.4598  0.1 sec          255.5 sec            5.0000\n",
      "      2      89    5.7091    6.5892             6.8883  0.1 sec          256.5 sec            5.0000\n",
      "      2      90    6.0977    7.4132             8.4734  0.1 sec          257.7 sec            5.0000\n",
      "      2      91    5.7997    6.9038             6.3396  0.1 sec          258.8 sec            5.0000\n",
      "      2      92    7.6047   10.6083             8.9200  0.1 sec          259.9 sec            5.0000\n",
      "      2      93    6.5182    8.4273             9.5488  0.1 sec          261.1 sec            5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2      94    7.3753    9.9222            11.5594  0.1 sec          262.3 sec            5.0000\n",
      "      2      95    5.6876    6.5437             7.4098  0.1 sec          263.5 sec            5.0000\n",
      "      2      96    6.5156    8.2993             8.7777  0.1 sec          264.6 sec            5.0000\n",
      "      2      97    7.5926   10.5827            10.0937  0.1 sec          265.8 sec            5.0000\n",
      "      2      98    6.0530    7.3183             7.4318  0.1 sec          266.9 sec            5.0000\n",
      "      2      99    4.9198    5.0384             6.4580  0.1 sec          268.1 sec            5.0000\n",
      "      2     100    5.5745    6.3039             5.6753  0.1 sec          269.3 sec            5.0000\n",
      "      2     101    5.6447    6.4528             6.3795  0.1 sec          270.5 sec            5.0000\n",
      "      2     102    7.9881   11.4211            10.9247  0.1 sec          271.7 sec            5.0000\n",
      "      2     103    7.4709   10.3245             8.2435  0.1 sec          272.8 sec            5.0000\n",
      "      2     104    7.9687   11.3801            12.6202  0.1 sec          273.9 sec            5.0000\n",
      "      2     105    7.8910   11.3379            12.4953  0.1 sec          274.9 sec            5.0000\n",
      "      2     106    5.9295    7.0566             7.1699  0.1 sec          276.0 sec            5.0000\n",
      "      2     107    5.3986    5.9310             5.5772  0.1 sec          277.2 sec            5.0000\n",
      "      2     108    4.9412    4.9611             4.8119  0.1 sec          278.4 sec            5.0000\n",
      "      2     109    6.5739    8.6951             9.4821  0.1 sec          279.4 sec            5.0000\n",
      "      2     110    4.8127    4.6887             4.5746  0.1 sec          280.5 sec            5.0000\n",
      "      2     111    6.0346    7.2794             7.6173  0.1 sec          281.7 sec            5.0000\n",
      "      2     112    6.0162    7.2403             7.0717  0.1 sec          282.9 sec            5.0000\n",
      "      2     113    6.7873    8.8226            10.0547  0.1 sec          284.0 sec            5.0000\n",
      "      2     114    6.6837    8.6556             7.6446  0.1 sec          285.1 sec            5.0000\n",
      "      2     115    5.7355    6.6453             8.2243  0.1 sec          286.2 sec            5.0000\n",
      "      2     116    5.5859    6.3281             7.9809  0.1 sec          287.4 sec            5.0000\n",
      "      2     117    6.3618    7.9731            10.4324  0.1 sec          288.5 sec            5.0000\n",
      "      2     118    5.5609    6.3976             9.0930  0.1 sec          289.6 sec            5.0000\n",
      "      2     119    5.8136    6.8108             8.3337  0.1 sec          290.7 sec            5.0000\n",
      "      2     120    5.2513    5.6186             5.0072  0.1 sec          291.8 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      2     121    9.2748   14.0471            16.4052  0.1 sec          293.0 sec            5.0000\n",
      "      2     122    9.0144   13.2507            15.5210  0.1 sec          294.1 sec            5.0000\n",
      "      2     123    6.5296    8.3288             7.0201  0.1 sec          295.3 sec            5.0000\n",
      "      2     124    7.2051    9.7541            13.0838  0.1 sec          296.5 sec            5.0000\n",
      "      2     125    6.0706    7.3558             8.4450  0.1 sec          297.6 sec            5.0000\n",
      "      2     126    5.1372    5.3766             6.6302  0.1 sec          298.7 sec            5.0000\n",
      "      2     127    4.8152    4.6940             4.8132  0.1 sec          299.9 sec            5.0000\n",
      "      2     128    8.1969   11.7049            11.5506  0.1 sec          301.1 sec            5.0000\n",
      "      2     129    8.1883   11.8456            12.7431  0.1 sec          302.3 sec            5.0000\n",
      "      2     130    7.1943    9.6673            10.5651  0.1 sec          303.4 sec            5.0000\n",
      "      2     131    7.4639   10.2902             8.6240  0.1 sec          304.5 sec            5.0000\n",
      "      2     132    6.5607    8.5174             9.0075  0.1 sec          305.7 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      3       1    7.4895   10.3640            12.3629  0.1 sec          306.8 sec            5.0000\n",
      "      3       2    7.8658   10.9921            13.0642  0.1 sec          307.9 sec            5.0000\n",
      "      3       3   10.3031   16.1731            15.9764  0.1 sec          309.1 sec            5.0000\n",
      "      3       4    5.8262    6.8374             7.3369  0.1 sec          310.2 sec            5.0000\n",
      "      3       5    5.8868    6.9659             7.2456  0.1 sec          311.4 sec            5.0000\n",
      "      3       6    9.5756   14.7870            15.7317  0.1 sec          312.5 sec            5.0000\n",
      "      3       7    6.8947    9.1029             8.9895  0.1 sec          313.7 sec            5.0000\n",
      "      3       8    5.1441    5.6637             5.7422  0.1 sec          314.9 sec            5.0000\n",
      "      3       9    5.8900    6.9727             8.5810  0.1 sec          316.0 sec            5.0000\n",
      "      3      10    5.4536    6.0476             6.5875  0.1 sec          317.1 sec            5.0000\n",
      "      3      11    6.0770    7.3693             7.1384  0.1 sec          318.3 sec            5.0000\n",
      "      3      12    7.0139    9.3557            12.0174  0.1 sec          319.4 sec            5.0000\n",
      "      3      13    6.6352    8.5528             9.0349  0.1 sec          320.6 sec            5.0000\n",
      "      3      14    6.5914    8.5825             9.3449  0.1 sec          321.7 sec            5.0000\n",
      "      3      15    8.7804   12.4617             9.3616  0.1 sec          322.9 sec            5.0000\n",
      "      3      16    5.9106    7.0165             8.7328  0.1 sec          324.0 sec            5.0000\n",
      "      3      17    5.8898    6.9724             7.4524  0.1 sec          325.2 sec            5.0000\n",
      "      3      18    5.8217    6.9506             6.1237  0.1 sec          326.4 sec            5.0000\n",
      "      3      19    5.5148    6.1774             6.1651  0.1 sec          327.6 sec            5.0000\n",
      "      3      20    5.7014    6.5729             5.9131  0.1 sec          328.7 sec            5.0000\n",
      "      3      21   10.0934   15.5711            19.7537  0.1 sec          329.9 sec            5.0000\n",
      "      3      22    6.0466    7.4274             7.5491  0.1 sec          331.1 sec            5.0000\n",
      "      3      23    6.1466    7.5170             8.4121  0.1 sec          332.3 sec            5.0000\n",
      "      3      24    6.1912    7.5093             5.8251  0.1 sec          333.4 sec            5.0000\n",
      "      3      25    6.7420    8.7696            11.4953  0.1 sec          334.7 sec            5.0000\n",
      "      3      26    6.4206    8.0978             9.6726  0.1 sec          335.8 sec            5.0000\n",
      "      3      27    5.4068    5.9482             7.5538  0.1 sec          337.0 sec            5.0000\n",
      "      3      28    6.8481    9.0041             8.1895  0.1 sec          338.1 sec            5.0000\n",
      "      3      29    5.5750    6.3050             5.4732  0.1 sec          339.2 sec            5.0000\n",
      "      3      30    6.4262    8.1096             8.7438  0.1 sec          340.4 sec            5.0000\n",
      "      3      31    6.8774    8.9643            11.3252  0.1 sec          341.6 sec            5.0000\n",
      "      3      32    4.8175    4.8215             4.5557  0.1 sec          342.8 sec            5.0000\n",
      "      3      33    7.3322   10.0304             9.6686  0.1 sec          344.0 sec            5.0000\n",
      "      3      34    5.6194    6.5216             6.1975  0.1 sec          345.3 sec            5.0000\n",
      "      3      35    5.8949    6.9833             6.3191  0.1 sec          346.4 sec            5.0000\n",
      "      3      36    6.9578    9.2369             8.1670  0.1 sec          347.6 sec            5.0000\n",
      "      3      37    6.0081    7.2233             7.0306  0.1 sec          348.7 sec            5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3      38    8.0764   11.6084            11.2094  0.1 sec          350.0 sec            5.0000\n",
      "      3      39    6.8958    9.2279             9.0347  0.1 sec          351.1 sec            5.0000\n",
      "      3      40    6.4949    8.2552             7.8474  0.1 sec          352.3 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      3      41    5.5898    6.3363             6.3004  0.1 sec          353.5 sec            5.0000\n",
      "      3      42    5.5667    6.4098             8.2217  0.1 sec          354.6 sec            5.0000\n",
      "      3      43    8.2642   11.1676            11.8531  0.1 sec          355.8 sec            5.0000\n",
      "      3      44    5.2457    5.7293             7.1388  0.1 sec          357.0 sec            5.0000\n",
      "      3      45    7.0324    9.3950             9.6088  0.1 sec          358.1 sec            5.0000\n",
      "      3      46    5.3877    5.9078             5.4638  0.1 sec          359.3 sec            5.0000\n",
      "      3      47    7.7319   10.8779            11.2732  0.1 sec          360.5 sec            5.0000\n",
      "      3      48    5.3857    5.8015             5.6120  0.1 sec          361.8 sec            5.0000\n",
      "      3      49    5.7300    6.6335             7.0299  0.1 sec          362.8 sec            5.0000\n",
      "      3      50    8.3661   12.1502             7.5962  0.1 sec          364.0 sec            5.0000\n",
      "      3      51    5.4343    6.1292             5.6740  0.1 sec          365.2 sec            5.0000\n",
      "      3      52    5.5511    6.2543             6.3501  0.1 sec          366.4 sec            5.0000\n",
      "      3      53    6.1147    7.4492             7.5728  0.1 sec          367.5 sec            5.0000\n",
      "      3      54    5.7602    6.8202             7.7272  0.1 sec          368.7 sec            5.0000\n",
      "      3      55    5.1843    5.4766             5.2303  0.1 sec          369.8 sec            5.0000\n",
      "      3      56    5.3318    5.7893             5.9670  0.1 sec          371.0 sec            5.0000\n",
      "      3      57    5.5919    6.3408             6.3887  0.1 sec          372.1 sec            5.0000\n",
      "      3      58    4.8613    4.7918             5.3831  0.1 sec          373.3 sec            5.0000\n",
      "      3      59    6.7412    8.7775             8.0232  0.1 sec          374.5 sec            5.0000\n",
      "      3      60    5.9574    7.1157             5.9375  0.1 sec          375.8 sec            5.0000\n",
      "      3      61    5.3858    5.9038             6.8138  0.1 sec          377.0 sec            5.0000\n",
      "      3      62    5.3570    5.8428             6.4941  0.1 sec          378.1 sec            5.0000\n",
      "      3      63    5.9477    7.0952             8.6138  0.1 sec          379.4 sec            5.0000\n",
      "      3      64    5.5243    6.1975             7.9886  0.1 sec          380.6 sec            5.0000\n",
      "      3      65    6.2586    7.7542             7.0042  0.1 sec          381.7 sec            5.0000\n",
      "      3      66    8.0333   11.9766            13.0037  0.1 sec          382.8 sec            5.0000\n",
      "      3      67    5.0767    5.5208             6.1881  0.1 sec          384.0 sec            5.0000\n",
      "      3      68    9.1307   13.8437            15.0435  0.1 sec          385.1 sec            5.0000\n",
      "      3      69    5.7099    6.7135             9.0112  0.1 sec          386.3 sec            5.0000\n",
      "      3      70    6.4449    8.1492            10.6012  0.1 sec          387.5 sec            5.0000\n",
      "      3      71    5.7859    6.7522             7.2928  0.1 sec          388.8 sec            5.0000\n",
      "      3      72    5.5840    6.3241             7.2158  0.1 sec          390.1 sec            5.0000\n",
      "      3      73    7.0656    9.3632             9.0028  0.1 sec          391.3 sec            5.0000\n",
      "      3      74    5.3502    5.7262             6.7189  0.1 sec          392.4 sec            5.0000\n",
      "      3      75    5.9180    7.0322             7.9834  0.1 sec          393.7 sec            5.0000\n",
      "      3      76    6.0547    7.5944             8.4070  0.1 sec          394.9 sec            5.0000\n",
      "      3      77    5.1788    5.4649             5.6091  0.1 sec          396.0 sec            5.0000\n",
      "      3      78    6.1235    7.4678             6.3602  0.1 sec          397.2 sec            5.0000\n",
      "      3      79    5.3069    6.0089             7.5169  0.1 sec          398.3 sec            5.0000\n",
      "      3      80    5.8242    6.8332             4.9596  0.1 sec          399.5 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      3      81    5.5246    6.1981             6.8989  0.1 sec          400.7 sec            5.0000\n",
      "      3      82    8.7838   13.1083            13.5382  0.1 sec          401.8 sec            5.0000\n",
      "      3      83    5.6623    6.4900             8.9688  0.1 sec          403.0 sec            5.0000\n",
      "      3      84    5.2426    5.7228             6.1617  0.1 sec          404.0 sec            5.0000\n",
      "      3      85    5.7667    6.7113             5.7484  0.1 sec          405.1 sec            5.0000\n",
      "      3      86    5.5506    6.2531             6.5840  0.1 sec          406.2 sec            5.0000\n",
      "      3      87    6.3901    8.0332            11.9322  0.1 sec          407.3 sec            5.0000\n",
      "      3      88    5.5363    6.1207             8.0403  0.1 sec          408.4 sec            5.0000\n",
      "      3      89    5.5102    6.1675             5.4796  0.1 sec          409.5 sec            5.0000\n",
      "      3      90    6.0996    7.4172             8.4864  0.1 sec          410.7 sec            5.0000\n",
      "      3      91    5.7670    6.8345             6.3649  0.1 sec          411.7 sec            5.0000\n",
      "      3      92    5.7651    6.7081             6.6633  0.1 sec          412.8 sec            5.0000\n",
      "      3      93    6.8429    9.1156             9.4202  0.1 sec          414.0 sec            5.0000\n",
      "      3      94    7.5811   10.3187            11.8372  0.1 sec          415.2 sec            5.0000\n",
      "      3      95    5.5609    6.2751             7.2536  0.1 sec          416.3 sec            5.0000\n",
      "      3      96    5.9174    7.0309             8.1128  0.1 sec          417.5 sec            5.0000\n",
      "      3      97    7.6760   10.7595            10.1977  0.1 sec          418.6 sec            5.0000\n",
      "      3      98    6.2982    7.8383             8.4819  0.1 sec          419.7 sec            5.0000\n",
      "      3      99    5.3505    5.9516             7.1692  0.1 sec          420.9 sec            5.0000\n",
      "      3     100    5.8214    6.8275             5.9192  0.1 sec          422.0 sec            5.0000\n",
      "      3     101    5.7385    6.6515             4.8254  0.1 sec          423.2 sec            5.0000\n",
      "      3     102    6.5754    8.4260             7.7499  0.1 sec          424.4 sec            5.0000\n",
      "      3     103    5.4463    6.0321             4.8547  0.1 sec          425.6 sec            5.0000\n",
      "      3     104    6.5712    8.4172             9.8708  0.1 sec          426.7 sec            5.0000\n",
      "      3     105    7.6868   10.9050            12.0043  0.1 sec          427.9 sec            5.0000\n",
      "      3     106    5.9690    7.1404             6.6160  0.1 sec          428.9 sec            5.0000\n",
      "      3     107    5.0766    5.2482             5.0978  0.1 sec          430.2 sec            5.0000\n",
      "      3     108    4.8004    4.6637             4.8829  0.1 sec          431.3 sec            4.9850\n",
      "      3     109    6.8105    9.1851            10.0947  0.1 sec          432.4 sec            5.0000\n",
      "      3     110    4.7863    4.6328             4.8567  0.1 sec          433.5 sec            5.0000\n",
      "      3     111    6.6958    8.6812             9.4291  0.1 sec          434.7 sec            5.0000\n",
      "      3     112    5.0535    5.1992             5.7072  0.1 sec          435.8 sec            5.0000\n",
      "      3     113    7.0376    9.1477             7.4049  0.1 sec          437.0 sec            5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3     114    7.6782   10.7640             8.6601  0.1 sec          438.1 sec            5.0000\n",
      "      3     115    6.2189    7.6702            10.8948  0.1 sec          439.2 sec            5.0000\n",
      "      3     116    5.7781    6.7356             8.3188  0.1 sec          440.3 sec            5.0000\n",
      "      3     117    6.3492    7.9464            11.0203  0.1 sec          441.5 sec            5.0000\n",
      "      3     118    5.4760    6.2177             9.2752  0.1 sec          442.6 sec            5.0000\n",
      "      3     119    5.3763    5.8837             7.4101  0.1 sec          443.7 sec            5.0000\n",
      "      3     120    5.3315    5.7887             5.0990  0.1 sec          444.8 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      3     121    9.0993   13.6745            15.7340  0.1 sec          446.0 sec            5.0000\n",
      "      3     122    9.1695   13.7247            15.6407  0.1 sec          447.2 sec            5.0000\n",
      "      3     123    6.3672    7.9845             6.4893  0.1 sec          448.3 sec            5.0000\n",
      "      3     124    6.4346    8.1275            10.2453  0.1 sec          449.5 sec            5.0000\n",
      "      3     125    6.4600    8.1813             7.5839  0.1 sec          450.6 sec            5.0000\n",
      "      3     126    5.1792    5.4657             5.6249  0.1 sec          451.8 sec            5.0000\n",
      "      3     127    5.0006    5.0871             5.7705  0.1 sec          453.1 sec            5.0000\n",
      "      3     128    8.9658   13.3241            12.1949  0.1 sec          454.4 sec            5.0000\n",
      "      3     129    7.3001    9.9624            10.5528  0.1 sec          455.6 sec            5.0000\n",
      "      3     130    7.4302   10.2250            10.7382  0.1 sec          456.7 sec            5.0000\n",
      "      3     131    6.7388    8.7724             7.3863  0.1 sec          457.9 sec            5.0000\n",
      "      3     132    5.8751    7.0638             7.4047  0.1 sec          459.0 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      4       1    6.2642    7.7661             9.3429  0.1 sec          460.2 sec            5.0000\n",
      "      4       2    7.2185    9.7670            12.4947  0.1 sec          461.3 sec            5.0000\n",
      "      4       3    9.2299   14.0369            13.8925  0.1 sec          462.4 sec            5.0000\n",
      "      4       4    5.2273    5.5677             5.9888  0.1 sec          463.6 sec            5.0000\n",
      "      4       5    5.8627    6.9150             6.9081  0.1 sec          464.7 sec            5.0000\n",
      "      4       6    8.8527   13.2543            13.4506  0.1 sec          465.9 sec            5.0000\n",
      "      4       7    6.2574    7.7518             7.9271  0.1 sec          467.0 sec            5.0000\n",
      "      4       8    5.1319    5.6378             7.2777  0.1 sec          468.2 sec            5.0000\n",
      "      4       9    5.7904    6.7616             7.3842  0.1 sec          469.3 sec            5.0000\n",
      "      4      10    5.2837    5.6874             5.9326  0.1 sec          470.5 sec            5.0000\n",
      "      4      11    6.0366    7.2836             6.9424  0.1 sec          471.7 sec            5.0000\n",
      "      4      12    6.7215    8.7358            10.5911  0.1 sec          472.8 sec            5.0000\n",
      "      4      13    5.9841    7.1723             7.2573  0.1 sec          474.0 sec            5.0000\n",
      "      4      14    6.2722    7.9058             7.6404  0.1 sec          475.1 sec            5.0000\n",
      "      4      15    8.2123   11.4500             8.2818  0.1 sec          476.3 sec            5.0000\n",
      "      4      16    5.8532    6.8949             8.0781  0.1 sec          477.4 sec            5.0000\n",
      "      4      17    5.8082    6.7995             6.7633  0.1 sec          478.7 sec            5.0000\n",
      "      4      18    6.4653    8.3150             6.5849  0.1 sec          479.8 sec            5.0000\n",
      "      4      19    5.6906    6.5501             5.1059  0.1 sec          481.0 sec            5.0000\n",
      "      4      20    4.8539    4.7762             5.4623  0.1 sec          482.1 sec            5.0000\n",
      "      4      21    7.9710   11.3848            15.5762  0.1 sec          483.2 sec            5.0000\n",
      "      4      22    5.8658    7.0441             7.6455  0.1 sec          484.4 sec            5.0000\n",
      "      4      23    5.7301    6.6338             7.6066  0.1 sec          485.5 sec            5.0000\n",
      "      4      24    5.6440    6.3492             5.5341  0.1 sec          486.7 sec            5.0000\n",
      "      4      25    6.3982    8.0504            10.4006  0.1 sec          487.8 sec            5.0000\n",
      "      4      26    5.0706    5.2354             7.1984  0.1 sec          488.9 sec            5.0000\n",
      "      4      27    5.3231    5.7708             7.0425  0.1 sec          490.1 sec            5.0000\n",
      "      4      28    6.9741    9.2713             8.7682  0.1 sec          491.2 sec            5.0000\n",
      "      4      29    5.5302    6.2100             5.4316  0.1 sec          492.3 sec            5.0000\n",
      "      4      30    6.3255    7.8962             8.3901  0.1 sec          493.6 sec            5.0000\n",
      "      4      31    6.8280    8.8688            11.1167  0.1 sec          494.8 sec            5.0000\n",
      "      4      32    4.8089    4.8032             4.5836  0.1 sec          495.9 sec            5.0000\n",
      "      4      33    6.4419    8.1430             7.8351  0.1 sec          497.1 sec            5.0000\n",
      "      4      34    5.9575    7.2384             6.4148  0.1 sec          498.2 sec            5.0000\n",
      "      4      35    5.6702    6.5068             5.7290  0.1 sec          499.3 sec            5.0000\n",
      "      4      36    6.1890    7.6068             7.1139  0.1 sec          500.5 sec            5.0000\n",
      "      4      37    5.6532    6.4708             6.7838  0.1 sec          501.6 sec            5.0000\n",
      "      4      38    8.3011   12.0848            11.9738  0.1 sec          502.7 sec            5.0000\n",
      "      4      39    6.5903    8.5801             8.7124  0.1 sec          503.8 sec            5.0000\n",
      "      4      40    6.5897    8.4562             8.6796  0.1 sec          504.9 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      4      41    6.3532    7.9548             7.5620  0.1 sec          506.1 sec            5.0000\n",
      "      4      42    5.1213    5.4656             5.4224  0.1 sec          507.2 sec            5.0000\n",
      "      4      43    7.8713   10.2093            11.4361  0.1 sec          508.3 sec            5.0000\n",
      "      4      44    4.7484    4.6749             5.0567  0.1 sec          509.5 sec            5.0000\n",
      "      4      45    7.1994    9.7489             8.7522  0.1 sec          510.7 sec            5.0000\n",
      "      4      46    5.3020    5.7262             5.3633  0.1 sec          511.8 sec            5.0000\n",
      "      4      47    8.0905   11.6373            12.0997  0.1 sec          513.0 sec            5.0000\n",
      "      4      48    6.4567    8.0722             8.7602  0.1 sec          514.3 sec            5.0000\n",
      "      4      49    6.1300    7.4816             8.4756  0.1 sec          515.4 sec            5.0000\n",
      "      4      50    7.3779   10.1275             8.0851  0.1 sec          516.6 sec            5.0000\n",
      "      4      51    5.2247    5.6848             7.9223  0.1 sec          517.7 sec            5.0000\n",
      "      4      52    5.2252    5.5634             4.9479  0.1 sec          518.9 sec            5.0000\n",
      "      4      53    6.4400    8.1389             7.8574  0.1 sec          520.1 sec            5.0000\n",
      "      4      54    5.2333    5.7031             6.1396  0.1 sec          521.2 sec            5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4      55    6.0383    7.2872             7.2709  0.1 sec          522.4 sec            5.0000\n",
      "      4      56    5.9803    7.1643             9.1759  0.1 sec          523.5 sec            5.0000\n",
      "      4      57    5.6606    6.4864             6.8643  0.1 sec          524.7 sec            5.0000\n",
      "      4      58    7.0250    9.3792            10.3767  0.1 sec          525.8 sec            5.0000\n",
      "      4      59    9.3616   14.3333            14.3476  0.1 sec          527.0 sec            5.0000\n",
      "      4      60    5.5412    6.2332             6.2319  0.1 sec          528.1 sec            5.0000\n",
      "      4      61    6.2236    7.6801             6.2935  0.1 sec          529.3 sec            5.0000\n",
      "      4      62    5.5680    6.2901             5.7491  0.1 sec          530.5 sec            5.0000\n",
      "      4      63    7.1965    9.7427            13.4003  0.1 sec          531.6 sec            5.0000\n",
      "      4      64    5.7016    6.5733             8.1827  0.1 sec          532.8 sec            5.0000\n",
      "      4      65    6.3499    7.9478             6.0368  0.1 sec          534.0 sec            5.0000\n",
      "      4      66    7.4698   10.7819            11.3430  0.1 sec          535.1 sec            5.0000\n",
      "      4      67    5.0176    5.3955             5.0397  0.1 sec          536.2 sec            5.0000\n",
      "      4      68    8.0473   11.5467            12.3125  0.1 sec          537.3 sec            5.0000\n",
      "      4      69    5.8483    7.0070             9.3461  0.1 sec          538.4 sec            5.0000\n",
      "      4      70    6.4870    8.2385            10.7449  0.1 sec          539.6 sec            5.0000\n",
      "      4      71    6.4134    8.0826             5.6822  0.1 sec          540.9 sec            5.0000\n",
      "      4      72    5.3001    5.7221             5.9818  0.1 sec          542.2 sec            5.0000\n",
      "      4      73    6.6486    8.4790             9.1668  0.1 sec          543.4 sec            5.0000\n",
      "      4      74    5.0550    5.1002             5.6066  0.1 sec          544.5 sec            5.0000\n",
      "      4      75    5.8767    6.9445             9.1962  0.1 sec          545.7 sec            5.0000\n",
      "      4      76    6.0779    7.6435             9.6581  0.1 sec          546.9 sec            5.0000\n",
      "      4      77    5.3524    5.8329             6.1091  0.1 sec          548.1 sec            5.0000\n",
      "      4      78    6.0925    7.4022             6.2783  0.1 sec          549.3 sec            5.0000\n",
      "      4      79    5.6964    6.8347             8.1950  0.1 sec          550.4 sec            5.0000\n",
      "      4      80    5.3656    5.8611             5.4980  0.1 sec          551.7 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      4      81    5.3544    5.8372             6.5108  0.1 sec          552.9 sec            5.0000\n",
      "      4      82    8.4021   12.2989            12.6217  0.1 sec          554.0 sec            5.0000\n",
      "      4      83    5.3156    5.7551             6.6861  0.1 sec          555.1 sec            5.0000\n",
      "      4      84    5.5741    6.4257             5.9710  0.1 sec          556.2 sec            5.0000\n",
      "      4      85    5.7370    6.6483             5.6240  0.1 sec          557.3 sec            5.0000\n",
      "      4      86    5.6072    6.3733             6.0581  0.1 sec          558.5 sec            5.0000\n",
      "      4      87    5.7897    6.7601             8.9483  0.1 sec          559.6 sec            5.0000\n",
      "      4      88    5.4677    5.9753             7.3266  0.1 sec          560.7 sec            5.0000\n",
      "      4      89    5.3979    5.9294             5.8727  0.1 sec          561.8 sec            5.0000\n",
      "      4      90    5.5117    6.1707             6.8908  0.1 sec          563.0 sec            5.0000\n",
      "      4      91    5.7005    6.6936             6.3131  0.1 sec          564.1 sec            5.0000\n",
      "      4      92    5.4165    5.9688             6.8931  0.1 sec          565.2 sec            5.0000\n",
      "      4      93    6.8064    9.0384             9.3474  0.1 sec          566.4 sec            5.0000\n",
      "      4      94    7.5202   10.0668            11.5002  0.1 sec          567.6 sec            5.0000\n",
      "      4      95    5.9572    7.1153             7.3032  0.1 sec          568.7 sec            5.0000\n",
      "      4      96    5.6058    6.3702             7.9428  0.1 sec          569.8 sec            5.0000\n",
      "      4      97    7.2184    9.7892             9.3082  0.1 sec          571.0 sec            5.0000\n",
      "      4      98    6.1905    7.6099             8.0708  0.1 sec          572.2 sec            5.0000\n",
      "      4      99    5.1418    5.5090             6.9472  0.1 sec          573.3 sec            5.0000\n",
      "      4     100    5.4179    5.9718             5.6995  0.1 sec          574.5 sec            5.0000\n",
      "      4     101    5.4054    5.9454             4.7676  0.1 sec          575.7 sec            5.0000\n",
      "      4     102    5.5520    6.2562             5.5959  0.1 sec          577.0 sec            5.0000\n",
      "      4     103    5.1497    5.4032             6.1916  0.1 sec          578.2 sec            5.0000\n",
      "      4     104    6.1280    7.4775             8.5935  0.1 sec          579.3 sec            5.0000\n",
      "      4     105    7.0584    9.5727            10.4067  0.1 sec          580.4 sec            5.0000\n",
      "      4     106    5.5950    6.3474             6.5546  0.1 sec          581.5 sec            5.0000\n",
      "      4     107    5.0419    5.1747             4.9705  0.1 sec          582.7 sec            5.0000\n",
      "      4     108    4.7151    4.4928             4.7179  0.1 sec          583.9 sec            4.9040\n",
      "      4     109    5.7970    7.0480             8.4596  0.1 sec          585.0 sec            5.0000\n",
      "      4     110    4.8502    4.7682             5.0978  0.1 sec          586.1 sec            5.0000\n",
      "      4     111    5.8177    6.8195             7.4066  0.1 sec          587.3 sec            5.0000\n",
      "      4     112    5.0951    5.2875             5.8845  0.1 sec          588.5 sec            5.0000\n",
      "      4     113    6.7639    8.7042             8.0610  0.1 sec          589.7 sec            5.0000\n",
      "      4     114    6.5579    8.3888             7.5926  0.1 sec          590.8 sec            5.0000\n",
      "      4     115    7.1441    9.6318             6.6190  0.1 sec          592.0 sec            5.0000\n",
      "      4     116    5.5506    6.2533             7.5137  0.1 sec          593.1 sec            5.0000\n",
      "      4     117    6.2987    7.8393            10.6366  0.1 sec          594.3 sec            5.0000\n",
      "      4     118    5.4923    6.2523             9.4416  0.1 sec          595.4 sec            5.0000\n",
      "      4     119    5.6966    6.5628             8.3662  0.1 sec          596.5 sec            5.0000\n",
      "      4     120    5.4409    6.0207             5.1763  0.1 sec          597.6 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      4     121    8.2277   11.8271            13.7270  0.1 sec          598.8 sec            5.0000\n",
      "      4     122    8.2717   12.0225            13.8985  0.1 sec          600.0 sec            5.0000\n",
      "      4     123    6.4009    8.0561             6.5219  0.1 sec          601.1 sec            5.0000\n",
      "      4     124    6.3213    7.8873             9.7383  0.1 sec          602.4 sec            5.0000\n",
      "      4     125    5.9770    7.1573             7.8039  0.1 sec          603.5 sec            5.0000\n",
      "      4     126    4.9943    5.0738             5.5469  0.1 sec          604.6 sec            5.0000\n",
      "      4     127    4.8229    4.7103             4.8996  0.1 sec          605.8 sec            5.0000\n",
      "      4     128    7.6549   10.5958            11.0398  0.1 sec          607.0 sec            5.0000\n",
      "      4     129    6.9062    9.1274             9.8384  0.1 sec          608.2 sec            5.0000\n",
      "      4     130    6.9425    9.0086            11.2467  0.1 sec          609.3 sec            5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4     131    6.9383    9.1954             7.8423  0.1 sec          610.4 sec            5.0000\n",
      "      4     132    5.4692    6.2031             6.4483  0.1 sec          611.6 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      5       1    6.1264    7.4740             8.7555  0.1 sec          612.8 sec            5.0000\n",
      "      5       2    7.2123    9.7569            12.2589  0.1 sec          614.0 sec            5.0000\n",
      "      5       3    7.7246   10.8625            10.7548  0.1 sec          615.1 sec            5.0000\n",
      "      5       4    5.1858    5.4798             5.8174  0.1 sec          616.2 sec            5.0000\n",
      "      5       5    6.2735    7.7859             7.9863  0.1 sec          617.4 sec            5.0000\n",
      "      5       6    9.4556   14.5325            14.9296  0.1 sec          618.5 sec            5.0000\n",
      "      5       7    5.6388    6.4403             6.4944  0.1 sec          619.7 sec            5.0000\n",
      "      5       8    7.6202   10.9135             9.5080  0.1 sec          620.9 sec            5.0000\n",
      "      5       9    5.5012    6.1486             6.8937  0.1 sec          622.0 sec            5.0000\n",
      "      5      10    5.5440    6.2393             7.0233  0.1 sec          623.1 sec            5.0000\n",
      "      5      11    5.7320    6.6378             7.2785  0.1 sec          624.2 sec            5.0000\n",
      "      5      12    6.0301    7.2698             8.2708  0.1 sec          625.4 sec            5.0000\n",
      "      5      13    5.4740    6.0909             5.8142  0.1 sec          626.6 sec            5.0000\n",
      "      5      14    6.0844    7.5075             7.0167  0.1 sec          627.8 sec            5.0000\n",
      "      5      15    7.3377    9.9437             7.1081  0.1 sec          629.0 sec            5.0000\n",
      "      5      16    5.6327    6.4272             7.4401  0.1 sec          630.3 sec            5.0000\n",
      "      5      17    5.7793    6.7381             6.0638  0.1 sec          631.7 sec            5.0000\n",
      "      5      18    5.7811    6.8644             6.6317  0.1 sec          632.9 sec            5.0000\n",
      "      5      19    5.2739    5.6666             5.5966  0.1 sec          634.1 sec            5.0000\n",
      "      5      20    4.8249    4.7146             4.9175  0.1 sec          635.3 sec            5.0000\n",
      "      5      21    6.8662    9.0425            12.8690  0.1 sec          636.5 sec            5.0000\n",
      "      5      22    5.6931    6.6778             7.0694  0.1 sec          637.7 sec            5.0000\n",
      "      5      23    4.9063    4.8872             5.4640  0.1 sec          638.9 sec            5.0000\n",
      "      5      24    5.1647    5.3329             5.6159  0.1 sec          640.0 sec            5.0000\n",
      "      5      25    5.9905    7.1858             8.8548  0.1 sec          641.2 sec            5.0000\n",
      "      5      26    6.3669    7.9840             7.7423  0.1 sec          642.2 sec            5.0000\n",
      "      5      27    5.2670    5.6520             5.0594  0.1 sec          643.7 sec            5.0000\n",
      "      5      28    5.8897    6.9721             6.6796  0.1 sec          645.0 sec            5.0000\n",
      "      5      29    5.6383    6.4391             5.6594  0.1 sec          646.1 sec            5.0000\n",
      "      5      30    6.1975    7.6249             8.2533  0.1 sec          647.4 sec            5.0000\n",
      "      5      31    6.8354    8.8821            11.1512  0.1 sec          648.7 sec            5.0000\n",
      "      5      32    4.9764    5.1585             5.1847  0.1 sec          649.8 sec            5.0000\n",
      "      5      33    5.2728    5.6642             5.0039  0.1 sec          651.0 sec            5.0000\n",
      "      5      34    6.4995    8.3876             7.6752  0.1 sec          652.2 sec            5.0000\n",
      "      5      35    5.7217    6.6160             5.8402  0.1 sec          653.3 sec            5.0000\n",
      "      5      36    6.4226    8.1021             6.5936  0.1 sec          654.5 sec            5.0000\n",
      "      5      37    5.6728    6.5123             6.8026  0.1 sec          655.6 sec            5.0000\n",
      "      5      38    7.3081    9.9794             9.5181  0.1 sec          656.8 sec            5.0000\n",
      "      5      39    7.8378   11.2250             9.3167  0.1 sec          657.9 sec            5.0000\n",
      "      5      40    6.7357    8.7659             9.0271  0.1 sec          659.1 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      5      41    5.9678    7.1378             6.6430  0.1 sec          660.3 sec            5.0000\n",
      "      5      42    5.0441    5.3018             5.4644  0.1 sec          661.4 sec            5.0000\n",
      "      5      43    9.5204   13.5345            13.5570  0.1 sec          662.6 sec            5.0000\n",
      "      5      44    4.8445    4.8787             5.7734  0.1 sec          663.8 sec            5.0000\n",
      "      5      45    6.5489    8.3698             7.6058  0.1 sec          665.1 sec            5.0000\n",
      "      5      46    5.3175    5.7590             5.3553  0.2 sec          666.3 sec            5.0000\n",
      "      5      47    8.0379   11.5245            12.0139  0.1 sec          667.5 sec            5.0000\n",
      "      5      48    5.3463    5.7179             4.8285  0.1 sec          668.7 sec            5.0000\n",
      "      5      49    5.7013    6.5727             7.1921  0.1 sec          669.8 sec            5.0000\n",
      "      5      50    7.7035   10.8127             7.6388  0.1 sec          671.0 sec            5.0000\n",
      "      5      51    5.1773    5.5842             6.4230  0.1 sec          672.1 sec            5.0000\n",
      "      5      52    5.5232    6.1952             5.4501  0.1 sec          673.2 sec            5.0000\n",
      "      5      53    5.6857    6.5397             6.2702  0.1 sec          674.3 sec            5.0000\n",
      "      5      54    5.6096    6.5008             7.2352  0.1 sec          675.5 sec            5.0000\n",
      "      5      55    6.1876    7.6039             7.8094  0.1 sec          676.6 sec            5.0000\n",
      "      5      56    7.5457   10.4832            13.4800  0.1 sec          677.9 sec            5.0000\n",
      "      5      57    5.3901    5.9130             5.3141  0.1 sec          679.1 sec            5.0000\n",
      "      5      58    5.1399    5.3825             5.6038  0.1 sec          680.3 sec            5.0000\n",
      "      5      59    6.1633    7.5523             6.8878  0.1 sec          681.4 sec            5.0000\n",
      "      5      60    4.8001    4.6619             5.0132  0.1 sec          682.7 sec            5.0000\n",
      "      5      61    5.3290    5.7835             6.6678  0.1 sec          683.9 sec            5.0000\n",
      "      5      62    5.7672    6.7125             6.1283  0.1 sec          685.0 sec            5.0000\n",
      "      5      63    6.4605    8.1823            11.0615  0.1 sec          686.2 sec            5.0000\n",
      "      5      64    6.0757    7.3665             7.7953  0.1 sec          687.3 sec            5.0000\n",
      "      5      65    6.5184    8.3051             6.5080  0.1 sec          688.4 sec            5.0000\n",
      "      5      66    6.5257    8.7801             9.2422  0.1 sec          689.5 sec            5.0000\n",
      "      5      67    5.0349    5.4321             5.3359  0.1 sec          690.6 sec            5.0000\n",
      "      5      68    6.9322    9.1824             9.7190  0.1 sec          691.7 sec            5.0000\n",
      "      5      69    5.5627    6.4014             8.9276  0.1 sec          692.9 sec            5.0000\n",
      "      5      70    6.4789    8.2215            10.2810  0.1 sec          694.1 sec            5.0000\n",
      "      5      71    5.6551    6.4748             6.8765  0.1 sec          695.2 sec            5.0000\n",
      "      5      72    5.4490    6.0377             6.2576  0.1 sec          696.5 sec            5.0000\n",
      "      5      73    6.3669    7.8818             8.1225  0.1 sec          697.7 sec            5.0000\n",
      "      5      74    5.4887    6.0198             7.0770  0.1 sec          698.8 sec            5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5      75    5.9181    7.0325             8.2740  0.1 sec          700.0 sec            5.0000\n",
      "      5      76    6.1860    7.8728             9.6854  0.1 sec          701.2 sec            5.0000\n",
      "      5      77    5.5353    6.2207             6.6810  0.1 sec          702.3 sec            5.0000\n",
      "      5      78    5.8964    6.9863             6.2322  0.1 sec          703.5 sec            5.0000\n",
      "      5      79    5.2654    5.9209             6.6393  0.1 sec          704.7 sec            5.0000\n",
      "      5      80    6.1348    7.4918             5.8466  0.1 sec          705.8 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      5      81    5.5939    6.3451             7.1220  0.1 sec          706.9 sec            5.0000\n",
      "      5      82    7.8980   11.2302            11.5091  0.1 sec          708.1 sec            5.0000\n",
      "      5      83    5.5353    6.2209             6.7774  0.1 sec          709.2 sec            5.0000\n",
      "      5      84    5.0759    5.3693             6.9266  0.1 sec          710.2 sec            5.0000\n",
      "      5      85    5.8316    6.8489             5.9204  0.1 sec          711.4 sec            5.0000\n",
      "      5      86    5.8707    6.9319             6.7833  0.1 sec          712.5 sec            5.0000\n",
      "      5      87    5.6451    6.4536             8.2592  0.1 sec          713.6 sec            5.0000\n",
      "      5      88    5.3666    5.7609             7.1460  0.1 sec          714.9 sec            5.0000\n",
      "      5      89    5.2716    5.6617             6.3005  0.1 sec          715.9 sec            5.0000\n",
      "      5      90    5.7321    6.6380             7.6766  0.1 sec          717.0 sec            5.0000\n",
      "      5      91    5.7286    6.7531             6.7930  0.1 sec          718.1 sec            5.0000\n",
      "      5      92    6.0054    7.2176             6.5434  0.1 sec          719.2 sec            5.0000\n",
      "      5      93    6.5233    8.4381             9.8686  0.1 sec          720.3 sec            5.0000\n",
      "      5      94    7.6404   10.0775            11.0025  0.1 sec          721.5 sec            5.0000\n",
      "      5      95    5.5381    6.2267             7.2054  0.1 sec          722.7 sec            5.0000\n",
      "      5      96    5.9059    7.0064             7.2557  0.1 sec          723.8 sec            5.0000\n",
      "      5      97    6.5023    8.2710             8.0905  0.1 sec          724.9 sec            5.0000\n",
      "      5      98    5.7045    6.5795             6.6093  0.1 sec          726.0 sec            5.0000\n",
      "      5      99    5.0429    5.2994             6.4534  0.1 sec          727.2 sec            5.0000\n",
      "      5     100    5.3840    5.9000             5.7291  0.1 sec          728.3 sec            5.0000\n",
      "      5     101    5.1986    5.5069             4.7753  0.1 sec          729.5 sec            5.0000\n",
      "      5     102    5.9284    7.0542             5.7788  0.1 sec          730.7 sec            5.0000\n",
      "      5     103    5.7540    6.6844             5.0138  0.1 sec          731.8 sec            5.0000\n",
      "      5     104    5.6864    6.5411             7.4360  0.1 sec          732.9 sec            5.0000\n",
      "      5     105    6.5129    8.4160             8.9331  0.1 sec          733.9 sec            5.0000\n",
      "      5     106    6.1352    7.4927             6.8718  0.1 sec          735.0 sec            5.0000\n",
      "      5     107    4.9743    5.0320             4.8685  0.1 sec          736.2 sec            4.9950\n",
      "      5     108    4.7185    4.5047             4.7085  0.1 sec          737.3 sec            4.8560\n",
      "      5     109    5.6026    6.6359             8.1538  0.1 sec          738.5 sec            5.0000\n",
      "      5     110    4.8075    4.6776             4.7977  0.1 sec          739.6 sec            5.0000\n",
      "      5     111    5.0750    5.2449             5.4870  0.1 sec          740.7 sec            5.0000\n",
      "      5     112    5.8777    6.9466             6.2474  0.1 sec          741.8 sec            5.0000\n",
      "      5     113    7.1744    9.6695            11.4269  0.1 sec          742.9 sec            5.0000\n",
      "      5     114    5.3875    5.9075             6.5382  0.1 sec          744.1 sec            5.0000\n",
      "      5     115    5.8618    6.9130             6.9004  0.1 sec          745.3 sec            5.0000\n",
      "      5     116    5.4633    6.0681             7.2027  0.1 sec          746.4 sec            5.0000\n",
      "      5     117    6.3979    8.0497            10.5653  0.1 sec          747.5 sec            5.0000\n",
      "      5     118    5.5032    6.2753             9.2904  0.1 sec          748.7 sec            5.0000\n",
      "      5     119    5.9294    7.0564             8.9277  0.1 sec          749.8 sec            5.0000\n",
      "      5     120    5.4473    6.0341             5.2215  0.1 sec          751.0 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      5     121    7.5874   10.4694            11.8894  0.1 sec          752.2 sec            5.0000\n",
      "      5     122    7.2021    9.7547            10.9773  0.1 sec          753.5 sec            5.0000\n",
      "      5     123    6.1369    7.4964             5.8625  0.1 sec          754.7 sec            5.0000\n",
      "      5     124    6.0480    7.3077             8.1796  0.1 sec          756.0 sec            5.0000\n",
      "      5     125    6.0325    7.2750            10.1322  0.1 sec          757.2 sec            5.0000\n",
      "      5     126    5.6916    6.5521             6.4344  0.1 sec          758.3 sec            5.0000\n",
      "      5     127    4.8287    4.7226             4.9581  0.1 sec          759.5 sec            5.0000\n",
      "      5     128    7.2822    9.8201            10.7295  0.1 sec          760.8 sec            5.0000\n",
      "      5     129    6.1316    7.4852             7.9242  0.1 sec          762.0 sec            5.0000\n",
      "      5     130    6.6481    8.5261            10.4134  0.1 sec          763.1 sec            5.0000\n",
      "      5     131    6.4201    8.0966             7.2236  0.1 sec          764.3 sec            5.0000\n",
      "      5     132    5.0594    5.3344             5.1107  0.1 sec          765.4 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      6       1    5.7998    6.7816             7.4300  0.1 sec          766.6 sec            5.0000\n",
      "      6       2    7.1320    9.6014            12.2575  0.1 sec          767.8 sec            5.0000\n",
      "      6       3    5.6402    6.4432             6.2595  0.1 sec          768.9 sec            5.0000\n",
      "      6       4    5.2069    5.5245             5.6702  0.1 sec          770.0 sec            5.0000\n",
      "      6       5    6.1059    7.4306             7.4172  0.1 sec          771.2 sec            5.0000\n",
      "      6       6    9.1983   13.9870            14.1722  0.1 sec          772.3 sec            5.0000\n",
      "      6       7    5.3398    5.8062             5.6025  0.1 sec          773.4 sec            5.0000\n",
      "      6       8    4.9326    5.2154             6.7019  0.1 sec          774.6 sec            5.0000\n",
      "      6       9    5.4727    6.0881             6.5091  0.1 sec          775.7 sec            5.0000\n",
      "      6      10    5.2371    5.5885             5.1926  0.1 sec          776.7 sec            5.0000\n",
      "      6      11    5.7370    6.6485             6.5822  0.1 sec          777.9 sec            5.0000\n",
      "      6      12    6.0842    7.3845             7.9600  0.1 sec          779.0 sec            5.0000\n",
      "      6      13    5.0647    5.2230             5.1849  0.1 sec          780.2 sec            5.0000\n",
      "      6      14    5.8977    7.1117             6.3324  0.1 sec          781.3 sec            5.0000\n",
      "      6      15    7.3256    9.9555             7.4370  0.1 sec          782.5 sec            5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6      16    5.7756    6.7303             7.7715  0.1 sec          783.7 sec            5.0000\n",
      "      6      17    5.7396    6.6539             6.6142  0.1 sec          784.9 sec            5.0000\n",
      "      6      18    5.8418    6.9931             6.8837  0.1 sec          786.1 sec            5.0000\n",
      "      6      19    5.1926    5.4943             4.9102  0.1 sec          787.3 sec            5.0000\n",
      "      6      20    4.7859    4.6319             5.0986  0.1 sec          788.5 sec            5.0000\n",
      "      6      21    5.3210    5.7665             7.1552  0.1 sec          789.6 sec            5.0000\n",
      "      6      22    5.6323    6.5491             6.9961  0.1 sec          790.8 sec            5.0000\n",
      "      6      23    4.8914    4.8555             5.4659  0.1 sec          792.0 sec            5.0000\n",
      "      6      24    5.1939    5.3949             6.1735  0.1 sec          793.3 sec            5.0000\n",
      "      6      25    6.3270    7.8994            10.1703  0.1 sec          794.5 sec            5.0000\n",
      "      6      26    5.8454    6.8782             7.5409  0.1 sec          795.7 sec            5.0000\n",
      "      6      27    5.2569    5.6306             5.1001  0.1 sec          796.9 sec            5.0000\n",
      "      6      28    6.5234    8.3157             7.7651  0.1 sec          798.0 sec            5.0000\n",
      "      6      29    5.4213    5.9791             5.4893  0.1 sec          799.2 sec            5.0000\n",
      "      6      30    6.1403    7.5036             7.9161  0.1 sec          800.4 sec            5.0000\n",
      "      6      31    6.8230    8.8915            10.9753  0.1 sec          801.7 sec            5.0000\n",
      "      6      32    5.3764    6.0064             6.0293  0.1 sec          803.0 sec            5.0000\n",
      "      6      33    5.0834    5.2627             4.8558  0.1 sec          804.2 sec            5.0000\n",
      "      6      34    6.6803    8.7710             7.8323  0.1 sec          805.5 sec            5.0000\n",
      "      6      35    5.6424    6.4479             5.5979  0.1 sec          806.7 sec            5.0000\n",
      "      6      36    5.7986    6.7790             5.8590  0.1 sec          807.8 sec            5.0000\n",
      "      6      37    5.6278    6.4169             6.6769  0.1 sec          808.9 sec            5.0000\n",
      "      6      38    7.8490   11.1262            11.2679  0.1 sec          810.1 sec            5.0000\n",
      "      6      39    5.8787    7.0714             8.9038  0.1 sec          811.2 sec            5.0000\n",
      "      6      40    6.7604    8.8183             9.5290  0.1 sec          812.3 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      6      41    6.7965    8.8947             8.1413  0.1 sec          813.4 sec            5.0000\n",
      "      6      42    5.0371    5.2871             4.8817  0.1 sec          814.5 sec            5.0000\n",
      "      6      43    7.4633    8.9002            11.1775  0.1 sec          815.7 sec            5.0000\n",
      "      6      44    5.5221    6.3153             6.0796  0.1 sec          816.8 sec            5.0000\n",
      "      6      45    5.6116    6.3825             7.5630  0.1 sec          818.0 sec            5.0000\n",
      "      6      46    5.4762    6.0954             5.4340  0.1 sec          819.2 sec            5.0000\n",
      "      6      47    8.1559   11.7535            12.2533  0.1 sec          820.3 sec            5.0000\n",
      "      6      48    5.3614    5.7500             5.5933  0.1 sec          821.6 sec            5.0000\n",
      "      6      49    5.8163    6.8166             7.8342  0.1 sec          822.7 sec            5.0000\n",
      "      6      50    6.8547    9.0183             8.0319  0.1 sec          823.9 sec            5.0000\n",
      "      6      51    5.4552    6.1735             8.4949  0.1 sec          825.0 sec            5.0000\n",
      "      6      52    5.8739    6.9386             6.4449  0.1 sec          826.1 sec            5.0000\n",
      "      6      53    7.0034    9.3333             8.8542  0.1 sec          827.3 sec            5.0000\n",
      "      6      54    5.4562    6.1756             6.6539  0.1 sec          828.5 sec            5.0000\n",
      "      6      55    5.9434    7.0861             6.5643  0.1 sec          829.6 sec            5.0000\n",
      "      6      56    6.0059    7.2185             9.6935  0.1 sec          830.8 sec            5.0000\n",
      "      6      57    5.8699    6.9302             8.0479  0.1 sec          831.9 sec            5.0000\n",
      "      6      58    6.2688    7.7760             8.2685  0.1 sec          833.1 sec            5.0000\n",
      "      6      59    7.0182    9.3648             9.5705  0.1 sec          834.2 sec            5.0000\n",
      "      6      60    5.1465    5.3964             5.3015  0.1 sec          835.4 sec            5.0000\n",
      "      6      61    5.9330    7.0639             6.3811  0.1 sec          836.5 sec            5.0000\n",
      "      6      62    5.4945    6.1343             6.3965  0.1 sec          837.6 sec            5.0000\n",
      "      6      63    6.2790    7.7975            11.0526  0.1 sec          838.8 sec            5.0000\n",
      "      6      64    5.7792    6.7378             8.3720  0.1 sec          839.9 sec            5.0000\n",
      "      6      65    6.5100    8.2873             6.9862  0.1 sec          841.0 sec            5.0000\n",
      "      6      66    6.5020    8.7299             9.0257  0.1 sec          842.1 sec            5.0000\n",
      "      6      67    5.0669    5.5000             5.6377  0.1 sec          843.2 sec            5.0000\n",
      "      6      68    7.0734    9.4817             9.9397  0.1 sec          844.2 sec            5.0000\n",
      "      6      69    5.5731    6.4236             8.9291  0.1 sec          845.4 sec            5.0000\n",
      "      6      70    7.3162    9.9966            11.3370  0.1 sec          846.7 sec            5.0000\n",
      "      6      71    5.6389    6.4405             7.5204  0.1 sec          847.9 sec            5.0000\n",
      "      6      72    5.2070    5.5248             5.5146  0.1 sec          849.2 sec            5.0000\n",
      "      6      73    5.5026    6.0493             6.7256  0.1 sec          850.5 sec            5.0000\n",
      "      6      74    5.1973    5.4021             5.7387  0.1 sec          851.6 sec            5.0000\n",
      "      6      75    5.9708    7.1441             8.2073  0.1 sec          852.8 sec            5.0000\n",
      "      6      76    6.2002    7.9029             8.7646  0.1 sec          854.1 sec            5.0000\n",
      "      6      77    5.0999    5.2978             5.1631  0.1 sec          855.3 sec            5.0000\n",
      "      6      78    6.0276    7.2645             6.2639  0.1 sec          856.5 sec            5.0000\n",
      "      6      79    5.0084    5.3761             5.8669  0.1 sec          857.7 sec            5.0000\n",
      "      6      80    6.9940    9.3135             8.5054  0.1 sec          858.9 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      6      81    5.1411    5.3850             5.8077  0.1 sec          860.1 sec            5.0000\n",
      "      6      82    7.6259   10.6532            10.8694  0.1 sec          861.2 sec            5.0000\n",
      "      6      83    5.2832    5.6863             6.5897  0.1 sec          862.3 sec            5.0000\n",
      "      6      84    5.2422    5.7219             6.1162  0.1 sec          863.4 sec            5.0000\n",
      "      6      85    5.7254    6.6238             5.6012  0.1 sec          864.5 sec            5.0000\n",
      "      6      86    5.5224    6.1935             5.7730  0.1 sec          865.6 sec            5.0000\n",
      "      6      87    5.4070    5.9487             5.6431  0.1 sec          866.7 sec            5.0000\n",
      "      6      88    5.3493    5.7244             6.8935  0.1 sec          867.9 sec            5.0000\n",
      "      6      89    5.4377    6.0139             5.4063  0.1 sec          868.9 sec            5.0000\n",
      "      6      90    6.4397    8.1383             9.7058  0.1 sec          870.1 sec            5.0000\n",
      "      6      91    5.3944    6.0447             6.1282  0.1 sec          871.1 sec            5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6      92    5.3028    5.7277             7.3097  0.1 sec          872.3 sec            5.0000\n",
      "      6      93    6.4770    8.3399            10.0955  0.1 sec          873.5 sec            5.0000\n",
      "      6      94    7.5282    9.9571            11.4796  0.1 sec          874.7 sec            5.0000\n",
      "      6      95    5.5972    6.3520             7.2475  0.1 sec          875.8 sec            5.0000\n",
      "      6      96    5.5061    6.1589             6.8335  0.1 sec          877.0 sec            5.0000\n",
      "      6      97    6.0336    7.2772             7.4070  0.1 sec          878.1 sec            5.0000\n",
      "      6      98    5.3451    5.8175             5.5748  0.1 sec          879.2 sec            5.0000\n",
      "      6      99    4.9999    5.2081             6.7604  0.1 sec          880.3 sec            5.0000\n",
      "      6     100    5.4487    6.0371             5.5299  0.1 sec          881.4 sec            5.0000\n",
      "      6     101    5.2135    5.5386             4.6328  0.1 sec          882.6 sec            5.0000\n",
      "      6     102    6.7427    8.7806             7.0948  0.1 sec          883.8 sec            5.0000\n",
      "      6     103    5.2149    5.5415             6.7892  0.1 sec          884.9 sec            5.0000\n",
      "      6     104    6.3064    7.8557             8.6994  0.1 sec          886.0 sec            5.0000\n",
      "      6     105    6.7522    8.9234             9.5244  0.1 sec          887.1 sec            5.0000\n",
      "      6     106    5.8503    6.8887             6.5536  0.1 sec          888.2 sec            5.0000\n",
      "      6     107    4.9746    5.0352             5.4337  0.1 sec          889.5 sec            4.9830\n",
      "      6     108    4.6926    4.4700             4.6703  0.1 sec          890.6 sec            4.7170\n",
      "      6     109    5.8584    7.1781             8.5487  0.1 sec          891.8 sec            5.0000\n",
      "      6     110    4.7533    4.5627             4.5510  0.1 sec          893.0 sec            5.0000\n",
      "      6     111    5.9694    7.1412             7.4818  0.1 sec          894.2 sec            5.0000\n",
      "      6     112    5.3103    5.7436             5.8518  0.1 sec          895.3 sec            5.0000\n",
      "      6     113    6.9731    9.2316            10.1808  0.1 sec          896.4 sec            5.0000\n",
      "      6     114    5.3572    5.8431             6.4064  0.1 sec          897.5 sec            5.0000\n",
      "      6     115    5.7458    6.6671             8.2662  0.1 sec          898.7 sec            5.0000\n",
      "      6     116    5.5080    6.1628             7.2553  0.1 sec          899.9 sec            5.0000\n",
      "      6     117    6.6161    8.5122            10.4605  0.1 sec          901.0 sec            5.0000\n",
      "      6     118    5.7437    6.7852             8.7562  0.1 sec          902.2 sec            5.0000\n",
      "      6     119    5.3103    5.7438             7.3436  0.1 sec          903.4 sec            5.0000\n",
      "      6     120    5.0970    5.2914             5.5801  0.1 sec          904.5 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      6     121    7.7424   10.7981            12.4845  0.1 sec          905.7 sec            5.0000\n",
      "      6     122    7.9260   11.2894            12.5814  0.1 sec          907.0 sec            5.0000\n",
      "      6     123    6.1058    7.4290             5.9450  0.1 sec          908.1 sec            5.0000\n",
      "      6     124    5.9065    7.0077             7.6320  0.1 sec          909.4 sec            5.0000\n",
      "      6     125    5.5420    6.2350             8.1965  0.1 sec          910.5 sec            5.0000\n",
      "      6     126    5.2366    5.5876             5.5926  0.1 sec          911.7 sec            5.0000\n",
      "      6     127    6.1734    7.5737             8.6188  0.1 sec          912.8 sec            5.0000\n",
      "      6     128    6.5460    8.2616            10.8916  0.1 sec          914.0 sec            5.0000\n",
      "      6     129    6.8919    9.0970             9.9262  0.1 sec          915.1 sec            5.0000\n",
      "      6     130    6.9094    8.9457            11.2127  0.1 sec          916.3 sec            5.0000\n",
      "      6     131    6.8595    9.0282             8.0490  0.1 sec          917.5 sec            5.0000\n",
      "      6     132    5.5456    6.3652             6.7971  0.1 sec          918.8 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      7       1    6.0433    7.2978             8.2915  0.1 sec          919.9 sec            5.0000\n",
      "      7       2    7.0075    9.3421            12.0032  0.1 sec          921.1 sec            5.0000\n",
      "      7       3    5.5817    6.3192             6.2528  0.1 sec          922.2 sec            5.0000\n",
      "      7       4    5.2882    5.6969             5.6051  0.1 sec          923.4 sec            5.0000\n",
      "      7       5    6.4458    8.1512             7.9751  0.1 sec          924.5 sec            5.0000\n",
      "      7       6    8.4228   12.3429            12.2850  0.1 sec          925.7 sec            5.0000\n",
      "      7       7    5.7349    6.6440             6.0903  0.1 sec          926.8 sec            5.0000\n",
      "      7       8    6.3625    8.2470             6.5947  0.1 sec          928.0 sec            5.0000\n",
      "      7       9    5.3604    5.8501             6.2782  0.1 sec          929.1 sec            5.0000\n",
      "      7      10    5.6739    6.5147             7.5506  0.1 sec          930.2 sec            5.0000\n",
      "      7      11    6.1999    7.6299             8.9141  0.1 sec          931.3 sec            5.0000\n",
      "      7      12    5.9828    7.1696             7.4563  0.1 sec          932.5 sec            5.0000\n",
      "      7      13    5.0871    5.2705             5.5958  0.1 sec          933.7 sec            5.0000\n",
      "      7      14    5.8947    7.1054             6.3843  0.1 sec          934.8 sec            5.0000\n",
      "      7      15    6.8343    8.9750             7.0030  0.1 sec          936.0 sec            5.0000\n",
      "      7      16    5.5775    6.3103             7.2870  0.1 sec          937.2 sec            5.0000\n",
      "      7      17    5.5514    6.2548             6.1899  0.1 sec          938.4 sec            5.0000\n",
      "      7      18    7.4417   10.3854            12.6933  0.1 sec          939.5 sec            5.0000\n",
      "      7      19    5.1004    5.2988             5.0292  0.1 sec          940.7 sec            5.0000\n",
      "      7      20    6.1620    7.5496             7.9351  0.1 sec          941.8 sec            5.0000\n",
      "      7      21    5.8190    6.8222            10.3882  0.2 sec          943.1 sec            5.0000\n",
      "      7      22    5.6940    6.6799             6.9972  0.1 sec          944.5 sec            5.0000\n",
      "      7      23    4.8484    4.7643             4.5786  0.1 sec          945.8 sec            5.0000\n",
      "      7      24    5.1629    5.3292             5.3437  0.1 sec          947.0 sec            5.0000\n",
      "      7      25    5.8507    6.8895             8.5259  0.1 sec          948.2 sec            5.0000\n",
      "      7      26    6.1688    7.5640             7.5929  0.1 sec          949.3 sec            5.0000\n",
      "      7      27    5.7657    6.7093             5.3864  0.1 sec          950.4 sec            5.0000\n",
      "      7      28    5.3324    5.7906             5.4305  0.1 sec          951.6 sec            5.0000\n",
      "      7      29    5.4588    6.0585             5.5607  0.1 sec          952.7 sec            5.0000\n",
      "      7      30    6.1568    7.5384             8.2018  0.1 sec          953.9 sec            5.0000\n",
      "      7      31    7.3487   10.0652            11.4384  0.1 sec          955.0 sec            5.0000\n",
      "      7      32    5.3897    6.0346             5.9493  0.1 sec          956.2 sec            5.0000\n",
      "      7      33    5.1926    5.4943             5.3717  0.1 sec          957.4 sec            5.0000\n",
      "      7      34    7.0385    9.5304             8.9862  0.1 sec          958.6 sec            5.0000\n",
      "      7      35    5.9705    7.1434             6.5664  0.1 sec          959.7 sec            5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7      36    6.2172    7.6666             5.9887  0.1 sec          960.8 sec            5.0000\n",
      "      7      37    5.6955    6.5604             6.8156  0.1 sec          962.0 sec            5.0000\n",
      "      7      38    7.2969    9.9556             9.4436  0.1 sec          963.2 sec            5.0000\n",
      "      7      39    7.1557    9.7790             8.7490  0.1 sec          964.3 sec            5.0000\n",
      "      7      40    6.7702    8.8390             9.1391  0.1 sec          965.5 sec            5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      7      41    5.6194    6.3991             6.2522  0.1 sec          966.8 sec            5.0000\n",
      "      7      42    5.0574    5.3300             4.6987  0.1 sec          967.9 sec            5.0000\n",
      "      7      43    8.7611   11.9560            12.4916  0.1 sec          969.1 sec            5.0000\n",
      "      7      44    4.7465    4.6709             5.4460  0.1 sec          970.3 sec            5.0000\n",
      "      7      45    6.6400    8.5628             7.5271  0.1 sec          971.4 sec            5.0000\n",
      "      7      46    5.3666    5.8630             5.7513  0.1 sec          972.6 sec            5.0000\n",
      "      7      47    7.7385   10.8864            11.3850  0.1 sec          973.7 sec            5.0000\n",
      "      7      48    5.3675    5.7628             5.2243  0.1 sec          975.1 sec            5.0000\n",
      "      7      49    5.6754    6.5177             7.2523  0.1 sec          976.1 sec            5.0000\n",
      "      7      50    7.0226    9.3742             8.1423  0.1 sec          977.3 sec            5.0000\n",
      "      7      51    5.4093    6.0763             5.7708  0.1 sec          978.4 sec            5.0000\n",
      "      7      52    5.4229    5.9825             5.3772  0.1 sec          979.5 sec            5.0000\n",
      "      7      53    5.5574    6.2675             6.0780  0.1 sec          980.6 sec            5.0000\n",
      "      7      54    5.5760    6.4297             6.9289  0.1 sec          981.8 sec            5.0000\n",
      "      7      55    5.3344    5.7949             5.5406  0.1 sec          982.9 sec            5.0000\n",
      "      7      56    6.2772    7.7937            10.3675  0.1 sec          984.1 sec            5.0000\n",
      "      7      57    5.5481    6.2480             6.3185  0.1 sec          985.3 sec            5.0000\n",
      "      7      58    4.7758    4.6106             4.8659  0.1 sec          986.7 sec            5.0000\n",
      "      7      59    4.8288    4.7228             5.4507  0.1 sec          987.8 sec            5.0000\n",
      "      7      60    4.7487    4.5531             4.3855  0.1 sec          989.0 sec            5.0000\n",
      "      7      61    5.7751    6.7292             6.3290  0.1 sec          990.1 sec            5.0000\n",
      "      7      62    6.2160    7.6640             7.2421  0.1 sec          991.3 sec            5.0000\n",
      "      7      63    6.5976    8.4731            11.5825  0.1 sec          992.5 sec            5.0000\n",
      "      7      64    6.0409    7.2927             8.0495  0.1 sec          993.6 sec            5.0000\n",
      "      7      65    6.7436    8.7826             7.0303  0.1 sec          994.7 sec            5.0000\n",
      "      7      66    4.7565    5.0291             5.6128  0.1 sec          995.8 sec            5.0000\n",
      "      7      67    5.3019    5.9982             5.0971  0.1 sec          996.9 sec            5.0000\n",
      "      7      68    5.4816    6.1070             6.8661  0.1 sec          998.0 sec            5.0000\n",
      "      7      69    5.6499    6.5863             8.1973  0.1 sec          999.1 sec            5.0000\n",
      "      7      70    6.5868    8.4501            10.2314  0.1 sec          1000.2 sec           5.0000\n",
      "      7      71    5.5797    6.3149             6.1332  0.1 sec          1001.4 sec           5.0000\n",
      "      7      72    5.7617    6.7008             6.2396  0.1 sec          1002.7 sec           5.0000\n",
      "      7      73    5.3219    5.6661             6.0028  0.1 sec          1003.8 sec           5.0000\n",
      "      7      74    5.1136    5.2246             5.8509  0.1 sec          1004.9 sec           5.0000\n",
      "      7      75    6.0977    7.4133             7.5942  0.1 sec          1006.1 sec           5.0000\n",
      "      7      76    6.2807    8.0735            10.3335  0.1 sec          1007.2 sec           5.0000\n",
      "      7      77    5.8120    6.8074             7.8807  0.1 sec          1008.4 sec           5.0000\n",
      "      7      78    5.6602    6.4855             6.1330  0.1 sec          1009.6 sec           5.0000\n",
      "      7      79    5.2292    5.8442             6.4959  0.1 sec          1010.7 sec           5.0000\n",
      "      7      80    6.8490    9.0061             7.3314  0.1 sec          1011.9 sec           5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      7      81    5.5120    6.1714             7.3244  0.1 sec          1013.0 sec           5.0000\n",
      "      7      82    6.7524    8.8013             9.1803  0.1 sec          1014.2 sec           5.0000\n",
      "      7      83    6.1247    7.4703             7.2273  0.1 sec          1015.2 sec           5.0000\n",
      "      7      84    5.3372    5.9234             7.1430  0.1 sec          1016.3 sec           5.0000\n",
      "      7      85    5.9482    7.0961             5.9225  0.1 sec          1017.4 sec           5.0000\n",
      "      7      86    5.6027    6.3637             5.9489  0.1 sec          1018.6 sec           5.0000\n",
      "      7      87    5.2377    5.5899             6.4626  0.1 sec          1019.7 sec           5.0000\n",
      "      7      88    5.2468    5.5071             6.6507  0.1 sec          1020.8 sec           5.0000\n",
      "      7      89    5.3777    5.8866             7.0342  0.1 sec          1021.9 sec           5.0000\n",
      "      7      90    6.1728    7.5725             8.9608  0.1 sec          1023.0 sec           5.0000\n",
      "      7      91    5.3304    5.9089             6.1174  0.1 sec          1024.1 sec           5.0000\n",
      "      7      92    5.3309    5.7875             6.9031  0.1 sec          1025.2 sec           5.0000\n",
      "      7      93    6.4972    8.3828            10.2449  0.1 sec          1026.4 sec           5.0000\n",
      "      7      94    7.8456   10.3742            11.1313  0.1 sec          1027.6 sec           5.0000\n",
      "      7      95    5.5384    6.2273             7.1842  0.1 sec          1028.8 sec           5.0000\n",
      "      7      96    5.4846    6.1134             7.0134  0.1 sec          1029.9 sec           5.0000\n",
      "      7      97    6.0859    7.3881             7.7923  0.1 sec          1031.0 sec           5.0000\n",
      "      7      98    5.4654    6.0726             5.9708  0.1 sec          1032.3 sec           5.0000\n",
      "      7      99    5.0611    5.3379             6.9200  0.2 sec          1033.7 sec           5.0000\n",
      "      7     100    5.4565    6.0538             6.2112  0.1 sec          1035.1 sec           5.0000\n",
      "      7     101    5.0369    5.1642             4.7320  0.1 sec          1036.3 sec           5.0000\n",
      "      7     102    6.1548    7.5342             5.7249  0.1 sec          1037.6 sec           5.0000\n",
      "      7     103    6.1102    7.4397             5.2334  0.1 sec          1038.8 sec           5.0000\n",
      "      7     104    5.8940    6.9814             7.7020  0.1 sec          1040.1 sec           5.0000\n",
      "      7     105    6.2206    7.7962             8.2871  0.1 sec          1041.3 sec           5.0000\n",
      "      7     106    5.9347    7.0676             6.7545  0.1 sec          1042.4 sec           5.0000\n",
      "      7     107    5.1619    5.4320             5.6987  0.1 sec          1043.6 sec           4.9800\n",
      "      7     108    4.8620    4.8261             5.8528  0.1 sec          1044.7 sec           4.7050\n",
      "      7     109    5.4034    6.2135             7.9070  0.1 sec          1045.8 sec           5.0000\n",
      "      7     110    4.7884    4.6372             4.7237  0.1 sec          1047.0 sec           5.0000\n",
      "      7     111    4.9202    4.9167             5.1570  0.1 sec          1048.1 sec           5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7     112    5.4889    6.1223             5.8121  0.1 sec          1049.2 sec           5.0000\n",
      "      7     113    6.9713    9.2346            10.2155  0.1 sec          1050.3 sec           5.0000\n",
      "      7     114    5.2709    5.6601             6.3157  0.1 sec          1051.5 sec           5.0000\n",
      "      7     115    5.5574    6.2676             7.3907  0.1 sec          1052.6 sec           5.0000\n",
      "      7     116    5.4838    6.1115             7.2565  0.1 sec          1053.7 sec           5.0000\n",
      "      7     117    6.3296    7.9048            10.8957  0.1 sec          1054.9 sec           5.0000\n",
      "      7     118    5.6174    6.5173             9.6146  0.1 sec          1056.0 sec           5.0000\n",
      "      7     119    5.9366    7.0716             8.8494  0.1 sec          1057.1 sec           5.0000\n",
      "      7     120    5.2867    5.6936             5.0664  0.1 sec          1058.2 sec           5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      7     121    6.6265    8.4322             9.6045  0.1 sec          1059.4 sec           5.0000\n",
      "      7     122    6.8894    9.0917             9.6568  0.1 sec          1060.6 sec           5.0000\n",
      "      7     123    6.1317    7.4342             6.0958  0.1 sec          1061.8 sec           4.9570\n",
      "      7     124    6.3130    7.8697             9.5654  0.1 sec          1063.0 sec           5.0000\n",
      "      7     125    5.5806    6.3168             8.6776  0.1 sec          1064.1 sec           5.0000\n",
      "      7     126    5.0347    5.1594             5.4107  0.1 sec          1065.3 sec           5.0000\n",
      "      7     127    4.8762    4.8235             4.9914  0.1 sec          1066.8 sec           5.0000\n",
      "      7     128    6.3905    7.9318            10.6763  0.1 sec          1068.2 sec           5.0000\n",
      "      7     129    5.7965    6.7746             7.4760  0.1 sec          1069.5 sec           5.0000\n",
      "      7     130    6.9227    8.9527            11.2224  0.1 sec          1070.8 sec           5.0000\n",
      "      7     131    6.2265    7.6862             7.2663  0.1 sec          1072.0 sec           5.0000\n",
      "      7     132    5.0789    5.3757             4.8031  0.1 sec          1073.1 sec           5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      8       1    5.8851    6.9624             7.0744  0.1 sec          1074.3 sec           5.0000\n",
      "      8       2    7.0550    9.4342            11.8814  0.1 sec          1075.5 sec           5.0000\n",
      "      8       3    5.7302    6.6339             6.8367  0.1 sec          1076.7 sec           5.0000\n",
      "      8       4    5.2404    5.5956             5.5182  0.1 sec          1077.8 sec           5.0000\n",
      "      8       5    5.7037    6.5779             6.2117  0.1 sec          1078.9 sec           5.0000\n",
      "      8       6    7.4930   10.3715             9.9221  0.1 sec          1080.0 sec           5.0000\n",
      "      8       7    5.3716    5.8737             6.1954  0.1 sec          1081.2 sec           5.0000\n",
      "      8       8    7.5379   10.7390            12.6096  0.1 sec          1082.4 sec           5.0000\n",
      "      8       9    5.4849    6.1140             6.9546  0.1 sec          1083.6 sec           5.0000\n",
      "      8      10    5.1810    5.4696             5.2765  0.1 sec          1084.7 sec           5.0000\n",
      "      8      11    5.7059    6.5824             6.4067  0.1 sec          1085.8 sec           5.0000\n",
      "      8      12    6.0780    7.3714             7.5760  0.1 sec          1086.9 sec           5.0000\n",
      "      8      13    5.1188    5.3378             5.8283  0.1 sec          1088.1 sec           5.0000\n",
      "      8      14    5.8580    7.0274             5.7242  0.1 sec          1089.2 sec           5.0000\n",
      "      8      15    8.3224   11.8079            10.2042  0.1 sec          1090.4 sec           5.0000\n",
      "      8      16    5.4764    6.0959             6.7899  0.1 sec          1091.5 sec           5.0000\n",
      "      8      17    5.6377    6.4379             6.5755  0.1 sec          1092.7 sec           5.0000\n",
      "      8      18    7.3733   10.2402            12.3811  0.1 sec          1093.9 sec           5.0000\n",
      "      8      19    5.5700    6.2943             6.1076  0.1 sec          1095.0 sec           5.0000\n",
      "      8      20    6.0740    7.3629             7.4215  0.1 sec          1096.2 sec           5.0000\n",
      "      8      21    5.9846    7.1733             4.7247  0.1 sec          1097.3 sec           5.0000\n",
      "      8      22    5.6705    6.6301             7.1716  0.1 sec          1098.5 sec           5.0000\n",
      "      8      23    4.7767    4.6123             4.6601  0.1 sec          1099.7 sec           5.0000\n",
      "      8      24    5.2311    5.4737             6.5880  0.1 sec          1100.9 sec           5.0000\n",
      "      8      25    7.1593    9.6641            11.4390  0.1 sec          1102.1 sec           5.0000\n",
      "      8      26    6.3992    8.0524             8.3242  0.1 sec          1103.2 sec           5.0000\n",
      "      8      27    6.1948    7.6191             6.5501  0.1 sec          1104.3 sec           5.0000\n",
      "      8      28    5.6708    6.5081             5.7025  0.1 sec          1105.4 sec           5.0000\n",
      "      8      29    5.5342    6.2185             5.6601  0.1 sec          1106.6 sec           5.0000\n",
      "      8      30    6.2081    7.6472             8.0953  0.1 sec          1107.8 sec           5.0000\n",
      "      8      31    7.5290   10.1427            11.4077  0.1 sec          1109.1 sec           5.0000\n",
      "      8      32    5.0783    5.3743             5.1324  0.1 sec          1110.2 sec           5.0000\n",
      "      8      33    5.0729    5.2405             4.9782  0.1 sec          1111.3 sec           5.0000\n",
      "      8      34    6.4675    8.3198             7.2471  0.1 sec          1112.5 sec           5.0000\n",
      "      8      35    5.8259    6.8370             5.8605  0.1 sec          1113.6 sec           5.0000\n",
      "      8      36    6.2041    7.6387             5.8619  0.1 sec          1114.8 sec           5.0000\n",
      "      8      37    5.6330    6.4279             6.6796  0.1 sec          1115.9 sec           5.0000\n",
      "      8      38    7.3564   10.0819            10.5132  0.1 sec          1117.1 sec           5.0000\n",
      "      8      39    5.8032    6.9112             9.9519  0.1 sec          1118.3 sec           5.0000\n",
      "      8      40    6.7191    8.7306             9.6042  0.1 sec          1119.5 sec           5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      8      41    6.5987    8.4754             8.0681  0.1 sec          1120.7 sec           5.0000\n",
      "      8      42    4.9827    5.1716             5.3411  0.1 sec          1121.8 sec           5.0000\n",
      "      8      43    7.2566    8.6053            10.8309  0.1 sec          1123.0 sec           5.0000\n",
      "      8      44    6.3140    7.9943             7.7324  0.1 sec          1124.2 sec           5.0000\n",
      "      8      45    6.1158    7.4516            10.3320  0.1 sec          1125.4 sec           5.0000\n",
      "      8      46    5.9020    6.9983             6.0233  0.1 sec          1126.6 sec           5.0000\n",
      "      8      47    8.0215   11.4645            11.9099  0.1 sec          1127.7 sec           5.0000\n",
      "      8      48    5.4343    5.9046             4.9944  0.1 sec          1129.0 sec           5.0000\n",
      "      8      49    5.8499    6.8878             7.7308  0.1 sec          1130.1 sec           5.0000\n",
      "      8      50    6.3178    7.8798             8.9249  0.1 sec          1131.2 sec           5.0000\n",
      "      8      51    5.4834    6.2333             8.7202  0.1 sec          1132.3 sec           5.0000\n",
      "      8      52    6.8959    9.1055             8.9169  0.1 sec          1133.5 sec           5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8      53    6.6997    8.6895             8.0833  0.1 sec          1134.6 sec           5.0000\n",
      "      8      54    5.7071    6.7077             7.3180  0.1 sec          1135.8 sec           5.0000\n",
      "      8      55    5.4828    6.1095             5.7956  0.1 sec          1136.9 sec           5.0000\n",
      "      8      56    5.5092    6.1655             8.6296  0.1 sec          1138.1 sec           5.0000\n",
      "      8      57    5.7219    6.6165             7.0734  0.1 sec          1139.3 sec           5.0000\n",
      "      8      58    5.1287    5.3586             5.2336  0.1 sec          1140.5 sec           5.0000\n",
      "      8      59    6.5796    8.4350             8.6156  0.1 sec          1141.7 sec           5.0000\n",
      "      8      60    4.8580    4.7848             4.3669  0.1 sec          1142.8 sec           5.0000\n",
      "      8      61    6.0890    7.3948             6.1008  0.1 sec          1143.9 sec           5.0000\n",
      "      8      62    5.4603    6.0618             6.5658  0.1 sec          1145.1 sec           5.0000\n",
      "      8      63    6.0321    7.2742            10.2368  0.1 sec          1146.3 sec           5.0000\n",
      "      8      64    5.8708    6.9321             8.1349  0.1 sec          1147.3 sec           5.0000\n",
      "      8      65    6.4539    8.1684             7.1830  0.1 sec          1148.5 sec           5.0000\n",
      "      8      66    4.4459    4.3707             4.8267  0.1 sec          1149.6 sec           5.0000\n",
      "      8      67    5.1832    5.7465             6.4687  0.1 sec          1150.7 sec           5.0000\n",
      "      8      68    5.2219    5.5563             6.0631  0.1 sec          1151.7 sec           5.0000\n",
      "      8      69    5.5265    6.3246             8.4474  0.1 sec          1152.9 sec           5.0000\n",
      "      8      70    6.8194    8.9433            10.4654  0.1 sec          1154.1 sec           5.0000\n",
      "      8      71    5.4641    6.0698             6.4634  0.1 sec          1155.3 sec           5.0000\n",
      "      8      72    5.2843    5.6886             5.6829  0.1 sec          1156.6 sec           5.0000\n",
      "      8      73    5.5584    6.1677             6.9700  0.1 sec          1157.7 sec           5.0000\n",
      "      8      74    5.4428    5.9226             6.7739  0.1 sec          1158.8 sec           5.0000\n",
      "      8      75    6.0066    7.2201             9.5168  0.1 sec          1160.0 sec           5.0000\n",
      "      8      76    6.1228    7.7388             9.4145  0.1 sec          1161.2 sec           5.0000\n",
      "      8      77    5.0714    5.2373             5.4863  0.1 sec          1162.4 sec           5.0000\n",
      "      8      78    5.5517    6.2555             6.0380  0.1 sec          1163.6 sec           5.0000\n",
      "      8      79    4.9695    5.2934             5.8122  0.1 sec          1164.7 sec           5.0000\n",
      "      8      80    5.7916    6.7643             5.2727  0.1 sec          1165.9 sec           5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      8      81    5.0768    5.2486             5.6540  0.1 sec          1167.0 sec           5.0000\n",
      "      8      82    6.8028    8.9080             9.2694  0.1 sec          1168.1 sec           5.0000\n",
      "      8      83    6.2730    7.7848             7.3607  0.1 sec          1169.3 sec           5.0000\n",
      "      8      84    5.6848    6.6604             5.9835  0.1 sec          1170.4 sec           5.0000\n",
      "      8      85    5.7868    6.7541             5.9689  0.1 sec          1171.5 sec           5.0000\n",
      "      8      86    5.7338    6.6416             6.3554  0.1 sec          1172.7 sec           5.0000\n",
      "      8      87    5.5484    6.2486             5.6605  0.1 sec          1173.8 sec           5.0000\n",
      "      8      88    5.2330    5.4778             6.6946  0.1 sec          1174.9 sec           5.0000\n",
      "      8      89    5.5783    6.3120             8.0995  0.1 sec          1176.0 sec           5.0000\n",
      "      8      90    7.0959    9.5297            10.9030  0.1 sec          1177.2 sec           5.0000\n",
      "      8      91    5.4705    6.2059             6.2539  0.1 sec          1178.2 sec           5.0000\n",
      "      8      92    5.2552    5.6269             7.2306  0.1 sec          1179.4 sec           5.0000\n",
      "      8      93    6.4643    8.3129            10.0270  0.1 sec          1180.5 sec           5.0000\n",
      "      8      94    7.6378   10.0903            11.3408  0.1 sec          1181.7 sec           5.0000\n",
      "      8      95    5.7383    6.6512             7.0583  0.1 sec          1182.9 sec           5.0000\n",
      "      8      96    5.3843    5.9006             6.6878  0.1 sec          1184.0 sec           5.0000\n",
      "      8      97    5.8745    6.9399             7.0292  0.1 sec          1185.1 sec           5.0000\n",
      "      8      98    5.4554    6.0513             5.7599  0.1 sec          1186.2 sec           5.0000\n",
      "      8      99    5.2141    5.6623             7.0172  0.1 sec          1187.3 sec           5.0000\n",
      "      8     100    5.4466    6.0328             6.1584  0.1 sec          1188.5 sec           5.0000\n",
      "      8     101    5.0380    5.1664             4.6881  0.1 sec          1189.7 sec           5.0000\n",
      "      8     102    5.6095    6.3781             5.1857  0.1 sec          1190.9 sec           5.0000\n",
      "      8     103    5.7963    6.7742             9.5823  0.1 sec          1192.0 sec           5.0000\n",
      "      8     104    5.7315    6.6368             7.3889  0.1 sec          1193.0 sec           5.0000\n",
      "      8     105    6.3431    8.0561             8.7694  0.1 sec          1194.2 sec           5.0000\n",
      "      8     106    5.6719    6.5105             6.3712  0.1 sec          1195.2 sec           5.0000\n",
      "      8     107    4.9899    5.0729             5.5184  0.1 sec          1196.4 sec           4.9610\n",
      "      8     108    4.7093    4.5282             4.6870  0.1 sec          1197.5 sec           4.6080\n",
      "      8     109    5.5207    6.4622             7.8687  0.1 sec          1198.6 sec           5.0000\n",
      "      8     110    5.0866    5.2694             5.9670  0.1 sec          1199.7 sec           5.0000\n",
      "      8     111    5.8928    6.9787             7.1281  0.1 sec          1201.0 sec           5.0000\n",
      "      8     112    5.0053    5.0972             6.0784  0.1 sec          1202.2 sec           5.0000\n",
      "      8     113    6.8983    9.0649             9.4716  0.1 sec          1203.3 sec           5.0000\n",
      "      8     114    5.0023    5.0906             5.6448  0.1 sec          1204.4 sec           5.0000\n",
      "      8     115    6.5065    8.2799             6.8538  0.1 sec          1205.6 sec           5.0000\n",
      "      8     116    5.5125    6.1724             7.3450  0.1 sec          1206.7 sec           5.0000\n",
      "      8     117    6.4739    8.2107            10.6423  0.1 sec          1207.9 sec           5.0000\n",
      "      8     118    5.5267    6.3251             9.0958  0.1 sec          1209.1 sec           5.0000\n",
      "      8     119    5.3744    5.8796             7.4543  0.1 sec          1210.2 sec           5.0000\n",
      "      8     120    5.1832    5.4742             5.0833  0.1 sec          1211.3 sec           5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      8     121    6.4765    8.1141             9.9831  0.1 sec          1212.4 sec           5.0000\n",
      "      8     122    6.7090    8.7092             9.7064  0.1 sec          1213.6 sec           5.0000\n",
      "      8     123    6.0947    7.3878             6.1494  0.1 sec          1214.8 sec           4.9920\n",
      "      8     124    5.9837    7.1716             7.9737  0.1 sec          1216.1 sec           5.0000\n",
      "      8     125    5.5133    6.1742             8.1188  0.1 sec          1217.3 sec           5.0000\n",
      "      8     126    5.0805    5.2566             5.4544  0.1 sec          1218.4 sec           5.0000\n",
      "      8     127    5.6214    6.4034             7.1212  0.1 sec          1219.6 sec           5.0000\n",
      "      8     128    6.3636    7.8700            11.9148  0.1 sec          1221.0 sec           5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8     129    5.9956    7.1967             7.6682  0.1 sec          1222.1 sec           5.0000\n",
      "      8     130    7.9638   10.9124            12.8378  0.1 sec          1223.3 sec           5.0000\n",
      "      8     131    6.6901    8.6692             7.6110  0.1 sec          1224.5 sec           5.0000\n",
      "      8     132    5.0906    5.4005             5.2540  0.1 sec          1225.6 sec           5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      9       1    5.8259    6.8369             7.1157  0.1 sec          1226.8 sec           5.0000\n",
      "      9       2    6.9503    9.2208            11.2336  0.1 sec          1227.9 sec           5.0000\n",
      "      9       3    5.7336    6.6413             7.1999  0.1 sec          1229.0 sec           5.0000\n",
      "      9       4    5.3441    5.8155             5.8985  0.1 sec          1230.2 sec           5.0000\n",
      "      9       5    5.9076    7.0101             6.9456  0.1 sec          1231.3 sec           5.0000\n",
      "      9       6    7.4729   10.3288            10.1582  0.1 sec          1232.4 sec           5.0000\n",
      "      9       7    5.3151    5.7538             5.5149  0.1 sec          1233.5 sec           5.0000\n",
      "      9       8    4.9371    5.2248             4.9919  0.1 sec          1234.7 sec           5.0000\n",
      "      9       9    5.6556    6.4758             6.9532  0.1 sec          1235.8 sec           5.0000\n",
      "      9      10    5.6781    6.5235             6.8436  0.1 sec          1236.9 sec           5.0000\n",
      "      9      11    6.0144    7.2365             7.7221  0.1 sec          1238.0 sec           5.0000\n",
      "      9      12    6.0354    7.2810             8.0318  0.1 sec          1239.1 sec           5.0000\n",
      "      9      13    5.1774    5.4620             5.8869  0.1 sec          1240.3 sec           5.0000\n",
      "      9      14    5.7281    6.7522             5.7459  0.1 sec          1241.6 sec           5.0000\n",
      "      9      15    8.4214   12.0806            11.4910  0.1 sec          1242.8 sec           5.0000\n",
      "      9      16    5.6044    6.3673             6.3299  0.1 sec          1243.9 sec           5.0000\n",
      "      9      17    5.5286    6.2066             6.2227  0.1 sec          1245.1 sec           5.0000\n",
      "      9      18    7.7612   11.0626            13.7601  0.1 sec          1246.3 sec           5.0000\n",
      "      9      19    5.0075    5.1018             4.7806  0.1 sec          1247.5 sec           5.0000\n",
      "      9      20    6.5597    8.3927             8.8929  0.1 sec          1248.6 sec           5.0000\n",
      "      9      21    5.3139    5.7513             8.4095  0.1 sec          1249.8 sec           5.0000\n",
      "      9      22    5.5973    6.4749             7.0410  0.1 sec          1251.0 sec           5.0000\n",
      "      9      23    4.7699    4.5979             4.8460  0.1 sec          1252.1 sec           5.0000\n",
      "      9      24    5.2020    5.4120             5.2877  0.1 sec          1253.3 sec           5.0000\n",
      "      9      25    5.8049    6.7924             8.1413  0.1 sec          1254.5 sec           5.0000\n",
      "      9      26    6.3065    7.8559             8.1206  0.1 sec          1255.5 sec           5.0000\n",
      "      9      27    5.9057    7.0062             5.9523  0.1 sec          1256.7 sec           5.0000\n",
      "      9      28    5.2917    5.7042             5.6170  0.1 sec          1257.8 sec           5.0000\n",
      "      9      29    5.5440    6.2392             5.7204  0.1 sec          1258.9 sec           5.0000\n",
      "      9      30    6.1427    7.5085             8.0120  0.1 sec          1260.1 sec           5.0000\n",
      "      9      31    7.5633   10.5114            11.5734  0.1 sec          1261.3 sec           5.0000\n",
      "      9      32    5.0633    5.3426             4.9812  0.1 sec          1262.4 sec           5.0000\n",
      "      9      33    5.2742    5.6671             5.4425  0.1 sec          1263.5 sec           5.0000\n",
      "      9      34    6.5595    8.5148             7.8079  0.1 sec          1264.8 sec           5.0000\n",
      "      9      35    5.9306    7.0589             6.3659  0.1 sec          1265.8 sec           5.0000\n",
      "      9      36    5.9428    7.0847             5.8551  0.1 sec          1267.0 sec           5.0000\n",
      "      9      37    5.7377    6.6499             6.7860  0.1 sec          1268.1 sec           5.0000\n",
      "      9      38    6.6069    8.4927             8.2501  0.1 sec          1269.2 sec           5.0000\n",
      "      9      39    7.1840    9.8389             8.8201  0.1 sec          1270.4 sec           5.0000\n",
      "      9      40    6.7342    8.7627             9.1578  0.1 sec          1271.6 sec           5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      9      41    5.6440    6.4513             6.1595  0.1 sec          1272.8 sec           5.0000\n",
      "      9      42    4.9923    5.1921             4.7214  0.1 sec          1273.9 sec           5.0000\n",
      "      9      43    7.8862    9.8815            11.3287  0.1 sec          1275.1 sec           5.0000\n",
      "      9      44    4.6407    4.4466             5.2920  0.1 sec          1276.2 sec           5.0000\n",
      "      9      45    6.6473    8.5784             7.2073  0.1 sec          1277.4 sec           5.0000\n",
      "      9      46    5.4402    6.0192             6.5128  0.1 sec          1278.6 sec           5.0000\n",
      "      9      47    7.9067   11.1859            11.7427  0.1 sec          1279.8 sec           5.0000\n",
      "      9      48    5.6779    6.4210             7.1342  0.1 sec          1281.0 sec           5.0000\n",
      "      9      49    5.6872    6.5428             7.4177  0.1 sec          1282.1 sec           5.0000\n",
      "      9      50    6.4432    8.1458             8.6374  0.1 sec          1283.3 sec           5.0000\n",
      "      9      51    5.1982    5.6287             6.0474  0.1 sec          1284.4 sec           5.0000\n",
      "      9      52    5.5286    6.2065             5.5600  0.1 sec          1285.5 sec           5.0000\n",
      "      9      53    5.6331    6.4281             6.3088  0.1 sec          1286.6 sec           5.0000\n",
      "      9      54    5.4697    6.2042             6.6356  0.1 sec          1287.9 sec           5.0000\n",
      "      9      55    5.2665    5.6508             5.3860  0.1 sec          1289.1 sec           5.0000\n",
      "      9      56    4.9306    4.9387             5.5612  0.2 sec          1290.5 sec           5.0000\n",
      "      9      57    5.4740    6.0908             6.0397  0.1 sec          1291.8 sec           5.0000\n",
      "      9      58    5.4369    6.0121             5.4221  0.1 sec          1293.0 sec           5.0000\n",
      "      9      59    5.1508    5.4056             5.9070  0.1 sec          1294.2 sec           5.0000\n",
      "      9      60    4.7850    4.6301             4.5446  0.1 sec          1295.4 sec           5.0000\n",
      "      9      61    5.5902    6.3371             6.5034  0.1 sec          1296.6 sec           5.0000\n",
      "      9      62    6.2708    7.7801             7.6127  0.1 sec          1297.8 sec           5.0000\n",
      "      9      63    7.5161   10.4203            13.4398  0.1 sec          1299.0 sec           5.0000\n",
      "      9      64    5.9931    7.1914             8.2167  0.1 sec          1300.2 sec           5.0000\n",
      "      9      65    6.8485    9.0051             7.1421  0.1 sec          1301.3 sec           5.0000\n",
      "      9      66    4.5191    4.5259             5.3339  0.1 sec          1302.4 sec           5.0000\n",
      "      9      67    5.5833    6.5949             5.4921  0.1 sec          1303.7 sec           5.0000\n",
      "      9      68    5.3987    5.9311             6.5858  0.1 sec          1304.8 sec           5.0000\n",
      "      9      69    5.6397    6.5647             8.2620  0.1 sec          1305.9 sec           5.0000\n",
      "      9      70    6.4573    8.1757            10.0616  0.1 sec          1307.0 sec           5.0000\n",
      "      9      71    5.3983    5.9304             6.2955  0.1 sec          1308.2 sec           5.0000\n",
      "      9      72    6.1497    7.5234             6.8835  0.1 sec          1309.5 sec           5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9      73    5.2675    5.5510             5.5836  0.1 sec          1310.7 sec           5.0000\n",
      "      9      74    5.5041    6.0524             5.6205  0.1 sec          1311.9 sec           5.0000\n",
      "      9      75    6.0271    7.2635             8.4338  0.1 sec          1313.1 sec           5.0000\n",
      "      9      76    6.2850    8.0826            10.6484  0.1 sec          1314.2 sec           5.0000\n",
      "      9      77    5.8437    6.8747             8.1323  0.1 sec          1315.3 sec           5.0000\n",
      "      9      78    5.5098    6.1666             5.8940  0.1 sec          1316.5 sec           5.0000\n",
      "      9      79    5.3451    6.0899             6.7606  0.1 sec          1317.7 sec           5.0000\n",
      "      9      80    6.4497    8.1594             6.0740  0.1 sec          1318.8 sec           5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      9      81    5.1585    5.4219             6.1119  0.1 sec          1320.0 sec           5.0000\n",
      "      9      82    5.8271    6.8395             6.9374  0.1 sec          1321.2 sec           5.0000\n",
      "      9      83    5.2270    5.5671             6.3230  0.1 sec          1322.3 sec           5.0000\n",
      "      9      84    5.6038    6.4886             7.5123  0.1 sec          1323.4 sec           5.0000\n",
      "      9      85    5.9554    7.1115             5.8685  0.1 sec          1324.5 sec           5.0000\n",
      "      9      86    6.5956    8.4687             7.7285  0.1 sec          1325.6 sec           5.0000\n",
      "      9      87    6.8758    9.0630             7.8223  0.1 sec          1326.8 sec           5.0000\n",
      "      9      88    5.7398    6.5521             6.8536  0.1 sec          1327.9 sec           5.0000\n",
      "      9      89    5.5312    6.2120             5.6811  0.1 sec          1329.1 sec           5.0000\n",
      "      9      90    5.4174    5.9709             6.6651  0.1 sec          1330.3 sec           5.0000\n",
      "      9      91    5.3120    5.8699             6.0677  0.1 sec          1331.4 sec           5.0000\n",
      "      9      92    5.7352    6.6447             8.7394  0.1 sec          1332.6 sec           5.0000\n",
      "      9      93    6.7259    8.8676            11.3195  0.1 sec          1333.7 sec           5.0000\n",
      "      9      94    8.2503   10.9257            11.6507  0.1 sec          1334.9 sec           5.0000\n",
      "      9      95    5.8119    6.8072             7.3375  0.1 sec          1336.1 sec           5.0000\n",
      "      9      96    5.3828    5.8975             6.7441  0.1 sec          1337.1 sec           5.0000\n",
      "      9      97    5.2891    5.6989             5.9970  0.1 sec          1338.3 sec           5.0000\n",
      "      9      98    5.3710    5.8724             5.6116  0.1 sec          1339.4 sec           5.0000\n",
      "      9      99    4.9840    5.1745             6.5568  0.1 sec          1340.6 sec           5.0000\n",
      "      9     100    5.7264    6.6260             6.9685  0.1 sec          1341.7 sec           5.0000\n",
      "      9     101    5.2497    5.6153             5.1915  0.1 sec          1342.9 sec           5.0000\n",
      "      9     102    4.9307    4.9389             5.2728  0.1 sec          1344.2 sec           5.0000\n",
      "      9     103    5.9806    7.1650             5.0851  0.1 sec          1345.3 sec           5.0000\n",
      "      9     104    5.5520    6.2562             6.8728  0.1 sec          1346.4 sec           5.0000\n",
      "      9     105    5.4899    6.2471             6.9037  0.1 sec          1347.5 sec           5.0000\n",
      "      9     106    6.3766    8.0044             7.2393  0.1 sec          1348.6 sec           5.0000\n",
      "      9     107    5.4669    6.0738             6.0023  0.1 sec          1349.8 sec           4.9590\n",
      "      9     108    4.9766    5.0372             5.5081  0.1 sec          1350.9 sec           4.7820\n",
      "      9     109    5.3672    6.1367             7.8115  0.1 sec          1352.0 sec           5.0000\n",
      "      9     110    4.8359    4.7379             4.8295  0.1 sec          1353.1 sec           5.0000\n",
      "      9     111    5.3337    5.7933             5.9939  0.1 sec          1354.3 sec           5.0000\n",
      "      9     112    5.2375    5.5894             5.6588  0.1 sec          1355.4 sec           5.0000\n",
      "      9     113    6.7966    8.7895             8.4765  0.1 sec          1356.5 sec           5.0000\n",
      "      9     114    5.2154    5.5426             5.9453  0.1 sec          1357.6 sec           5.0000\n",
      "      9     115    6.4881    8.2408             9.7427  0.1 sec          1358.8 sec           5.0000\n",
      "      9     116    5.9249    7.0467             8.0105  0.1 sec          1360.0 sec           5.0000\n",
      "      9     117    6.4980    8.2620            10.4415  0.1 sec          1361.2 sec           5.0000\n",
      "      9     118    5.5104    6.2905             9.1098  0.1 sec          1362.4 sec           5.0000\n",
      "      9     119    5.6520    6.4683             8.2034  0.1 sec          1363.4 sec           5.0000\n",
      "      9     120    5.0340    5.1579             4.9940  0.1 sec          1364.6 sec           5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "      9     121    6.2965    7.7326             9.1973  0.1 sec          1365.8 sec           5.0000\n",
      "      9     122    7.6561   10.7172            11.2052  0.1 sec          1367.0 sec           5.0000\n",
      "      9     123    6.0413    7.1740             5.9819  0.1 sec          1368.1 sec           4.8910\n",
      "      9     124    6.2001    7.6303             9.1198  0.1 sec          1369.3 sec           5.0000\n",
      "      9     125    6.1689    7.5642             6.8998  0.1 sec          1370.4 sec           5.0000\n",
      "      9     126    5.0600    5.2130             5.3972  0.1 sec          1371.7 sec           5.0000\n",
      "      9     127    5.6222    6.4051             7.5478  0.1 sec          1372.8 sec           5.0000\n",
      "      9     128    6.6822    8.5502            10.4051  0.1 sec          1374.0 sec           5.0000\n",
      "      9     129    6.7042    8.6992             9.7635  0.1 sec          1375.2 sec           5.0000\n",
      "      9     130    7.5861   10.2207            12.1500  0.1 sec          1376.3 sec           5.0000\n",
      "      9     131    6.7205    8.7335             7.8683  0.1 sec          1377.5 sec           5.0000\n",
      "      9     132    5.6729    6.6350             7.1902  0.1 sec          1378.6 sec           5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "     10       1    6.1861    7.6007             8.4557  0.1 sec          1379.8 sec           5.0000\n",
      "     10       2    6.9142    9.1442            11.8516  0.1 sec          1380.9 sec           5.0000\n",
      "     10       3    5.6074    6.3737             5.8015  0.1 sec          1382.0 sec           5.0000\n",
      "     10       4    5.2863    5.6928             5.4752  0.1 sec          1383.2 sec           5.0000\n",
      "     10       5    5.8234    6.8315             6.5305  0.1 sec          1384.4 sec           5.0000\n",
      "     10       6    8.1567   11.7786            11.5288  0.1 sec          1385.5 sec           5.0000\n",
      "     10       7    6.1178    7.4558             6.9362  0.1 sec          1386.6 sec           5.0000\n",
      "     10       8    5.7773    7.0062             8.6340  0.1 sec          1387.8 sec           5.0000\n",
      "     10       9    5.4446    6.0285             6.3610  0.1 sec          1388.9 sec           5.0000\n",
      "     10      10    5.2600    5.6370             5.5512  0.1 sec          1390.0 sec           5.0000\n",
      "     10      11    5.6449    6.4532             6.8328  0.1 sec          1391.1 sec           5.0000\n",
      "     10      12    6.2410    7.7169             8.7475  0.1 sec          1392.3 sec           5.0000\n",
      "     10      13    5.2300    5.5734             5.2357  0.2 sec          1393.5 sec           5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10      14    6.2343    7.8252             7.0313  0.1 sec          1394.7 sec           5.0000\n",
      "     10      15    6.3352    7.9168             6.4208  0.1 sec          1395.9 sec           5.0000\n",
      "     10      16    5.4782    6.0998             6.5677  0.1 sec          1397.1 sec           5.0000\n",
      "     10      17    6.0974    7.4126             7.6852  0.1 sec          1398.3 sec           5.0000\n",
      "     10      18    5.8231    6.9534             6.4806  0.1 sec          1399.4 sec           5.0000\n",
      "     10      19    5.0165    5.1209             4.9259  0.1 sec          1400.7 sec           5.0000\n",
      "     10      20    4.9636    5.0087             5.0833  0.1 sec          1401.8 sec           5.0000\n",
      "     10      21    6.0245    7.2579             4.8179  0.1 sec          1402.9 sec           5.0000\n",
      "     10      22    5.8275    6.9628             7.5969  0.1 sec          1404.0 sec           5.0000\n",
      "     10      23    5.2100    5.5310             6.4534  0.1 sec          1405.2 sec           5.0000\n",
      "     10      24    5.0381    5.0645             5.2567  0.1 sec          1406.3 sec           5.0000\n",
      "     10      25    5.9804    7.1645             8.9898  0.1 sec          1407.5 sec           5.0000\n",
      "     10      26    5.7015    6.5731             7.4132  0.1 sec          1408.7 sec           5.0000\n",
      "     10      27    5.2911    5.7031             6.3853  0.1 sec          1409.9 sec           5.0000\n",
      "     10      28    5.8436    6.8745             6.6455  0.1 sec          1411.0 sec           5.0000\n",
      "     10      29    5.3538    5.8361             5.6549  0.1 sec          1412.2 sec           5.0000\n",
      "     10      30    6.0922    7.4016             7.5789  0.1 sec          1413.4 sec           5.0000\n",
      "     10      31    7.0125    9.3528            10.9393  0.1 sec          1414.6 sec           5.0000\n",
      "     10      32    4.8919    4.9792             5.0728  0.1 sec          1415.8 sec           5.0000\n",
      "     10      33    5.4779    6.0990             5.2046  0.1 sec          1417.3 sec           5.0000\n",
      "     10      34    5.7967    6.8975             6.4392  0.1 sec          1418.5 sec           5.0000\n",
      "     10      35    5.7815    6.7428             6.1101  0.1 sec          1419.6 sec           5.0000\n",
      "     10      36    5.1820    5.4718             5.4188  0.1 sec          1420.7 sec           5.0000\n",
      "     10      37    5.6811    6.5300             8.1537  0.1 sec          1421.8 sec           5.0000\n",
      "     10      38    6.5474    8.3667             7.8659  0.1 sec          1423.1 sec           5.0000\n",
      "     10      39    5.9552    7.2336             9.9816  0.1 sec          1424.2 sec           5.0000\n",
      "     10      40    6.2112    7.6537             6.7896  0.1 sec          1425.4 sec           5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "     10      41    5.4618    6.0649             5.9781  0.1 sec          1426.6 sec           5.0000\n",
      "     10      42    4.9283    5.0564             5.0886  0.1 sec          1427.7 sec           5.0000\n",
      "     10      43    7.3878    9.2961            11.2685  0.1 sec          1428.9 sec           5.0000\n",
      "     10      44    4.7090    4.5913             5.2257  0.1 sec          1430.1 sec           5.0000\n",
      "     10      45    6.2253    7.6838             9.3783  0.1 sec          1431.3 sec           5.0000\n",
      "     10      46    5.3951    5.9234             5.8121  0.1 sec          1432.4 sec           5.0000\n",
      "     10      47    8.7344   12.6977            13.1642  0.1 sec          1433.6 sec           5.0000\n",
      "     10      48    5.9691    7.0383             8.0763  0.1 sec          1434.9 sec           5.0000\n",
      "     10      49    6.0394    7.2895             8.2262  0.1 sec          1436.0 sec           5.0000\n",
      "     10      50    6.2040    7.6385             9.7099  0.1 sec          1437.2 sec           5.0000\n",
      "     10      51    5.2693    5.7795             7.6603  0.1 sec          1438.2 sec           5.0000\n",
      "     10      52    5.6733    6.5134             5.7872  0.1 sec          1439.4 sec           5.0000\n",
      "     10      53    5.8423    6.8717             6.7025  0.1 sec          1440.5 sec           5.0000\n",
      "     10      54    5.7580    6.8156             7.0564  0.1 sec          1441.7 sec           5.0000\n",
      "     10      55    5.0788    5.2529             5.3740  0.1 sec          1442.8 sec           5.0000\n",
      "     10      56    5.4177    5.9715             7.0596  0.1 sec          1444.0 sec           5.0000\n",
      "     10      57    5.8240    6.8329             7.5230  0.1 sec          1445.2 sec           5.0000\n",
      "     10      58    5.4339    6.0058             7.3411  0.1 sec          1446.3 sec           5.0000\n",
      "     10      59    7.7218   10.8566            11.4607  0.1 sec          1447.5 sec           5.0000\n",
      "     10      60    4.7275    4.5081             4.5065  0.1 sec          1448.7 sec           5.0000\n",
      "     10      61    5.8081    6.7991             6.1457  0.1 sec          1449.8 sec           5.0000\n",
      "     10      62    5.6626    6.4907             6.7477  0.1 sec          1451.0 sec           5.0000\n",
      "     10      63    5.7977    6.7771             9.6905  0.1 sec          1452.2 sec           5.0000\n",
      "     10      64    5.6437    6.4507             8.4705  0.1 sec          1453.3 sec           5.0000\n",
      "     10      65    6.4398    8.1386             7.0187  0.1 sec          1454.5 sec           5.0000\n",
      "     10      66    6.5541    8.8403             9.4898  0.1 sec          1455.6 sec           5.0000\n",
      "     10      67    5.0881    5.5449             5.5720  0.1 sec          1456.8 sec           5.0000\n",
      "     10      68    6.6261    8.5335             9.2877  0.1 sec          1457.9 sec           5.0000\n",
      "     10      69    5.5793    6.4365             8.6987  0.1 sec          1459.1 sec           5.0000\n",
      "     10      70    6.8215    8.9477            11.0822  0.1 sec          1460.3 sec           5.0000\n",
      "     10      71    5.5156    6.1790             5.6584  0.1 sec          1461.5 sec           5.0000\n",
      "     10      72    5.2533    5.6229             6.0590  0.1 sec          1462.8 sec           5.0000\n",
      "     10      73    6.0142    7.1340             7.9024  0.1 sec          1463.9 sec           5.0000\n",
      "     10      74    5.3256    5.6741             6.8662  0.1 sec          1465.0 sec           5.0000\n",
      "     10      75    6.0323    7.2745             9.3471  0.1 sec          1466.2 sec           5.0000\n",
      "     10      76    6.1501    7.7966             8.6010  0.1 sec          1467.4 sec           5.0000\n",
      "     10      77    5.1412    5.3852             5.5360  0.1 sec          1468.5 sec           5.0000\n",
      "     10      78    5.5211    6.1908             5.9301  0.1 sec          1469.8 sec           5.0000\n",
      "     10      79    4.9276    5.2046             5.4420  0.1 sec          1470.9 sec           5.0000\n",
      "     10      80    5.7737    6.7262             4.8009  0.1 sec          1472.1 sec           5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "     10      81    5.0329    5.1555             5.2079  0.1 sec          1473.2 sec           5.0000\n",
      "     10      82    5.6370    6.4364             6.8506  0.1 sec          1474.3 sec           5.0000\n",
      "     10      83    5.2835    5.6870             6.5359  0.1 sec          1475.4 sec           5.0000\n",
      "     10      84    4.9906    5.1886             6.1160  0.1 sec          1476.5 sec           5.0000\n",
      "     10      85    5.7735    6.7259             5.5397  0.1 sec          1477.6 sec           5.0000\n",
      "     10      86    5.5858    6.3278             5.9353  0.1 sec          1478.7 sec           5.0000\n",
      "     10      87    5.0649    5.2235             5.3155  0.1 sec          1479.9 sec           5.0000\n",
      "     10      88    5.2732    5.5628             6.7600  0.1 sec          1481.0 sec           5.0000\n",
      "     10      89    5.3888    5.9102             6.8437  0.1 sec          1482.1 sec           5.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10      90    5.4987    6.1432             5.9754  0.1 sec          1483.2 sec           5.0000\n",
      "     10      91    5.2865    5.8158             5.7276  0.1 sec          1484.3 sec           5.0000\n",
      "     10      92    5.3610    5.8512             6.3108  0.1 sec          1485.5 sec           5.0000\n",
      "     10      93    6.5599    8.5157            10.4067  0.1 sec          1486.6 sec           5.0000\n",
      "     10      94    7.9840   10.4034            11.3262  0.1 sec          1487.9 sec           5.0000\n",
      "     10      95    5.8360    6.8583             7.4122  0.1 sec          1489.1 sec           5.0000\n",
      "     10      96    5.5976    6.3530             7.4615  0.1 sec          1490.5 sec           5.0000\n",
      "     10      97    4.9650    5.0117             5.4072  0.4 sec          1492.1 sec           5.0000\n",
      "     10      98    5.3032    5.7287             5.2253  0.2 sec          1493.5 sec           5.0000\n",
      "     10      99    4.9210    5.0410             5.9517  0.2 sec          1495.0 sec           5.0000\n",
      "     10     100    5.4122    5.9598             6.0114  0.2 sec          1496.5 sec           5.0000\n",
      "     10     101    5.0750    5.2449             5.0902  0.2 sec          1498.1 sec           5.0000\n",
      "     10     102    4.8314    4.7283             5.3631  0.2 sec          1499.7 sec           5.0000\n",
      "     10     103    5.1800    5.4674             4.7914  0.2 sec          1501.2 sec           5.0000\n",
      "     10     104    5.5511    6.2543             6.7387  0.4 sec          1502.8 sec           5.0000\n",
      "     10     105    5.6231    6.5296             7.9492  0.2 sec          1504.3 sec           5.0000\n",
      "     10     106    5.6958    6.5610             5.9173  0.3 sec          1506.0 sec           5.0000\n",
      "     10     107    5.0460    5.1863             5.3604  0.2 sec          1507.7 sec           4.9670\n",
      "     10     108    4.6153    4.3184             4.4305  0.3 sec          1509.4 sec           4.6440\n",
      "     10     109    5.3891    6.1831             7.6322  0.3 sec          1511.0 sec           5.0000\n",
      "     10     110    5.0258    5.1406             6.5674  0.2 sec          1512.5 sec           5.0000\n",
      "     10     111    4.8101    4.6832             4.7855  0.2 sec          1514.2 sec           5.0000\n",
      "     10     112    5.5527    6.2577             4.8949  0.3 sec          1515.8 sec           5.0000\n",
      "     10     113    7.4240   10.0955            10.6459  0.1 sec          1517.2 sec           5.0000\n",
      "     10     114    5.2829    5.6856             5.8974  0.1 sec          1518.6 sec           5.0000\n",
      "     10     115    6.2388    7.7124             6.2409  0.2 sec          1520.1 sec           5.0000\n",
      "     10     116    5.5129    6.1733             6.7563  0.2 sec          1521.6 sec           5.0000\n",
      "     10     117    6.3078    7.8586            10.5880  0.1 sec          1523.0 sec           5.0000\n",
      "     10     118    5.7794    6.8608            10.1217  0.2 sec          1524.4 sec           5.0000\n",
      "     10     119    6.3874    8.0275            10.6589  0.1 sec          1525.7 sec           5.0000\n",
      "     10     120    5.5285    6.2064             5.5471  0.2 sec          1527.2 sec           5.0000\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "     10     121    5.5028    6.0498             6.3655  0.3 sec          1528.8 sec           5.0000\n",
      "     10     122    5.0165    5.1209             6.8055  0.3 sec          1530.5 sec           5.0000\n",
      "     10     123    6.1213    7.3429             6.2746  0.1 sec          1532.0 sec           4.8780\n",
      "     10     124    5.9476    7.0950             7.4240  0.2 sec          1533.6 sec           5.0000\n",
      "     10     125    5.7597    6.6966             7.0005  0.3 sec          1535.2 sec           5.0000\n",
      "     10     126    5.0746    5.2440             5.8516  0.2 sec          1536.7 sec           5.0000\n",
      "     10     127    4.8493    4.7663             4.8766  0.2 sec          1538.4 sec           5.0000\n",
      "     10     128    6.6005    8.3771            10.6186  0.2 sec          1540.2 sec           5.0000\n",
      "     10     129    5.0837    5.2633             5.7185  0.2 sec          1541.7 sec           5.0000\n",
      "     10     130    6.7514    8.6711            10.9110  0.3 sec          1543.3 sec           5.0000\n",
      "     10     131    5.8492    6.8862             6.6344  0.2 sec          1544.9 sec           5.0000\n",
      "     10     132    5.1956    5.6231             4.9938  0.2 sec          1546.4 sec           5.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCHS = 10\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in tqdm(range(MAX_EPOCHS)):\n",
    "    for cur_iter, data in enumerate(train_dataset):  # tqdm(, desc='Iteration over dataset'):\n",
    "#         if cur_iter >= 1:\n",
    "#             break\n",
    "        cur_start_time = time.time()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "#         loss = model(data)\n",
    "        percents, weeks, FVC_true, features, lungs, images = data\n",
    "        FVCs_mean, FVCs_std = 2690.479018721756, 832.5021066817238\n",
    "\n",
    "        all_preds = model(data)\n",
    "\n",
    "        agg_loss = 0\n",
    "        agg_metric = 0\n",
    "        agg_metric_last_3 = 0\n",
    "        for preds in all_preds:  # zip(, [None, ]):  # TODO: REMOVE!\n",
    "            FVC_preds, log_sigmas = preds.transpose(0, 1)\n",
    "            FVC_preds = FVC_preds * FVCs_std + FVCs_mean\n",
    "\n",
    "            agg_loss += LaplaceLoss()(FVC_true, FVC_preds, log_sigmas)\n",
    "#             agg_loss += nn.MSELoss()(FVC_true, FVC_preds).pow(0.5)  # , log_sigmas)\n",
    "            with torch.no_grad():\n",
    "                agg_metric += LaplaceLoss()(FVC_true, FVC_preds, torch.tensor(5.), metric=True).item()  # log_sigmas\n",
    "                agg_metric_last_3 += LaplaceLoss()(FVC_true[-3:], FVC_preds[-3:], torch.tensor(5.), metric=True).item()\n",
    "        loss = agg_loss / weeks.shape[0]\n",
    "        metric = agg_metric / weeks.shape[0]\n",
    "        metric_last_3 = agg_metric_last_3 / weeks.shape[0]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cur_end_time = time.time()\n",
    "\n",
    "        print_results('train', log_writer, epoch, cur_iter, loss, metric, metric_last_3,\n",
    "                      start_time, cur_start_time, cur_end_time, log_sigmas)\n",
    "\n",
    "#         print(\n",
    "#             f'Epoch {epoch + 1:3d}, '\n",
    "#             f'iter {cur_iter + 1:4d}, '\n",
    "#             f'loss {loss.item():12.6f}, '\n",
    "#             f'metric {metric:12.6f}, '\n",
    "#             f'metric (last 3) {metric_last_3:12.6f}, '\n",
    "#             f'cur iter time {cur_end_time - cur_start_time:6.1f} sec, '\n",
    "#             f'elapsed time {cur_end_time - start_time:6.1f} sec, '\n",
    "#             f'log sigma {log_sigmas.detach().mean().item()}'\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "     10       1    5.7202    5.3873             5.2042  0.5 sec          1.9 sec              4.2480\n",
      "loss tensor(5.7202) metric 5.387323803371853 metric_last_3 5.204214043087429 metric_by_first_week 5.753589153289795 metric_last_3_by_first_week 5.813117980957031\n",
      "     10       2    9.1193   12.5940            15.4620  0.1 sec          3.6 sec              4.2480\n",
      "loss tensor(7.4198) metric 8.990668568346235 metric_last_3 10.333087179395887 metric_by_first_week 9.80460810661316 metric_last_3_by_first_week 14.233376502990723\n",
      "     10       3    6.9437    7.9812             9.6980  0.1 sec          5.5 sec              4.2480\n",
      "loss tensor(7.2611) metric 8.654176734111926 metric_last_3 10.121376284846553 metric_by_first_week 9.644667466481527 metric_last_3_by_first_week 13.459429105122885\n",
      "     10       4    8.3885   11.0445            13.8308  0.1 sec          7.0 sec              4.2480\n",
      "loss tensor(7.5429) metric 9.251769930124283 metric_last_3 11.048733313878376 metric_by_first_week 10.442800402641296 metric_last_3_by_first_week 14.961460828781128\n",
      "     10       5    8.4984   11.2775            10.4445  0.1 sec          8.5 sec              4.2480\n",
      "loss tensor(7.7340) metric 9.656925415992736 metric_last_3 10.92789311091105 metric_by_first_week 10.332830715179444 metric_last_3_by_first_week 13.799166488647462\n",
      "     10       6    6.2270    6.4618             6.1509  0.1 sec          10.1 sec             4.2480\n",
      "loss tensor(7.4829) metric 9.124408344427744 metric_last_3 10.13172237254955 metric_by_first_week 9.595600843429565 metric_last_3_by_first_week 12.38299528757731\n",
      "     10       7    7.1568    8.4332            11.2624  0.1 sec          11.8 sec             4.2480\n",
      "loss tensor(7.4363) metric 9.025658794811793 metric_last_3 10.29324642400893 metric_by_first_week 9.36430447442191 metric_last_3_by_first_week 12.141479355948311\n",
      "     10       8    6.7057    7.4766             7.0801  0.1 sec          13.3 sec             4.2480\n",
      "loss tensor(7.3450) metric 8.832028272747994 metric_last_3 9.891598121656312 metric_by_first_week 8.986853063106537 metric_last_3_by_first_week 11.361072480678558\n",
      "     10       9    6.7593    7.5904             7.4399  0.1 sec          15.0 sec             4.2480\n",
      "loss tensor(7.2799) metric 8.69406484939434 metric_last_3 9.619189959690894 metric_by_first_week 8.77989149093628 metric_last_3_by_first_week 10.936843130323622\n",
      "     10      10    6.3920    6.8115             6.7226  0.1 sec          16.5 sec             4.2480\n",
      "loss tensor(7.1911) metric 8.5058060669899 metric_last_3 9.32952998717626 metric_by_first_week 8.464672231674195 metric_last_3_by_first_week 10.510311222076416\n",
      "     10      11    6.6359    7.3286             9.1691  0.1 sec          18.1 sec             4.2480\n",
      "loss tensor(7.1406) metric 8.398788892620741 metric_last_3 9.31494490522327 metric_by_first_week 8.409715349023992 metric_last_3_by_first_week 10.491965900767934\n",
      "     10      12    6.7304    7.5291             6.8479  0.1 sec          19.6 sec             4.2480\n",
      "loss tensor(7.1064) metric 8.326318628037418 metric_last_3 9.109358970544957 metric_by_first_week 8.262764175732931 metric_last_3_by_first_week 10.30960456530253\n",
      "     10      13    7.3859    8.9188             9.2828  0.1 sec          21.2 sec             4.2480\n",
      "loss tensor(7.1279) metric 8.371890422421643 metric_last_3 9.122703638647357 metric_by_first_week 8.263557470761812 metric_last_3_by_first_week 10.393873068002554\n",
      "     10      14    6.4445    6.9229             6.0445  0.1 sec          22.7 sec             4.2480\n",
      "loss tensor(7.0791) metric 8.268392960041288 metric_last_3 8.902833492793734 metric_by_first_week 8.134356090000697 metric_last_3_by_first_week 10.040124518530709\n",
      "     10      15    7.2663    8.6653             8.4571  0.1 sec          24.2 sec             4.2480\n",
      "loss tensor(7.0916) metric 8.294853192611978 metric_last_3 8.873116045351383 metric_by_first_week 8.080185476938883 metric_last_3_by_first_week 10.056830437978109\n",
      "     10      16    7.9703   10.1579            10.0578  0.1 sec          25.6 sec             4.2480\n",
      "loss tensor(7.1465) metric 8.41129161235359 metric_last_3 8.947160692099068 metric_by_first_week 8.015397667884827 metric_last_3_by_first_week 9.82494068145752\n",
      "     10      17    6.8316    7.7437             6.9362  0.1 sec          27.2 sec             4.2480\n",
      "loss tensor(7.1280) metric 8.372019795654648 metric_last_3 8.828869181754541 metric_by_first_week 8.054794648114372 metric_last_3_by_first_week 9.593712161569034\n",
      "     10      18    8.0837   10.3983             9.1352  0.1 sec          28.7 sec             4.2480\n",
      "loss tensor(7.1811) metric 8.484591151314017 metric_last_3 8.845889310262821 metric_by_first_week 8.281663311852348 metric_last_3_by_first_week 9.667391591601902\n",
      "     10      19    6.3067    6.6307             6.4877  0.1 sec          30.3 sec             4.2480\n",
      "loss tensor(7.1351) metric 8.387019779110512 metric_last_3 8.721772100005234 metric_by_first_week 8.17286007027877 metric_last_3_by_first_week 9.480891905332866\n",
      "     10      20    8.0284   10.2811             9.7127  0.1 sec          31.8 sec             4.2480\n",
      "loss tensor(7.1797) metric 8.481725104517407 metric_last_3 8.771316147711541 metric_by_first_week 8.187274956703186 metric_last_3_by_first_week 9.492486929893493\n",
      "     10      21    6.4159    6.8623             7.1362  0.1 sec          33.3 sec             4.2480\n",
      "loss tensor(7.1434) metric 8.404611909074127 metric_last_3 8.693452412047714 metric_by_first_week 8.125157583327521 metric_last_3_by_first_week 9.422084740230016\n",
      "     10      22    7.2500    8.6307             8.9808  0.1 sec          35.0 sec             4.2480\n",
      "loss tensor(7.1482) metric 8.414886393811967 metric_last_3 8.706512870993278 metric_by_first_week 8.151354442943227 metric_last_3_by_first_week 9.39557485146956\n",
      "     10      23    6.7810    7.6363             8.7011  0.1 sec          36.5 sec             4.2480\n",
      "loss tensor(7.1322) metric 8.381033601277116 metric_last_3 8.706278808623695 metric_by_first_week 8.079050644584324 metric_last_3_by_first_week 9.307588929715363\n",
      "     10      24    7.4655    9.0875             8.1304  0.1 sec          38.1 sec             4.2480\n",
      "loss tensor(7.1461) metric 8.410471612546178 metric_last_3 8.682285807916411 metric_by_first_week 8.290223876635233 metric_last_3_by_first_week 9.43886556228002\n",
      "     10      25    9.7388   13.6585            15.1496  0.1 sec          39.7 sec             4.2480\n",
      "loss tensor(7.2498) metric 8.620393037690057 metric_last_3 8.940978982872434 metric_by_first_week 8.393498153686524 metric_last_3_by_first_week 9.742481060028076\n",
      "     10      26    6.6484    7.3552             6.5688  0.1 sec          41.3 sec             4.2480\n",
      "loss tensor(7.2267) metric 8.571733543404147 metric_last_3 8.849739623018818 metric_by_first_week 8.325851605488705 metric_last_3_by_first_week 9.614273878244253\n",
      "     10      27    6.3094    6.6364             6.6949  0.1 sec          42.8 sec             4.2480\n",
      "loss tensor(7.1927) metric 8.500054264657292 metric_last_3 8.769929136415568 metric_by_first_week 8.236720667945015 metric_last_3_by_first_week 9.49451349399708\n",
      "     10      28    7.9159   10.0424             9.8584  0.1 sec          44.4 sec             4.2480\n",
      "loss tensor(7.2186) metric 8.55513977569247 metric_last_3 8.808803955855824 metric_by_first_week 8.426244480269295 metric_last_3_by_first_week 9.628978507859367\n",
      "     10      29    7.6865    9.5562             8.9119  0.1 sec          46.0 sec             4.2480\n",
      "loss tensor(7.2347) metric 8.589657874308326 metric_last_3 8.812360394640445 metric_by_first_week 8.439482310722614 metric_last_3_by_first_week 9.57142004473456\n",
      "     10      30    7.4639    9.0842            10.6536  0.1 sec          47.6 sec             4.2480\n",
      "loss tensor(7.2423) metric 8.606141079266866 metric_last_3 8.87373446725033 metric_by_first_week 8.432548093795777 metric_last_3_by_first_week 9.577522214253744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10      31    6.8773    7.8406             7.3049  0.1 sec          49.1 sec             4.2480\n",
      "loss tensor(7.2306) metric 8.58144613611228 metric_last_3 8.823125582997518 metric_by_first_week 8.396107489062894 metric_last_3_by_first_week 9.528011691185736\n",
      "     10      32    8.8742   11.5666            12.9520  0.1 sec          50.8 sec             4.2480\n",
      "loss tensor(7.2819) metric 8.674732717706096 metric_last_3 8.952152442725168 metric_by_first_week 8.517435848712921 metric_last_3_by_first_week 9.715100139379501\n",
      "     10      33    5.8803    5.7266             5.8650  0.1 sec          52.3 sec             4.2480\n",
      "loss tensor(7.2394) metric 8.585395565945806 metric_last_3 8.85860270649381 metric_by_first_week 8.43679698308309 metric_last_3_by_first_week 9.60078477859497\n",
      "     10      34    7.2218    8.5708             9.5377  0.1 sec          53.9 sec             4.2480\n",
      "loss tensor(7.2389) metric 8.584966239007581 metric_last_3 8.878574766815543 metric_by_first_week 8.481925501542932 metric_last_3_by_first_week 9.709107048371258\n",
      "     10      35    7.3978    8.9440             9.7820  0.1 sec          55.3 sec             4.2480\n",
      "loss tensor(7.2435) metric 8.595225163306237 metric_last_3 8.90438584946721 metric_by_first_week 8.44237995147705 metric_last_3_by_first_week 9.62090436390468\n",
      "     10      36    6.8101    7.6981             8.6293  0.1 sec          56.8 sec             4.2480\n",
      "loss tensor(7.2314) metric 8.570305097881027 metric_last_3 8.896745565922593 metric_by_first_week 8.40284146202935 metric_last_3_by_first_week 9.617588321367899\n",
      "     10      37    7.7771    9.7483            10.7963  0.1 sec          58.3 sec             4.2480\n",
      "loss tensor(7.2462) metric 8.602143919759428 metric_last_3 8.948084701345183 metric_by_first_week 8.420813586260822 metric_last_3_by_first_week 9.634997019896636\n",
      "     10      38    6.9837    8.0661             7.0855  0.1 sec          59.9 sec             4.2480\n",
      "loss tensor(7.2393) metric 8.588037304611333 metric_last_3 8.899070243792625 metric_by_first_week 8.504362156516628 metric_last_3_by_first_week 9.700020150134439\n",
      "     10      39    6.4856    7.0100             6.3199  0.1 sec          61.5 sec             4.2480\n",
      "loss tensor(7.2199) metric 8.547574042497635 metric_last_3 8.83293668128729 metric_by_first_week 8.470734596252441 metric_last_3_by_first_week 9.608854244916866\n",
      "     10      40    7.0620    8.2322             8.6549  0.1 sec          63.0 sec             4.2480\n",
      "loss tensor(7.2160) metric 8.539689516264295 metric_last_3 8.82848605391052 metric_by_first_week 8.538528275489806 metric_last_3_by_first_week 9.719061756134034\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "  Epoch    Iter      Loss    Metric    Metric (last 3)  Cur iter time    Elapsed time      Log sigma\n",
      "-------  ------  --------  --------  -----------------  ---------------  --------------  -----------\n",
      "     10      41    6.2192    6.4452             6.5481  0.1 sec          64.8 sec             4.2480\n",
      "loss tensor(7.1917) metric 8.488605106979943 metric_last_3 8.772867821193323 metric_by_first_week 8.518513295708633 metric_last_3_by_first_week 9.65344777921351\n",
      "     10      42   10.6307   15.2646            18.0914  0.1 sec          66.3 sec             4.2480\n",
      "loss tensor(7.2736) metric 8.649939395357782 metric_last_3 8.994737170139949 metric_by_first_week 8.677785112744285 metric_last_3_by_first_week 10.01403522491455\n",
      "     10      43    6.8250    7.7296             8.4893  0.1 sec          67.7 sec             4.2480\n",
      "loss tensor(7.2631) metric 8.628537015001376 metric_last_3 8.982982321703465 metric_by_first_week 8.695929826692094 metric_last_3_by_first_week 10.051465367161951\n",
      "     10      44    7.4199    8.9909             8.9055  0.1 sec          69.3 sec             4.2480\n",
      "loss tensor(7.2667) metric 8.636772290237712 metric_last_3 8.981221967664633 metric_by_first_week 8.680779619650407 metric_last_3_by_first_week 10.040329391306097\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "sum_loss = 0\n",
    "sum_metric = 0\n",
    "sum_metric_last_3 = 0\n",
    "sum_metric_by_first_week = 0\n",
    "sum_metric_last_3_by_first_week = 0\n",
    "\n",
    "for cur_iter, data in enumerate(test_dataset):\n",
    "    cur_start_time = time.time()\n",
    "\n",
    "    percents, weeks, FVC_true, features, lungs, images = data\n",
    "    FVCs_mean, FVCs_std = 2690.479018721756, 832.5021066817238\n",
    "    with torch.no_grad():\n",
    "        all_preds = model(data)\n",
    "\n",
    "    agg_loss = 0\n",
    "    agg_metric = 0\n",
    "    agg_metric_last_3 = 0\n",
    "\n",
    "    for preds in all_preds:\n",
    "        FVC_preds, log_sigmas = preds.transpose(0, 1)\n",
    "        FVC_preds = FVC_preds * FVCs_std + FVCs_mean\n",
    "\n",
    "        agg_loss += LaplaceLoss()(FVC_true, FVC_preds, log_sigmas)\n",
    "#             agg_loss += nn.MSELoss()(FVC_true, FVC_preds).pow(0.5)  # , log_sigmas)\n",
    "#         with torch.no_grad():\n",
    "        agg_metric += LaplaceLoss()(FVC_true, FVC_preds, log_sigmas, metric=True).item()  # log_sigmas\n",
    "        agg_metric_last_3 += LaplaceLoss()(FVC_true[-3:], FVC_preds[-3:], log_sigmas[-3:], metric=True).item()\n",
    "    loss = agg_loss / weeks.shape[0]\n",
    "    metric = agg_metric / weeks.shape[0]\n",
    "    metric_last_3 = agg_metric_last_3 / weeks.shape[0]\n",
    "\n",
    "    FVC_preds, log_sigmas = all_preds[0].transpose(0, 1)\n",
    "    FVC_preds = FVC_preds * FVCs_std + FVCs_mean\n",
    "    metric_by_first_week = LaplaceLoss()(FVC_true, FVC_preds, log_sigmas, metric=True).item()\n",
    "    metric_last_3_by_first_week = LaplaceLoss()(FVC_true[-3:], FVC_preds[-3:], log_sigmas[-3:], metric=True).item()\n",
    "\n",
    "    sum_loss += loss\n",
    "    sum_metric += metric\n",
    "    sum_metric_last_3 += metric_last_3\n",
    "    sum_metric_by_first_week += metric_by_first_week\n",
    "    sum_metric_last_3_by_first_week += metric_last_3_by_first_week\n",
    "\n",
    "    cur_end_time = time.time()\n",
    "\n",
    "    print_results('test', log_writer, epoch, cur_iter, loss, metric, metric_last_3,\n",
    "                  start_time, cur_start_time, cur_end_time, log_sigmas)\n",
    "\n",
    "\n",
    "    print(\n",
    "        'loss', sum_loss / (cur_iter + 1),\n",
    "        'metric', sum_metric / (cur_iter + 1),\n",
    "        'metric_last_3', sum_metric_last_3 / (cur_iter + 1),\n",
    "        'metric_by_first_week', sum_metric_by_first_week / (cur_iter + 1),\n",
    "        'metric_last_3_by_first_week', sum_metric_last_3_by_first_week / (cur_iter + 1)\n",
    "    )\n",
    "\n",
    "#         print(\n",
    "#             f'Epoch {epoch + 1:3d}, '\n",
    "#             f'iter {cur_iter + 1:4d}, '\n",
    "#             f'loss {loss.item():12.6f}, '\n",
    "#             f'metric {metric:12.6f}, '\n",
    "#             f'metric (last 3) {metric_last_3:12.6f}, '\n",
    "#             f'cur iter time {cur_end_time - cur_start_time:6.1f} sec, '\n",
    "#             f'elapsed time {cur_end_time - start_time:6.1f} sec, '\n",
    "#             f'log sigma {log_sigmas.detach().mean().item()}'\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in optimizer.param_groups:\n",
    "    g['lr'] *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.79811972337355"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(2) * 1000 / 70 + np.log(70) + np.log(2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2390, 2390, 2322, 2305, 2116, 2036, 2062, 1865, 1928, 1901, 2322])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FVC_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2279.0103, 2140.1113, 2132.3945, 2124.6780, 2116.9614, 2109.2446,\n",
       "        2086.0950, 2039.7952, 1989.6372, 1927.9043, 1715.6973],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds[0][:, 0] * FVCs_std + FVCs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_diff = (all_preds[0][:, 0] * FVCs_std + FVCs_mean - FVC_true).abs()\n",
    "losses = np.sqrt(2) * abs_diff / 70 + np.log(70) + np.log(2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.7151, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplaceLoss(nn.Module):  # _Loss):\n",
    "    def forward(self, y_true, preds, log_sigma, metric=False):\n",
    "        abs_diff = (y_true - preds).abs()\n",
    "\n",
    "        log_sigma.clamp_(-5, 5)\n",
    "\n",
    "        if metric:\n",
    "            print('HERE')\n",
    "            abs_diff.clamp_max_(1000)\n",
    "            print(log_sigma)\n",
    "            log_sigma.clamp_(-np.log(70), np.log(70))  # TODO: min bound is strange??\n",
    "            print(log_sigma)\n",
    "\n",
    "        print(log_sigma)\n",
    "#         log_sigma.clamp_min_(-5)\n",
    "\n",
    "        losses = np.sqrt(2) * abs_diff / log_sigma.exp() + log_sigma + np.log(2) / 2\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.7567, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
       "        5.0000, 5.0000], grad_fn=<AsStridedBackward>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_sigmas.clamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.248495242049359"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.7567, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
       "        5.0000, 5.0000], grad_fn=<AsStridedBackward>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2485)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(7.7151, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LaplaceLoss()(FVC_true, all_preds[0][:, 0] * FVCs_std + FVCs_mean, torch.tensor(np.log(70)), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE\n",
      "tensor([4.7567, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000], grad_fn=<AsStridedBackward>)\n",
      "tensor([4.7567, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000], grad_fn=<AsStridedBackward>)\n",
      "tensor([4.7567, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000], grad_fn=<AsStridedBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(6.8225, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LaplaceLoss()(FVC_true, all_preds[0][:, 0] * FVCs_std + FVCs_mean, log_sigmas, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25.7638, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LaplaceLoss()(FVC_true, FVC_preds, log_sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25.7757, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LaplaceLoss()(FVC_true, FVC_preds[0], log_sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coefs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-b234d62209fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcoefs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'coefs' is not defined"
     ]
    }
   ],
   "source": [
    "coefs.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks_mean ** 3, weeks_mean ** 2, weeks_mean, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplaceLossTMP(_Loss):\n",
    "    def forward(self, y_true, preds, log_sigma):\n",
    "        abs_diff = (y_true - preds).abs()\n",
    "#         abs_diff.clamp_max_(1_000)\n",
    "        log_sigma.clamp_(-5, 5)  # -np.log(70), np.log(70)\n",
    "#         log_sigma.clamp_min_(-5)\n",
    "        losses = np.sqrt(2) * abs_diff / log_sigma.exp() + log_sigma + np.log(2) / 2\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6365897236027999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-0.4516299068927765)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = train_dataset[0]\n",
    "\n",
    "\n",
    "# weeks_mean, weeks_std = 31.861846352485475, 23.240045178171002\n",
    "# FVCs_mean, FVCs_std = 2690.479018721756, 832.5021066817238\n",
    "\n",
    "# data_weeks = torch.tensor(data.weeks, dtype=dtype)\n",
    "# data_weeks = (data_weeks - weeks_mean) / weeks_std\n",
    "# weeks = torch.empty(len(data.weeks), 4, dtype=dtype)\n",
    "# weeks[:, 0] = 0 * data_weeks ** 3  # TODO: remove\n",
    "# weeks[:, 1] = 0 * data_weeks ** 2  # TODO: remove\n",
    "# weeks[:, 2] = data_weeks\n",
    "# weeks[:, 3] = 1\n",
    "\n",
    "# all_preds = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22a6482ee08>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data.weeks, FVC_preds.detach().cpu().numpy())\n",
    "\n",
    "plt.plot(data.weeks, FVC_true.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_loss = 0\n",
    "for FVC, preds in zip(data.fvcs, all_preds):\n",
    "    coefs = preds[:4]\n",
    "    log_sigma = preds[4]\n",
    "#             print(log_sigma.item())\n",
    "\n",
    "    FVC_preds = (weeks * coefs).sum(dim=1)\n",
    "    FVC_preds = FVC_preds * FVCs_std + FVCs_mean + 1000 - 200\n",
    "    FVC_true = torch.tensor(data.fvcs, dtype=dtype)\n",
    "\n",
    "    agg_loss += LaplaceLossTMP()(FVC_true, FVC_preds, torch.tensor(np.log(70)))\n",
    "loss = agg_loss / len(data.weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.7861, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sigma.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summary(model.CT_features_extractor[0].net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    print(f'{name[20:]:50} : {p.data.min().item():15.3e}, {p.data.max().item():15.3e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = model(train_dataset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.0239,  0.0427, -0.0162,  0.0765, -0.0407], grad_fn=<CopyBackwards>),\n",
       " tensor([-0.0596,  0.0999,  0.0310,  0.0311, -0.0328], grad_fn=<CopyBackwards>),\n",
       " tensor([-0.0534,  0.0610,  0.0263,  0.1096, -0.0509], grad_fn=<CopyBackwards>),\n",
       " tensor([-0.0468, -0.0004,  0.0322,  0.0902, -0.0749], grad_fn=<CopyBackwards>),\n",
       " tensor([-0.0137,  0.0090,  0.0003,  0.0589, -0.0920], grad_fn=<CopyBackwards>),\n",
       " tensor([-0.0302,  0.0220,  0.0029,  0.1146, -0.0387], grad_fn=<CopyBackwards>),\n",
       " tensor([-0.0218,  0.0516, -0.0411,  0.0951,  0.0158], grad_fn=<CopyBackwards>),\n",
       " tensor([-0.0205,  0.0779, -0.0219,  0.1012, -0.0544], grad_fn=<CopyBackwards>),\n",
       " tensor([ 0.0394,  0.0843, -0.0223,  0.0686, -0.0343], grad_fn=<CopyBackwards>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset[2]\n",
    "data_weeks = torch.tensor(data.weeks, dtype=dtype)\n",
    "weeks = torch.empty(len(data.weeks), 4, dtype=dtype)\n",
    "weeks[:, 0] = data_weeks ** 3\n",
    "weeks[:, 1] = data_weeks ** 2\n",
    "weeks[:, 2] = data_weeks\n",
    "weeks[:, 3] = 1\n",
    "\n",
    "# all_preds = model(data)\n",
    "\n",
    "agg_loss = 0\n",
    "for week, FVC, preds in zip(data.weeks, data.fvcs, all_preds):\n",
    "    coefs = preds[:4]\n",
    "    log_sigma = preds[4]\n",
    "\n",
    "    FVC_preds = (weeks * coefs).sum(dim=1)\n",
    "    FVC_true = torch.tensor(data.fvcs, dtype=dtype)\n",
    "\n",
    "    agg_loss += LaplaceLoss()(FVC_true, FVC_preds, log_sigma)\n",
    "loss = agg_loss / len(data.weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4912.0527, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-8b8d69623f00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Has grad but it is None: {name[20:]:50}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{name[20:]:50} : {p.grad.data.cpu().min().item():15.3e}, {p.grad.data.cpu().max().item():15.3e}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'No grad: {name[20:]:50}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        if p.grad is None:\n",
    "            print(f'Has grad but it is None: {name[20:]:50}')\n",
    "        else:\n",
    "            print(f'{name[20:]:50} : {p.grad.data.cpu().min().item():15.3e}, {p.grad.data.cpu().max().item():15.3e}')\n",
    "    else:\n",
    "        print(f'No grad: {name[20:]:50}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "    print(i, train_dataset[i].images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_all = CTDataset(\n",
    "    f'{PROCESSED_PATH}/train',\n",
    "    f'{IMAGE_PATH}/train.csv',\n",
    "    train=True, test_size=0.0, random_state=42\n",
    ")\n",
    "\n",
    "images = [-1000 * (1.0 - dataset_all[i].masks) + dataset_all[i].masks * dataset_all[i].images\n",
    "          for i in range(len(dataset_all))]\n",
    "\n",
    "sum_image = 0\n",
    "sum_sq_image = 0\n",
    "for image in images:\n",
    "    sum_image += image.sum()\n",
    "    sum_sq_image += (image ** 2).sum()\n",
    "\n",
    "N = np.prod((176., 192., 256., 256.))\n",
    "\n",
    "mean = sum_image / N\n",
    "\n",
    "mean\n",
    "\n",
    "var = sum_sq_image / N + mean ** 2 - 2 * mean * sum_image / N\n",
    "\n",
    "std = var ** 0.5\n",
    "\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
