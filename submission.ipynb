{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "from collections import namedtuple\n",
    "import time\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import tabulate\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sparse\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from my_efficientnet_pytorch_3d import EfficientNet3D\n",
    "\n",
    "import torchio\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import CTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ..src.utils import segmentate_patient, resample, CTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ..src.model_utils import OSICNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "USE_GPU = True\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../models/model.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"../input/osic-pulmonary-fibrosis-progression/\" if 'linux' in platform.platform().lower() else 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_PATH = os.path.join(IMAGE_PATH, 'processed_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patients = sorted(os.listdir(os.path.join(IMAGE_PATH, 'test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'test'\n",
    "\n",
    "for patient_n in tqdm.tqdm(range(len(test_patients))):\n",
    "    patient = test_patients[patient_n]\n",
    "    \n",
    "    all_images, _, _, all_masks, meta_data = segmentate_patient(mode, patient_n, IMAGE_PATH, perform_hack=False)\n",
    "    SliceThickness, PixelSpacing = meta_data['SliceThickness'][0], meta_data['PixelSpacing'][0]\n",
    "    assert len(PixelSpacing) == 2\n",
    "    \n",
    "    new_spacing = np.array([SliceThickness] + list(PixelSpacing))\n",
    "    # noinspection PyBroadException\n",
    "    try:\n",
    "        ordering, case = np.argsort([float(_) for _ in meta_data['SliceLocation']]), 0\n",
    "    except Exception:\n",
    "        # noinspection PyBroadException\n",
    "        try:\n",
    "            ordering, case = np.argsort([float(_) for _ in meta_data['InstanceNumber']]), 1\n",
    "        except Exception:\n",
    "            ordering, case = np.arange(len(all_images)), 2\n",
    "    \n",
    "    all_images, all_masks = np.array(all_images)[ordering], np.array(all_masks)[ordering]\n",
    "    for key, values in meta_data.items():\n",
    "        meta_data[key] = np.array(values)[ordering].tolist()\n",
    "    \n",
    "    if len(all_images) != 196:\n",
    "        all_images, _ = resample(\n",
    "            all_images, [196, *all_images.shape[1:]], SliceThickness, PixelSpacing\n",
    "        )\n",
    "        all_masks, new_spacing = resample(\n",
    "            all_masks, [196, *all_images.shape[1:]], SliceThickness, PixelSpacing\n",
    "        )\n",
    "        all_masks = all_masks > 0\n",
    "\n",
    "        meta_data['SliceThickness'] = [new_spacing[0] for _ in meta_data['SliceThickness']]\n",
    "        meta_data['PixelSpacing'] = [[new_spacing[0], new_spacing[1]] for _ in meta_data['PixelSpacing']]\n",
    "\n",
    "    base_path = os.path.join(PROCESSED_PATH, mode, test_patients[patient_n])\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    \n",
    "    if all_images.shape[1] == 512:\n",
    "        all_masks = all_masks[:, ::2, ::2]\n",
    "        all_images = all_images[:, ::2, ::2]\n",
    "        meta_data['PixelSpacing'] = [[new_spacing[0] * 2, new_spacing[1] * 2] for _ in meta_data['PixelSpacing']] \n",
    "    if all_images.shape[1] == 632:\n",
    "        all_masks = all_masks[:, 60:-60:2, 60:-60:2]\n",
    "        all_images = all_images[:, 60:-60:2, 60:-60:2]\n",
    "        meta_data['PixelSpacing'] = [[new_spacing[0] * 2, new_spacing[1] * 2] for _ in meta_data['PixelSpacing']]\n",
    "    if all_images.shape[1] == 768:\n",
    "        all_masks = all_masks[:, ::3, ::3]\n",
    "        all_images = all_images[:, ::3, ::3]\n",
    "        meta_data['PixelSpacing'] = [[new_spacing[0] * 3, new_spacing[1] * 3] for _ in meta_data['PixelSpacing']]\n",
    "    if all_images.shape[1] == 1302:\n",
    "        all_masks = all_masks[:, 11:-11:5, 11:-11:5]\n",
    "        all_images = all_images[:, 11:-11:5, 11:-11:5]\n",
    "        meta_data['PixelSpacing'] = [[new_spacing[0] * 5, new_spacing[1] * 5] for _ in meta_data['PixelSpacing']]\n",
    "\n",
    "    np.save(os.path.join(base_path, 'meta.npy'), meta_data)\n",
    "    np.save(os.path.join(base_path, 'images.npy'), all_images)\n",
    "    sparse.save_npz(os.path.join(base_path, 'masks.npz'), sparse.COO(np.array(all_masks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CTDataset(\n",
    "    f'{PROCESSED_PATH}/test',\n",
    "    f'{IMAGE_PATH}/test.csv',\n",
    "    train=False,\n",
    "    transform=None,\n",
    "    test_size=0,\n",
    "    padding_mode=None, \n",
    "    random_state=42,\n",
    "    pad_global=False,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OSICNet(\n",
    "    dtype=dtype, device=device, use_poly=False, efficient_net_model_number=0, hidden_size=256, dropout_rate=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = []\n",
    "\n",
    "model.eval()\n",
    "for cur_iter, data in enumerate(test_dataset):\n",
    "    FVC_true = data[2]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        weeks = list(range(-12, 133 + 1))\n",
    "        data[0] = torch.tensor([data[0][0].item()] * len(weeks), dtype=torch.float32)\n",
    "        data[1] = torch.tensor(weeks, dtype=torch.float32)\n",
    "        data[2] = torch.tensor([data[2][0].item()] * len(weeks), dtype=torch.float32)\n",
    "        \n",
    "        all_preds = model(data)\n",
    "\n",
    "    FVC_low, FVC_preds, FVC_high = all_preds[0]    \n",
    "    sigmas = torch.clamp_min(FVC_high - FVC_low, 1e-7)\n",
    "        \n",
    "    for idx, week in enumerate(range(-12, 133 + 1)):\n",
    "        tmp_id = test_dataset_test_patients[cur_iter] + '_' + str(week)\n",
    "        FVC = FVC_preds[idx].item()\n",
    "        Confidence = sigmas[idx].item()\n",
    "        answer.append([tmp_id, FVC, Confidence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(answer, columns=['Patient_Week', 'FVC', 'Confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
