{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add crop for log_sigma and for abs diff for FVC\n",
    "# TODO: add normalization for data\n",
    "# TODO: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import os\n",
    "import platform\n",
    "from collections import namedtuple\n",
    "import time\n",
    "\n",
    "# import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sparse\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "# from torchvision import transforms\n",
    "# from torchsummary import summary\n",
    "# from efficientnet_pytorch_3d import EfficientNet3D\n",
    "from my_efficientnet_pytorch_3d import EfficientNet3D\n",
    "\n",
    "# from utils import *\n",
    "\n",
    "\n",
    "########################\n",
    "\n",
    "RUNNING_IN_KAGGLE = 'linux' in platform.platform().lower()\n",
    "IMAGE_PATH = \"../input/osic-pulmonary-fibrosis-progression/\" if RUNNING_IN_KAGGLE else 'data/'\n",
    "PROCESSED_PATH = 'FIX IT!' if RUNNING_IN_KAGGLE else 'data/processed-data/'  # TODO: fix this line\n",
    "\n",
    "dtype = torch.float32\n",
    "USE_GPU = True\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataset(Dataset):\n",
    "    _ReturnValue = namedtuple('ReturnValue', ['weeks', 'fvcs', 'features', 'masks', 'images'])\n",
    "\n",
    "    def __init__(\n",
    "            self, root, csv_path, train=True, test_size=0.25, random_state=42):\n",
    "        \"\"\"\n",
    "        :param dataset:\n",
    "\n",
    "        :param root:\n",
    "        :param train:\n",
    "        :param train_test_split:\n",
    "        :param random_state:\n",
    "        \"\"\"\n",
    "        assert test_size is not None\n",
    "\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.csv_path = csv_path\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "        if not os.path.exists(self.root):\n",
    "            raise ValueError('Data is missing')\n",
    "\n",
    "        self._patients = list(sorted(os.listdir(self.root)))\n",
    "\n",
    "        if self.test_size == 0:\n",
    "            self._train_patients, self._test_patients = self._patients, []\n",
    "        else:\n",
    "            self._train_patients, self._test_patients = train_test_split(\n",
    "                self._patients, test_size=self.test_size, random_state=random_state\n",
    "            )\n",
    "\n",
    "        self._table_features = dict()\n",
    "        table_data = pd.read_csv(self.csv_path)\n",
    "        for patient in self._patients:\n",
    "            patient_data = table_data[table_data.Patient == patient]\n",
    "\n",
    "            all_weeks = patient_data.Weeks.tolist()\n",
    "            all_fvcs = patient_data.FVC.tolist()\n",
    "\n",
    "            all_weeks, all_fvcs = zip(*sorted(zip(all_weeks, all_fvcs), key=lambda x: x[0]))\n",
    "\n",
    "            age = sorted(zip(*np.unique(patient_data.Age, return_counts=True)), key=lambda x: x[1])[-1][0]\n",
    "            sex = sorted(zip(*np.unique(patient_data.Sex, return_counts=True)), key=lambda x: x[1])[-1][0]\n",
    "            smoking_status = sorted(zip(*np.unique(patient_data.SmokingStatus, return_counts=True)), key=lambda x: x[1])[-1][0]\n",
    "\n",
    "            sex = [0, 1] if sex == 'Female' else [1, 0]\n",
    "            smoking_status = (\n",
    "                [1, 0, 0] if smoking_status == 'Ex-smoker' else\n",
    "                [0, 1, 0] if smoking_status == 'Never smoked' else\n",
    "                [0, 0, 1] if smoking_status == 'Currently smokes' else\n",
    "                [0, 0, 0]\n",
    "            )\n",
    "            self._table_features[patient] = (\n",
    "                all_weeks, all_fvcs, [age] + sex + smoking_status\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        patient = self._train_patients[index] if self.train else self._test_patients[index]\n",
    "        base_path = os.path.join(self.root, patient)\n",
    "\n",
    "        meta = np.load(os.path.join(base_path, 'meta.npy'), allow_pickle=True).tolist()\n",
    "        masks = sparse.load_npz(os.path.join(base_path, 'masks.npz'))\n",
    "        images = np.load(os.path.join(base_path, 'images.npy'))\n",
    "\n",
    "        meta_processed = dict()\n",
    "        for key, values in meta.items():\n",
    "            if key in {'SliceLocation', 'InstanceNumber'}:\n",
    "                continue\n",
    "            else:\n",
    "                unique_values, values_cnt = np.unique(values, return_counts=True, axis=0)\n",
    "                most_frequent = sorted(zip(unique_values, values_cnt), key=lambda x: x[1])[-1][0]\n",
    "                most_frequent = np.array(most_frequent).reshape(-1)\n",
    "                if key in {\n",
    "                    'SliceThickness', 'TableHeight', 'WindowCenter', 'WindowWidth'\n",
    "                }:\n",
    "                    meta_processed[key] = most_frequent[0]\n",
    "                elif key == 'PixelSpacing':\n",
    "                    if len(most_frequent) == 1:\n",
    "                        meta_processed['PixelSpacingX'], meta_processed['PixelSpacingY'] = (\n",
    "                            most_frequent[0], most_frequent[0]\n",
    "                        )\n",
    "                    else:\n",
    "                        meta_processed['PixelSpacingX'], meta_processed['PixelSpacingY'] = (\n",
    "                            most_frequent[0], most_frequent[1]\n",
    "                        )\n",
    "                elif key == 'PatientPosition':\n",
    "                    pass\n",
    "                elif key == 'PositionReferenceIndicator':\n",
    "                    pass\n",
    "\n",
    "        all_weeks, all_fvcs, features = self._table_features[patient]\n",
    "        features = [value for key, value in meta_processed.items()] + features\n",
    "\n",
    "        return CTDataset._ReturnValue(weeks=all_weeks, fvcs=all_fvcs, features=features, masks=masks, images=images)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._train_patients if self.train else self._test_patients)\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'OSIC Pulmonary Fibrosis Progression Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        tmp = 'train' if self.train is True else 'test'\n",
    "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        return fmt_str\n",
    "\n",
    "\n",
    "class LaplaceLoss(_Loss):\n",
    "    def forward(self, y_true, preds, log_sigma):\n",
    "        return (y_true - preds).pow(2).mean().pow(0.5)  # TODO: remove\n",
    "        abs_diff = (y_true - preds).abs()\n",
    "#         abs_diff.clamp_max_(1_000)\n",
    "        log_sigma.clamp_(-5, 5)  # -np.log(70), np.log(70)\n",
    "#         log_sigma.clamp_min_(-5)\n",
    "        losses = np.sqrt(2) * abs_diff / log_sigma.exp() + log_sigma + np.log(2) / 2\n",
    "        return losses.mean()\n",
    "\n",
    "\n",
    "class SqueezeLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.squeeze()\n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, net):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net.extract_features(x.unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "\n",
    "class OSICNet(nn.Module):\n",
    "    def __init__(self, dtype, device, efficient_net_model_number, hidden_size, dropout_rate):  # , output_size\n",
    "        super().__init__()\n",
    "\n",
    "        self.dtype = dtype\n",
    "        self.device = device\n",
    "\n",
    "        self.CT_features_extractor = nn.Sequential(\n",
    "            FeatureExtractor(\n",
    "                EfficientNet3D.from_name(\n",
    "                    f'efficientnet-b{efficient_net_model_number}', override_params={'num_classes': 1}, in_channels=1\n",
    "                )\n",
    "            ),\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            SqueezeLayer()\n",
    "        )\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(1280 + 14, hidden_size),  # 1294\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, 5)  # output_size\n",
    "        )\n",
    "        \n",
    "        self._initialize_weights()\n",
    "\n",
    "        self.CT_features_extractor.to(self.device)\n",
    "        self.predictor.to(self.device)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv3d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.kernel_size[2] * m.out_channels\n",
    "                m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "            elif isinstance(m, torch.nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        \n",
    "#     def forward(self, data):\n",
    "#         mean_dataset, std_dataset = -971.4692260919278, 117.84143467421829\n",
    "#         lungs = -1000 * (1.0 - data.masks) + data.masks * data.images\n",
    "#         lungs = (lungs - mean_dataset) / std_dataset\n",
    "#         lungs = torch.tensor(lungs, dtype=self.dtype, device=self.device)\n",
    "#         lungs_features = self.CT_features_extractor(lungs)\n",
    "\n",
    "#         data_weeks = torch.tensor(data.weeks, dtype=self.dtype)\n",
    "#         weeks = torch.empty(len(data.weeks), 4, dtype=self.dtype)\n",
    "#         weeks[:, 3] = 1\n",
    "#         weeks[:, 2] = data_weeks\n",
    "#         weeks[:, 1] = data_weeks ** 2\n",
    "#         weeks[:, 0] = data_weeks ** 3\n",
    "\n",
    "#         agg_loss = 0\n",
    "#         for week, FVC in zip(data.weeks, data.fvcs):\n",
    "#             table_features = torch.tensor(np.r_[week, FVC, data.features], dtype=self.dtype, device=self.device)\n",
    "#             X = lungs_features  # torch.cat([lungs_features, table_features])\n",
    "\n",
    "#             pred_numbers = self.predictor(X).cpu()\n",
    "#             coefs = pred_numbers[:4]\n",
    "#             log_sigma = pred_numbers[4]\n",
    "\n",
    "#             FVC_preds = (weeks * coefs).sum(dim=1)\n",
    "#             FVC_true = torch.tensor(data.fvcs, dtype=self.dtype)\n",
    "\n",
    "#             agg_loss += LaplaceLoss()(FVC_true, FVC_preds, log_sigma)\n",
    "\n",
    "#         return agg_loss / len(data.weeks)\n",
    "\n",
    "    def forward(self, data):\n",
    "        lungs_mean, lungs_std = -971.4692260919278, 117.84143467421829\n",
    "        lungs = -1000 * (1.0 - data.masks) + data.masks * data.images\n",
    "        lungs = (lungs - lungs_mean) / lungs_std\n",
    "        lungs = torch.tensor(lungs, dtype=self.dtype, device=self.device)\n",
    "        lungs_features = self.CT_features_extractor(lungs)\n",
    "\n",
    "        weeks_mean, weeks_std = 31.861846352485475, 23.240045178171002\n",
    "        FVCs_mean, FVCs_std = 2690.479018721756, 832.5021066817238\n",
    "        other_ftrs_mean = np.array([\n",
    "            2.76561876e+00,  1.42373805e+00,  1.25608294e+00,  1.33766080e+02,\n",
    "            -5.23857955e+02, -1.24154545e+03,  6.72613636e+01,  7.89772727e-01,\n",
    "            2.10227273e-01,  6.70454545e-01,  2.78409091e-01,  5.11363636e-02\n",
    "        ])\n",
    "        other_ftrs_std = np.array([\n",
    "            2.34777445e+00, 1.47563586e-01, 9.90841780e-01, 5.85989667e+01,\n",
    "            1.92059435e+02, 8.48268563e+02, 7.06784382e+00, 4.07469958e-01,\n",
    "            4.07469958e-01, 4.70048134e-01, 4.48215873e-01, 2.20275818e-01\n",
    "        ])\n",
    "\n",
    "        data._replace(weeks = (np.array(data.weeks) - weeks_mean) / weeks_std)\n",
    "        data._replace(fvcs = (np.array(data.fvcs) - FVCs_mean) / FVCs_std)\n",
    "        data._replace(features = (np.array(data.features) - other_ftrs_mean) / other_ftrs_std)\n",
    "\n",
    "#         data_weeks = torch.tensor(data.weeks, dtype=self.dtype)\n",
    "#         weeks = torch.empty(len(data.weeks), 4, dtype=self.dtype)\n",
    "#         weeks[:, 3] = 1\n",
    "#         weeks[:, 2] = data_weeks\n",
    "#         weeks[:, 1] = data_weeks ** 2\n",
    "#         weeks[:, 0] = data_weeks ** 3\n",
    "\n",
    "#         agg_loss = 0\n",
    "        all_preds = []\n",
    "        for week, FVC in zip(data.weeks, data.fvcs):\n",
    "            table_features = torch.tensor(np.r_[week, FVC, data.features], dtype=self.dtype, device=self.device)\n",
    "            X = torch.cat([lungs_features, table_features])  # lungs_features\n",
    "\n",
    "            pred_numbers = self.predictor(X).cpu()\n",
    "            all_preds.append(pred_numbers)\n",
    "#             coefs = pred_numbers[:4]\n",
    "#             log_sigma = pred_numbers[4]\n",
    "\n",
    "#             FVC_preds = (weeks * coefs).sum(dim=1)\n",
    "#             FVC_true = torch.tensor(data.fvcs, dtype=self.dtype)\n",
    "            \n",
    "#             agg_loss += LaplaceLoss()(FVC_true, FVC_preds, log_sigma)\n",
    "\n",
    "#         return agg_loss / len(data.weeks)\n",
    "        return all_preds\n",
    "\n",
    "\n",
    "class LinearDecayLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, start_epoch, stop_epoch, start_lr, stop_lr, last_epoch=-1):\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.start_epoch = start_epoch\n",
    "        self.stop_epoch = stop_epoch\n",
    "\n",
    "        self.start_lr = start_lr\n",
    "        self.stop_lr = stop_lr\n",
    "\n",
    "        self.last_epoch = last_epoch\n",
    "\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self) -> list:\n",
    "        if self.last_epoch < self.start_epoch:\n",
    "            new_lr = self.start_lr\n",
    "        elif self.last_epoch > self.stop_epoch:\n",
    "            new_lr = self.stop_lr\n",
    "        else:\n",
    "            new_lr = self.start_lr + (\n",
    "                (self.stop_lr - self.start_lr) *\n",
    "                (self.last_epoch - self.start_epoch) /\n",
    "                (self.stop_epoch - self.start_epoch)\n",
    "            )\n",
    "        return [new_lr for _ in self.optimizer.param_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CTDataset(\n",
    "    f'{PROCESSED_PATH}/train',\n",
    "    f'{IMAGE_PATH}/train.csv',\n",
    "    train=True, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "test_dataset = CTDataset(\n",
    "    f'{PROCESSED_PATH}/train',\n",
    "    f'{IMAGE_PATH}/train.csv',\n",
    "    train=False, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OSICNet(dtype=dtype, device=device, efficient_net_model_number=0, hidden_size=512, dropout_rate=0.5)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-8, momentum=0.9)  # , weight_decay=5e-4)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "\n",
    "### TMP ###\n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-9, momentum=0, weight_decay=0)  # 0.9, 5e-4)\n",
    "# lr_scheduler = LinearDecayLR(optimizer, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for g in optimizer.param_groups:\n",
    "#     g['lr'] /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([53.5616, 53.7588, 62.3433, -9.2700,  0.0000])\n",
      "Epoch   1, iter    1, loss  2501.177002, cur iter time    8.4 sec, elapsed time    8.5 sec, log sigma -0.9355030059814453\n",
      "tensor([18.9669, 25.5763, 24.8538, 91.5446,  0.0000])\n",
      "Epoch   2, iter    1, loss  2506.117432, cur iter time    8.3 sec, elapsed time   17.0 sec, log sigma -0.22857779264450073\n",
      "tensor([-45.4187, -53.6036, -61.3432, -82.2663,   0.0000])\n",
      "Epoch   3, iter    1, loss  2383.500000, cur iter time    8.3 sec, elapsed time   25.5 sec, log sigma 0.4796966016292572\n",
      "tensor([-57.4433, -60.6987, -73.4870, -12.2167,   0.0000])\n",
      "Epoch   4, iter    1, loss  1377.990234, cur iter time    8.3 sec, elapsed time   33.9 sec, log sigma -0.04289938509464264\n",
      "tensor([39.0523, 45.9659, 48.1560, 89.6505,  0.0000])\n",
      "Epoch   5, iter    1, loss   976.821838, cur iter time    8.3 sec, elapsed time   42.4 sec, log sigma 0.3753660023212433\n",
      "tensor([58.3137, 64.4769, 75.1582, 59.0687,  0.0000])\n",
      "Epoch   6, iter    1, loss  1865.181030, cur iter time    8.3 sec, elapsed time   50.9 sec, log sigma 0.19675830006599426\n",
      "tensor([-21.1042, -29.2720, -31.1767, -90.8420,   0.0000])\n",
      "Epoch   7, iter    1, loss  1346.692749, cur iter time    8.3 sec, elapsed time   59.3 sec, log sigma -0.2277003526687622\n",
      "tensor([57.7774, 61.9295, 77.3125, 29.9541,  0.0000])\n",
      "Epoch   8, iter    1, loss  1871.659302, cur iter time    8.6 sec, elapsed time   68.1 sec, log sigma 0.6202340722084045\n",
      "tensor([56.2149, 62.9062, 77.8712, 49.7728,  0.0000])\n",
      "Epoch   9, iter    1, loss  1409.271973, cur iter time    8.3 sec, elapsed time   76.5 sec, log sigma -0.7573236227035522\n",
      "tensor([-54.4317, -61.6631, -72.0585, -68.6441,   0.0000])\n",
      "Epoch  10, iter    1, loss  1303.527100, cur iter time    8.3 sec, elapsed time   85.0 sec, log sigma -0.16952542960643768\n",
      "tensor([-17.5131, -24.2339, -20.1521, -90.7455,   0.0000])\n",
      "Epoch  11, iter    1, loss   861.324341, cur iter time    8.4 sec, elapsed time   93.5 sec, log sigma 1.247833490371704\n",
      "tensor([-56.6812, -59.2100, -69.8196,  -5.4326,   0.0000])\n",
      "Epoch  12, iter    1, loss  1078.938843, cur iter time    8.5 sec, elapsed time  102.1 sec, log sigma -0.34169894456863403\n",
      "tensor([-59.0181, -64.6371, -69.6332, -64.2877,   0.0000])\n",
      "Epoch  13, iter    1, loss  1313.370483, cur iter time    8.3 sec, elapsed time  110.6 sec, log sigma -1.2915709018707275\n",
      "tensor([-39.1098, -47.1820, -53.5114, -87.5912,   0.0000])\n",
      "Epoch  14, iter    1, loss   897.097595, cur iter time    8.4 sec, elapsed time  119.1 sec, log sigma 0.4924854636192322\n",
      "tensor([55.3604, 60.5445, 62.1685, 73.5539,  0.0000])\n",
      "Epoch  15, iter    1, loss  1278.713623, cur iter time    8.4 sec, elapsed time  127.6 sec, log sigma 1.258838415145874\n",
      "tensor([-47.6614, -52.8955, -46.5281, -74.1873,   0.0000])\n",
      "Epoch  16, iter    1, loss   686.656128, cur iter time    8.5 sec, elapsed time  136.3 sec, log sigma 1.3036285638809204\n",
      "tensor([-60.0261, -65.5733, -70.7228, -58.5544,   0.0000])\n",
      "Epoch  17, iter    1, loss   911.259216, cur iter time    8.4 sec, elapsed time  144.8 sec, log sigma 0.037427544593811035\n",
      "tensor([ 5.0287,  9.4544,  2.6344, 84.5161,  0.0000])\n",
      "Epoch  18, iter    1, loss   910.956604, cur iter time    8.5 sec, elapsed time  153.5 sec, log sigma -1.0809509754180908\n",
      "tensor([ 22.1504,  18.5797,  28.6031, -62.7869,   0.0000])\n",
      "Epoch  19, iter    1, loss  1108.521484, cur iter time    8.6 sec, elapsed time  162.3 sec, log sigma 0.24114662408828735\n",
      "tensor([-14.9208, -23.5022, -29.0186, -87.2345,   0.0000])\n",
      "Epoch  20, iter    1, loss   793.415344, cur iter time    8.4 sec, elapsed time  170.9 sec, log sigma 0.2649293541908264\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCHS = 20\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    for cur_iter, data in enumerate(train_dataset):  # tqdm(, desc='Iteration over dataset'):\n",
    "        if cur_iter == 1:\n",
    "            break\n",
    "        cur_start_time = time.time()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "#         loss = model(data)\n",
    "\n",
    "        weeks_mean, weeks_std = 31.861846352485475, 23.240045178171002\n",
    "        FVCs_mean, FVCs_std = 2690.479018721756, 832.5021066817238\n",
    "\n",
    "        data_weeks = torch.tensor(data.weeks, dtype=dtype)\n",
    "        data_weeks = (data_weeks - weeks_mean) / weeks_std\n",
    "        weeks = torch.empty(len(data.weeks), 4, dtype=dtype)\n",
    "        weeks[:, 0] = data_weeks ** 3  # TODO: remove\n",
    "        weeks[:, 1] = data_weeks ** 2  # TODO: remove\n",
    "        weeks[:, 2] = data_weeks\n",
    "        weeks[:, 3] = 1\n",
    "\n",
    "        all_preds = model(data)\n",
    "\n",
    "        agg_loss = 0\n",
    "        for FVC, preds in zip(data.fvcs, all_preds):\n",
    "            coefs = preds[:4]\n",
    "            preds.retain_grad()\n",
    "            log_sigma = preds[4]\n",
    "#             print(log_sigma.item())\n",
    "\n",
    "            coefs[0] /= 4\n",
    "            coefs[1] /= 2\n",
    "            coefs[2] /= 1\n",
    "\n",
    "            coefs.retain_grad()  # TODO: remove\n",
    "\n",
    "            FVC_preds = (weeks * coefs).sum(dim=1)\n",
    "            FVC_preds = FVC_preds * FVCs_std + FVCs_mean\n",
    "            FVC_true = torch.tensor(data.fvcs, dtype=dtype)\n",
    "\n",
    "            agg_loss += LaplaceLoss()(FVC_true, FVC_preds, log_sigma)\n",
    "        loss = agg_loss / len(data.weeks)\n",
    "\n",
    "        loss.backward()\n",
    "#         print(coefs, coefs.grad)\n",
    "        print(preds.grad)\n",
    "        optimizer.step()\n",
    "\n",
    "        cur_end_time = time.time()\n",
    "\n",
    "        print(\n",
    "            f'Epoch {epoch + 1:3d}, '\n",
    "            f'iter {cur_iter + 1:4d}, '\n",
    "            f'loss {loss.item():12.6f}, '\n",
    "            f'cur iter time {cur_end_time - cur_start_time:6.1f} sec, '\n",
    "            f'elapsed time {cur_end_time - start_time:6.1f} sec, '\n",
    "            f'log sigma {log_sigma.item()}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32345.421655286285, 1015.177252989392, 31.861846352485475, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weeks_mean ** 3, weeks_mean ** 2, weeks_mean, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplaceLossTMP(_Loss):\n",
    "    def forward(self, y_true, preds, log_sigma):\n",
    "        abs_diff = (y_true - preds).abs()\n",
    "#         abs_diff.clamp_max_(1_000)\n",
    "        log_sigma.clamp_(-5, 5)  # -np.log(70), np.log(70)\n",
    "#         log_sigma.clamp_min_(-5)\n",
    "        losses = np.sqrt(2) * abs_diff / log_sigma.exp() + log_sigma + np.log(2) / 2\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6365897236027999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-0.4516299068927765)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = train_dataset[0]\n",
    "\n",
    "\n",
    "# weeks_mean, weeks_std = 31.861846352485475, 23.240045178171002\n",
    "# FVCs_mean, FVCs_std = 2690.479018721756, 832.5021066817238\n",
    "\n",
    "# data_weeks = torch.tensor(data.weeks, dtype=dtype)\n",
    "# data_weeks = (data_weeks - weeks_mean) / weeks_std\n",
    "# weeks = torch.empty(len(data.weeks), 4, dtype=dtype)\n",
    "# weeks[:, 0] = 0 * data_weeks ** 3  # TODO: remove\n",
    "# weeks[:, 1] = 0 * data_weeks ** 2  # TODO: remove\n",
    "# weeks[:, 2] = data_weeks\n",
    "# weeks[:, 3] = 1\n",
    "\n",
    "# all_preds = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22a6482ee08>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data.weeks, FVC_preds.detach().cpu().numpy())\n",
    "\n",
    "plt.plot(data.weeks, FVC_true.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_loss = 0\n",
    "for FVC, preds in zip(data.fvcs, all_preds):\n",
    "    coefs = preds[:4]\n",
    "    log_sigma = preds[4]\n",
    "#             print(log_sigma.item())\n",
    "\n",
    "    FVC_preds = (weeks * coefs).sum(dim=1)\n",
    "    FVC_preds = FVC_preds * FVCs_std + FVCs_mean + 1000 - 200\n",
    "    FVC_true = torch.tensor(data.fvcs, dtype=dtype)\n",
    "\n",
    "    agg_loss += LaplaceLossTMP()(FVC_true, FVC_preds, torch.tensor(np.log(70)))\n",
    "loss = agg_loss / len(data.weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.7861, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sigma.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summary(model.CT_features_extractor[0].net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    print(f'{name[20:]:50} : {p.data.min().item():15.3e}, {p.data.max().item():15.3e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = model(train_dataset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.0239,  0.0427, -0.0162,  0.0765, -0.0407], grad_fn=<CopyBackwards>),\n",
       " tensor([-0.0596,  0.0999,  0.0310,  0.0311, -0.0328], grad_fn=<CopyBackwards>),\n",
       " tensor([-0.0534,  0.0610,  0.0263,  0.1096, -0.0509], grad_fn=<CopyBackwards>),\n",
       " tensor([-0.0468, -0.0004,  0.0322,  0.0902, -0.0749], grad_fn=<CopyBackwards>),\n",
       " tensor([-0.0137,  0.0090,  0.0003,  0.0589, -0.0920], grad_fn=<CopyBackwards>),\n",
       " tensor([-0.0302,  0.0220,  0.0029,  0.1146, -0.0387], grad_fn=<CopyBackwards>),\n",
       " tensor([-0.0218,  0.0516, -0.0411,  0.0951,  0.0158], grad_fn=<CopyBackwards>),\n",
       " tensor([-0.0205,  0.0779, -0.0219,  0.1012, -0.0544], grad_fn=<CopyBackwards>),\n",
       " tensor([ 0.0394,  0.0843, -0.0223,  0.0686, -0.0343], grad_fn=<CopyBackwards>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset[2]\n",
    "data_weeks = torch.tensor(data.weeks, dtype=dtype)\n",
    "weeks = torch.empty(len(data.weeks), 4, dtype=dtype)\n",
    "weeks[:, 0] = data_weeks ** 3\n",
    "weeks[:, 1] = data_weeks ** 2\n",
    "weeks[:, 2] = data_weeks\n",
    "weeks[:, 3] = 1\n",
    "\n",
    "# all_preds = model(data)\n",
    "\n",
    "agg_loss = 0\n",
    "for week, FVC, preds in zip(data.weeks, data.fvcs, all_preds):\n",
    "    coefs = preds[:4]\n",
    "    log_sigma = preds[4]\n",
    "\n",
    "    FVC_preds = (weeks * coefs).sum(dim=1)\n",
    "    FVC_true = torch.tensor(data.fvcs, dtype=dtype)\n",
    "\n",
    "    agg_loss += LaplaceLoss()(FVC_true, FVC_preds, log_sigma)\n",
    "loss = agg_loss / len(data.weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4912.0527, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-8b8d69623f00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Has grad but it is None: {name[20:]:50}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{name[20:]:50} : {p.grad.data.cpu().min().item():15.3e}, {p.grad.data.cpu().max().item():15.3e}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'No grad: {name[20:]:50}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        if p.grad is None:\n",
    "            print(f'Has grad but it is None: {name[20:]:50}')\n",
    "        else:\n",
    "            print(f'{name[20:]:50} : {p.grad.data.cpu().min().item():15.3e}, {p.grad.data.cpu().max().item():15.3e}')\n",
    "    else:\n",
    "        print(f'No grad: {name[20:]:50}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "    print(i, train_dataset[i].images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_all = CTDataset(\n",
    "    f'{PROCESSED_PATH}/train',\n",
    "    f'{IMAGE_PATH}/train.csv',\n",
    "    train=True, test_size=0.0, random_state=42\n",
    ")\n",
    "\n",
    "images = [-1000 * (1.0 - dataset_all[i].masks) + dataset_all[i].masks * dataset_all[i].images\n",
    "          for i in range(len(dataset_all))]\n",
    "\n",
    "sum_image = 0\n",
    "sum_sq_image = 0\n",
    "for image in images:\n",
    "    sum_image += image.sum()\n",
    "    sum_sq_image += (image ** 2).sum()\n",
    "\n",
    "N = np.prod((176., 192., 256., 256.))\n",
    "\n",
    "mean = sum_image / N\n",
    "\n",
    "mean\n",
    "\n",
    "var = sum_sq_image / N + mean ** 2 - 2 * mean * sum_image / N\n",
    "\n",
    "std = var ** 0.5\n",
    "\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
